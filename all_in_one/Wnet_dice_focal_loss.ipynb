{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Wnet_dice_focal_loss.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RIqV48zuBpwM","colab_type":"text"},"source":["\"\"\"\n","COMPLETELY NEW VERSION OF UNET DESIGNED FOR BRAIN TUMOUR SEGMENTATION\n","\n","SPECS:\n","\n","1. Input size  is 240x240x4 for each image\n","\n","2. BRATS dataset \n","\n","3. DICE LOSS IS TAKEN AS A LOSS FUNCTION\n","\n","4. MULTICLASS SEGMENTATION HAS BEEN IMPLEMENTED\n","\n","\n","DESC:\n","\n","HERE OUR PREDICTION WILL HAVE 4 DIMENSIONS(because we have 4 classes) FOR EACH IMAGE. THESE 4 PREDICTIONS are compared with hot encoded label(Ground truth)\n","THIS IN A WAY TRAINS THE SYSTEM TO HOT ENCODE THE PREDICTIONS TOO.\n","WE ARE TRYING TO IMPLEMENT THE ABOVE STATED MODEL TO IMPLEMENT MULTICLASS SEGEMENTATION. BUT HAD TO CHANGE SOME THINGS WHICH ARE STATED BELOW\n","\n","PROBLEMS AND CHANGES:\n","\n","1. Faced the problem of class imbalance. So in this version we multiply dice coefficient for each class with certain weight. this weight is reciprocal of the frequency of that class\n","\n","2. The problem of class imbalance still persists and dice coeff is more than 1. So i this version we have implemented a new dice coefficient function.\n","\n","\n","FUTURE:\n","\n","1. IMPROVING DICE COEFFICIENT\n","\n","2. 3D IMPLEMENTATION\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"eSGVMeVbibw0","colab_type":"code","outputId":"cd391251-6a8b-4515-bdce-ce854d6e5720","executionInfo":{"status":"ok","timestamp":1558293137612,"user_tz":-330,"elapsed":1145,"user":{"displayName":"dwijay shanbhag","photoUrl":"","userId":"10252205309947413859"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["'''Mounting Google Drive on the Colab notebook'''\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hxotR3CiirGu","colab_type":"code","colab":{}},"source":["#file_image = '/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_image.hdf5'\n","import h5py\n","#dataset has data of 484 patients. (155 images of each patient)\n","#data is extracted using 4 different techniques\n","#size of data of 1 patient is [240,240,155,4]\n","#for 2D segmentation we stack in 3rd dimension (axis=2)\n","#train_image\n","image_store = h5py.File(\"/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_image.hdf5\", \"r\")\n","#train_labels\n","label_store = h5py.File(\"/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_label.hdf5\", \"r\")\n","train_images = image_store[\"image\"]\n","train_labels = label_store[\"label\"]\n","#print('hi')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RIkjuDek_v5Q","colab_type":"code","colab":{}},"source":["'''IMPORTING LIBRARIES'''\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import time\n","import math\n","import os\n","'''Clearing tesorflow computation graph'''\n","tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SAFj-oXR_0Rs","colab_type":"code","colab":{}},"source":["'''DEFINING VARIABLES'''\n","\n","batch_size=1              #batch size taken at a time\n","n_class = 4                #number of classes in the label\n","\n","'''PLACEHOLDER for input and output of UNET'''\n","'''Here we crop the 155x240x240 image to  160x160x192 by repeating the last layer 5 times to convert 155 to 160'''\n","#X = tf.placeholder(shape=[None,160,160,192,4], dtype=tf.float32, name='input_image')\n","#y = tf.placeholder(shape=[None,160,160,192,1], dtype=tf.int64, name='hot_encode_label')\n","#training = tf.placeholder_with_default(False, shape = (), name = 'training')\n","\n","\n","'''Batch variable exraction from h5py file (used by functions 'rnadom_h5py_batch' and 'test_batch')'''\n","out_img = np.empty((240,240,batch_size*155,4),dtype=np.float32)\n","out_label = np.empty((240,240,batch_size*155,1),dtype=np.int64)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"re3MWWJHLxuD","colab_type":"text"},"source":["DEFINING ALL THE REQUIRED FUNCTIONS"]},{"cell_type":"code","metadata":{"id":"No2sukbcBnCm","colab_type":"code","colab":{}},"source":["'''COMPUTATION GRAPH Function Definitions'''\n","\n","\n","def left_filter_def(ker_size,in_chan,out_chan,name='left_filter'):\n","    '''Defining a filter variable to perform convolution'''\n","    stddev = np.sqrt(4/(ker_size*ker_size*ker_size*ker_size*in_chan*out_chan))           #HE initialization\n","    if stddev < 0.0008:\n","        stddev = 0.0008\n","    return (tf.Variable(tf.truncated_normal([ker_size,ker_size,ker_size,in_chan,out_chan],stddev=stddev),name=name))\n","\n","\n","def right_filter_def(ker_size,in_chan,out_chan,name='right_filter'):\n","    '''Defining a filter variable to perform transpose convolution'''\n","    stddev = np.sqrt(4/(ker_size*ker_size*ker_size*ker_size*in_chan*out_chan))\n","    if stddev < 0.0008:\n","        stddev = 0.0008\n","    return (tf.Variable(tf.truncated_normal([ker_size,ker_size,ker_size,out_chan,in_chan],stddev=stddev),name=name))\n","\n","\n","def Conv_layer(input_im,filter_mask,stride,activation='None',name='conv'):\n","    '''Function to perform Convolution and apply activation filter'''\n","    '''Convolution'''\n","    conv = tf.nn.conv3d(input_im,filter_mask,strides = [1,stride,stride,stride,1], padding = \"SAME\",name=name)\n","    #norm_conv = tf.layers.batch_normalization(conv, training=training, momentum=0.9)\n","    '''Activation'''\n","    if activation == 'relu':\n","        return(tf.nn.relu(conv))\n","    elif activation == 'softmax':\n","        return(tf.nn.softmax(conv,axis=-1))\n","    elif activation == 'elu':\n","        return(tf.nn.elu(conv))\n","    else:\n","        #activation == 'None'\n","        return(conv)\n","    \n","\n","def Deconv_layer(input_im,filter_mask,stride,activation='None',name='De_conv'):\n","    '''Function to perform Transpose Convolution and apply activation filter'''\n","    '''Transpose Convolution'''\n","    inp_shape = np.shape(input_im) #tf.shape()\n","    out_shape = [batch_size]+[int(inp_shape[1].value*2), int(inp_shape[2].value*2),int(inp_shape[3].value*2), int(inp_shape[4].value/2)]\n","    \n","    conv = tf.nn.conv3d_transpose(input_im, filter_mask, out_shape, strides = [1,stride,stride,stride,1], padding = \"SAME\",name=name)\n","    #norm_conv = tf.layers.batch_normalization(conv, training=training, momentum=0.9)\n","    '''Activation'''\n","    if activation == 'relu':\n","        return(tf.nn.relu(conv))\n","    elif activation == 'softmax':\n","        return(tf.nn.softmax(conv,axis=-1))\n","    elif activation == 'elu':\n","        return(tf.nn.elu(conv))\n","    else:\n","        #activation == 'None'\n","        return(conv)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K2tyXeDFbpMy","colab_type":"code","colab":{}},"source":["'''Functions for batch Extraction and pre processing'''\n","\n","def normalizing_input():\n","    '''normalization of each input channels'''\n","    global out_img\n","    '''CHANNEL INFO'''\n","    # maximum value found using function called \"Finding_maximum_to_normalise \"\n","    #'''max value for dimension 4 is 5337.0'''\n","    #'''max value for dimension 3 is 11737.0'''\n","    #'''max value for dimension 2 is 9751.0'''\n","    #'''max value for dimension 1 is 6476.0'''\n","    out_img[:,:,:,0] = out_img[:,:,:,0]/6476.0\n","    out_img[:,:,:,1] = out_img[:,:,:,1]/9751.0\n","    out_img[:,:,:,2] = out_img[:,:,:,2]/11737.0\n","    out_img[:,:,:,3] = out_img[:,:,:,3]/5337.0\n","    \n","    \n","\n","def crop_image_fit_brain(in_image):\n","    '''cropping size was found using the code finding_brain.ipynb'''\n","    left = 19\n","    right= 210\n","    top  = 38\n","    bot  = 199\n","    out_image = in_image[top:(bot-1),left:(right+1),:,:]\n","    return (out_image)\n","\n","\n","def Pre_processing_3D(a):\n","    '''Function to roll axis to convert array into[depth,width,height,channels] and the divide it in batches'''\n","    #print(np.shape(a))\n","    b = np.rollaxis(a,2, 0)\n","    #print(np.shape(b))\n","    #image shape\n","    out_arr = np.empty(shape=[batch_size,160,np.shape(b)[1],np.shape(b)[2],np.shape(b)[3]])\n","    for i in range(batch_size):\n","        start = i*155\n","        end = start+155\n","        out_arr[i,0:155,:,:,:] = b[start:end,:,:,:]\n","    \n","    a = [out_arr[:,154:155,:,:,:]]*5\n","    out_arr[:,155:160,:,:,:] = a[0]\n","    \n","    '''clippig data from front of each batch'''\n","    '''to fit the model we remove first 3 slices of each batch'''\n","    '''shape of a is [batch_size,depth,width,height,channels]'''\n","    out_send = out_arr[:,:,:,:,:]\n","    #print(\"arr\",np.shape(out_arr),\"send\",np.shape(out_send))\n","    return (out_send)\n","\n","def random_rotate(in_image,in_label):\n","    \n","    check = np.random.random(1)[0]\n","    if check<0.25:\n","        out_image = in_image[:,:,::-1,:,:]\n","        out_lab = in_label[:,:,::-1,:,:]\n","        \n","    elif check<0.50:\n","        \n","        out_image = in_image[:,:,:,::-1,:]\n","        out_lab = in_label[:,:,:,::-1,:]\n","        \n","    elif check<0.75:\n","        \n","        out_image = in_image[:,::-1,:,:,:]\n","        out_lab = in_label[:,::-1,:,:,:]\n","        \n","    else:\n","        out_image =in_image\n","        out_lab = in_label\n","    \n","    return (out_image,out_lab)\n","\n","\n","\n","def random_h5py_batch(current_batch_no,permute_mat):\n","    '''Function to take batches randomly'''\n","    global out_img\n","    global out_label\n","    \n","    '''training info'''\n","    train_info = 380  #100 patients with 155 images each\n","\n","    if current_batch_no == 0:\n","        no_of_batches = train_info//batch_size  \n","        permute_mat = np.random.permutation(no_of_batches)\n","    \n","    start = permute_mat[current_batch_no]*batch_size*155\n","    end = start + (batch_size*155)\n","    train_images.read_direct(out_img,np.s_[:,:,start:end,:])\n","    train_labels.read_direct(out_label,np.s_[:,:,start:end,:])\n","    current_batch_no += 1\n","    #print(len(out_img))\n","    '''Input normalization'''\n","    normalizing_input()\n","    '''normalization oof labels'''\n","    #out_label = out_label\n","    #normalizing_label()\n","    '''converting multi class to dual class'''\n","    #out_label = convert_dual_class(out_label)\n","    '''cropping image and labels'''\n","    crop_out_image = crop_image_fit_brain(out_img)\n","    crop_out_label = crop_image_fit_brain(out_label)\n","    '''Rolling axes'''\n","    #out_img_send = np.rollaxis(crop_out_image,2, 0)\n","    '''hot encoding'''\n","    #out_label_send = crop_out_label\n","    '''3D conversion'''\n","    out_img_send = Pre_processing_3D(crop_out_image)\n","    out_label_send = Pre_processing_3D(crop_out_label)\n","    '''Data augmentation rotation'''\n","    #out_img_send,out_label_send = random_rotate(out_img_send,out_label_send)\n","     \n","    last=0\n","    if current_batch_no == len(permute_mat):\n","        last=1\n","    \n","    return (out_img_send,out_label_send,current_batch_no,permute_mat,last)\n","\n","def test_batch():\n","    '''Function to take next test batch''' \n","    global out_img\n","    global out_label\n","    \n","    '''training and testing info'''\n","    train_info = 380  #100 patients with 155 images each\n","    test_info = 484-train_info  #100 patients with 155 images each\n","    \n","    no_of_batches = test_info//batch_size  \n","    permute_mat = np.random.permutation(no_of_batches)\n","    start = (permute_mat[0]*batch_size*155) +(train_info*155)\n","    end = start + (155*batch_size)\n","    train_images.read_direct(out_img,np.s_[:,:,start:end,:])\n","    train_labels.read_direct(out_label,np.s_[:,:,start:end,:])\n","    \n","    '''normalization'''\n","    normalizing_input()\n","    #normalizing_label()\n","    '''croping images and labels'''\n","    crop_out_image = crop_image_fit_brain(out_img)\n","    crop_out_label = crop_image_fit_brain(out_label) \n","    '''3D processing'''\n","    out_img_send = Pre_processing_3D(crop_out_image)\n","    out_label_send = Pre_processing_3D(crop_out_label)\n","    \n","    return (out_img_send,out_label_send)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-NTV_zXbaY7","colab_type":"code","colab":{}},"source":["\n","  \n","def hot_encode(check_image,depth=n_class,name='hot_encode'):\n","    '''function for hot encoding images'''\n","    a = tf.one_hot(indices = check_image, depth=depth,name=name)\n","    b = tf.transpose(a,perm=[0,1,2,3,5,4])\n","    return b\n","\n","#############################################################################################################################\n","#GENERALIZED DICE LOSS FUNCTION\n","#############################################################################################################################\n","def generalized_dice_coeff(y_true, y_pred):\n","    Ncl = y_pred.shape[-1]\n","    print(Ncl)\n","    w = np.zeros(shape=(Ncl,))\n","    w = tf.reduce_sum(y_true, axis=[0,1,2,3]) + 1\n","    print(np.shape(w))\n","    w = 1/((w**2))\n","    print(np.shape(w))\n","    # Compute gen dice coef:\n","    numerator = tf.reduce_sum(y_true*y_pred, axis=[0,1,2,3])\n","    denominator = tf.reduce_sum(y_true+y_pred, axis=[0,1,2,3])\n","    num=den=0\n","    for i in range(np.shape(w)[0]):\n","        num += w[i]*numerator[i]\n","        den += w[i]*denominator[i]\n","            \n","    #num = tf.reduce_sum(a)\n","    #den = tf.reduce_sum(b)\n","    num = num + 0.000000001\n","    den = den + 0.000000001\n","\n","    gen_dice_coef = tf.identity(tf.divide((2*num),den),name='dice_coeff')\n","\n","    return (gen_dice_coef)\n","#############################################################################################################################\n","#GENERALIZED FOCAL LOSS FUNCTION\n","#############################################################################################################################\n","def generalized_focal_loss(y_true, y_pred, gamma=2.0, alpha=0.25):\n","    \n","    Ncl = y_pred.shape[-1]\n","    w = np.zeros(shape=(Ncl,))\n","    w = tf.reduce_sum(y_true, axis=[0,1,2,3]) + 1\n","    w = 1/((w))\n","    y_pred = y_pred + 0.000000001                                               #to ensure that logarithm in next step doenst give math error\n","    \n","    ce = tf.multiply(y_true, -tf.log(y_pred))                                   #cross entropy (multiclass)\n","    fl_var = tf.multiply(y_true, tf.pow(tf.subtract(1., y_pred), gamma))        #focal loss variables (gamma*(1-pt)*(graund_truth))\n","    #fl = tf.multiply(alpha, tf.multiply(fl_var, ce))\n","    fl = tf.multiply(fl_var, ce)\n","    #fl=ce\n","    final = tf.reduce_sum(fl, axis=[0,1,2,3])\n","    normalized_focal = 0\n","    \n","    for i in range(np.shape(w)[0]):\n","        #print(i)\n","        #a = w[i]#/tf.reduce_sum(w)\n","        #b = fl[:,:,:,:,i]\n","        #c = (b)/(tf.reduce_max(b)+1)\n","        #normalized_focal += tf.reduce_sum(a*b)\n","        #b += w[i]*denominator[:,:,:,i]\n","        normalized_focal += w[i]*final[i]\n","    weighted_focal = tf.divide(normalized_focal,4.0,name='focal_loss')\n","    return (weighted_focal)\n","#############################################################################################################################\n","#LOSS FUNCTION\n","#############################################################################################################################\n","def hybrid_loss(y_true, y_pred, gamma=0.5):\n","    dice = generalized_dice_coeff(y_true, y_pred)\n","    focal = generalized_focal_loss(y_true, y_pred)\n","    #update = (gamma*dice) + ((1-gamma)*focal)\n","    update = (gamma*(1-dice))\n","    final_loss = tf.add(update,((1-gamma)*focal),name='final_loss')\n","    return final_loss,dice,focal"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CQCK3RO4L3hl","colab_type":"text"},"source":["INITIALIZING THE MODEL FILTERS"]},{"cell_type":"markdown","metadata":{"id":"mf9Y3JjeMQnI","colab_type":"text"},"source":["DEFINING THE MODEL STRUCTURE"]},{"cell_type":"code","metadata":{"id":"3uIZEngOMVfS","colab_type":"code","colab":{}},"source":["def predict_model1(X):\n","    '''Function to define the UNET model'''\n","    '''MODEL1 Filter definition'''\n","    '''LEFT'''\n","    \n","    filter1 = left_filter_def(3,4,8,name='filter1')\n","    filter2 = left_filter_def(3,8,16,name='filter2')\n","    pre_resnet_filter1 = left_filter_def(1,16,8,name='pre_resnet_filter1')\n","    resnet_filter1 = left_filter_def(3,8,8,name='pre_resnet_filter1')\n","    \n","    filter3 = left_filter_def(3,8,16,name='filter3')\n","    filter4 = left_filter_def(3,16,32,name='filter4')\n","    pre_resnet_filter2 = left_filter_def(1,32,16,name='pre_resnet_filter2')\n","    resnet_filter2 = left_filter_def(3,16,16,name='pre_resnet_filter2')\n","    \n","    \n","    filter5 = left_filter_def(3,16,32,name='filter5')\n","    filter6 = left_filter_def(3,32,64,name='filter6')\n","    pre_resnet_filter3 = left_filter_def(1,64,32,name='pre_resnet_filter3')\n","    resnet_filter3 = left_filter_def(3,32,32,name='pre_resnet_filter3')\n","    \n","    \n","    filter7 = left_filter_def(3,32,64,name='filter7')\n","    filter8 = left_filter_def(3,64,128,name='filter8')\n","    pre_resnet_filter4 = left_filter_def(1,128,64,name='pre_resnet_filter4')\n","    resnet_filter4 = left_filter_def(3,64,64,name='pre_resnet_filter5')\n","    \n","    \n","    filter9 = left_filter_def(3,64,128,name='filter9')\n","    filter10= left_filter_def(3,128,(128*2),name='filter10')\n","    pre_resnet_filter5 = left_filter_def(1,(2*128),128,name='pre_resnet_filter5')\n","    resnet_filter5 = left_filter_def(3,128,128,name='pre_resnet_filter5')\n","    \n","    \n","    \n","    '''last_up'''\n","    lastup_deconv_filter1 = right_filter_def(3,128,64,name='lastup_deconv_filter1')\n","    lastup_deconv_filter2 = right_filter_def(3,64,32,name='lastup_deconv_filter2')\n","    lastup_conv_filter1 = left_filter_def(3,32,64,name='lastup_conv_filter1')\n","    lastup_conv_filter2 = left_filter_def(3,64,32,name='lastup_conv_filter2')\n","    lastup_deconv_filter3 = right_filter_def(3,32,16,name='lastup_deconv_filter1')\n","    lastup_deconv_filter4 = right_filter_def(3,16,8,name='lastup_deconv_filter2')\n","    '''mid_up'''\n","    midup_deconv_filter1 = right_filter_def(3,32,16,name='midup_deconv_filter1')\n","    midup_conv_filter1 = left_filter_def(3,16,16,name='midup_conv_filter1')\n","    midup_conv_filter2 = left_filter_def(3,16,16,name='midup_conv_filter2')\n","    midup_deconv_filter2 = right_filter_def(3,16,8,name='midup_deconv_filter2')\n","    '''final_meet'''\n","    filter11 = left_filter_def(1,(8*3),8,name='filter11')\n","    pre_resnet_filter6 = left_filter_def(3,8,8,name='pre_resnet_filter6')\n","    resnet_filter6 = left_filter_def(3,8,8,name='pre_resnet_filter6')\n","    filter12 = left_filter_def(1,8,4,name='filter12')\n","    \n","    \n","    \n","    with tf.name_scope(\"BLOCK1\"):\n","        '''BLOCK1'''\n","        CNN1 = Conv_layer(X,filter1,stride=1,activation='relu',name='CNN1')\n","        #print (\"CNN1\",np.shape(CNN1))\n","        CNN2 = Conv_layer(CNN1,filter2,stride=1,activation='relu',name='CNN2')\n","        #print (\"CNN2\",np.shape(CNN2))\n","        pre_CNN1 = Conv_layer(CNN2,pre_resnet_filter1,stride=1,activation='relu',name='pre_resnet_filter1CNN2')\n","        resnet_CNN1 = tf.add(Conv_layer(pre_CNN1,resnet_filter1,stride=1,activation='relu'),CNN1,name='resnet_filter1CNN2')\n","        batch_norm1 = tf.layers.batch_normalization(resnet_CNN1, training=training, momentum=0.9, name=\"batch_norm\")\n","        pool1 = tf.nn.max_pool3d(resnet_CNN1,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID',name='POOL1')\n","    \n","    with tf.name_scope(\"BLOCK2\"):\n","        '''BLOCK2'''\n","        CNN3 = Conv_layer(pool1,filter3,stride=1,activation='relu',name='CNN3')\n","        #print (\"CNN3\",np.shape(CNN3))\n","        CNN4 = Conv_layer(CNN3,filter4,stride=1,activation='relu',name='CNN4')\n","        #print (\"CNN4\",np.shape(CNN4))\n","        pre_CNN2 = Conv_layer(CNN4,pre_resnet_filter2,stride=1,activation='relu',name='pre_resnet_filter2CNN2')\n","        resnet_CNN2 = tf.add(Conv_layer(pre_CNN2,resnet_filter2,stride=1,activation='relu'),CNN3,name='resnet_filter2CNN2') \n","\n","        pool2 = tf.nn.max_pool3d(resnet_CNN2,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID',name='POOL2')\n","    \n","    with tf.name_scope(\"BLOCK3\"):\n","        '''BLOCK3'''\n","        CNN5 = Conv_layer(pool2,filter5,stride=1,activation='relu',name='CNN5')\n","        #print (\"CNN5\",np.shape(CNN5))\n","        CNN6 = Conv_layer(CNN5,filter6,stride=1,activation='relu',name='CNN6')\n","        #print (\"CNN6\",np.shape(CNN6))\n","        pre_CNN3 = Conv_layer(CNN6,pre_resnet_filter3,stride=1,activation='relu',name='pre_resnet_filter3CNN2')\n","        resnet_CNN3 = tf.add(Conv_layer(pre_CNN3,resnet_filter3,stride=1,activation='relu'),CNN5,name='resnet_filter3CNN2')\n","        pool3 = tf.nn.max_pool3d(resnet_CNN3,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID',name='POOL3')\n","    \n","    with tf.name_scope(\"BLOCK4\"):\n","        '''BLOCK4'''\n","        CNN7 = Conv_layer(pool3,filter7,stride=1,activation='relu',name='CNN7')\n","        #print (\"CNN7\",np.shape(CNN7))\n","        CNN8 = Conv_layer(CNN7,filter8,stride=1,activation='relu',name='CNN8')\n","        #print (\"CNN8\",np.shape(CNN8))\n","        pre_CNN4 = Conv_layer(CNN8,pre_resnet_filter4,stride=1,activation='relu',name='pre_resnet_filter4CNN2')\n","        resnet_CNN4 = tf.add(Conv_layer(pre_CNN4,resnet_filter4,stride=1,activation='relu'),CNN7,name='resnet_filter4CNN2')\n","\n","        pool4 = tf.nn.max_pool3d(resnet_CNN4,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID',name='POOL4')\n","    \n","    with tf.name_scope(\"BLOCK5\"):\n","        '''BLOCK5'''\n","        CNN9 = Conv_layer(pool4,filter9,stride=1,activation='relu',name='CNN9')\n","        #print (\"CNN9\",np.shape(CNN9))\n","        CNN10 = Conv_layer(CNN9,filter10,stride=1,activation='relu',name='CNN10')\n","        pre_CNN5 = Conv_layer(CNN10,pre_resnet_filter5,stride=1,activation='relu',name='pre_resnet_filter5CNN2')\n","        resnet_CNN5 = tf.add(Conv_layer(pre_CNN5,resnet_filter5,stride=1,activation='relu'),CNN9,name='resnet_filter5CNN2')\n","        \n","        #print (\"CNN10\",np.shape(CNN10))\n","        \n","    with tf.name_scope(\"mid_up\"):\n","        \n","        '''DECONVOLUTION'''\n","        midup_deconv1 = Deconv_layer(resnet_CNN3,midup_deconv_filter1,stride=2,activation='relu',name='midup_DE_CONV1')\n","        '''MID_RESNET'''\n","        Mid_resnet1 = Conv_layer(midup_deconv1,midup_conv_filter1,stride=1,activation='relu',name='mid_resnet1')\n","        Mid_resnet2 = tf.add(Conv_layer(Mid_resnet1,midup_conv_filter2,stride=1,activation='relu',name='mid_resnet2'),midup_deconv1)\n","        '''Deconvolution'''\n","        midup_deconv2 = Deconv_layer(Mid_resnet2,midup_deconv_filter2,stride=2,activation='relu',name='midup_DE_CONV2')\n","        \n","        \n","    with tf.name_scope(\"last_up\"):\n","        \n","        '''DECONVOLUTION'''\n","        lastup_deconv1 = Deconv_layer(resnet_CNN5,lastup_deconv_filter1,stride=2,activation='relu',name='lastup_DE_CONV1')\n","        lastup_deconv2 = Deconv_layer(lastup_deconv1,lastup_deconv_filter2,stride=2,activation='relu',name='lastup_DE_CONV2')\n","        '''MID_RESNET'''\n","        Mid_resnet3 = Conv_layer(lastup_deconv2,lastup_conv_filter1,stride=1,activation='relu',name='mid_resnet1')\n","        Mid_resnet4 = tf.add(Conv_layer(Mid_resnet3,lastup_conv_filter2,stride=1,activation='relu',name='mid_resnet2'),lastup_deconv2)\n","        \n","        lastup_deconv3 = Deconv_layer(Mid_resnet4,lastup_deconv_filter3,stride=2,activation='relu',name='lastup_DE_CONV3')\n","        lastup_deconv4 = Deconv_layer(lastup_deconv3,lastup_deconv_filter4,stride=2,activation='relu',name='lastup_DE_CONV4')\n","        \n","        \n","    with tf.name_scope(\"final_layer\"):\n","        concat1 = tf.concat([lastup_deconv4,midup_deconv2,resnet_CNN1],axis=4,name='CONCAT4')\n","        CNN_depth = Conv_layer(concat1,filter11,stride=1,activation='relu',name='CNN_depth')\n","        batch_norm = tf.layers.batch_normalization(CNN_depth, training=training, momentum=0.9, name=\"batch_norm\")\n","        pre_CNN6 = Conv_layer(batch_norm,pre_resnet_filter6,stride=1,activation='relu',name='pre_resnet_filter6')\n","        resnet_CNN6 = tf.add(Conv_layer(pre_CNN6,resnet_filter6,stride=1,activation='relu'),batch_norm,name='resnet_filter6')\n","        final_CNN = Conv_layer(resnet_CNN6,filter12,stride=1,activation='softmax',name='CNN_depth2')\n","        \n","    return(final_CNN)\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8VWIc00uslsC","colab_type":"code","colab":{}},"source":["def chose_train_restore(learning_rate =0.0001,n_epochs = 100):\n","    output_dir = \"/content/gdrive/My Drive/Brain_Tumour_segmentation/all_in_one/Wnet_dice_focal/saving_model\"\n","    model_checkpoint_file_base = os.path.join(output_dir, \"model.ckpt\")\n","\n","    \n","    if not os.path.exists(model_checkpoint_file_base + \".meta\"):\n","        '''FIRST TIME TRAINING'''\n","        print(\"Making new\")\n","        brand_new = True\n","        \n","        prediction = predict_model1(X)#logits\n","        '''----------------------------------------------------------------------------------------------------------------------------------------------------------------'''\n","        with tf.name_scope(\"LOSS_FUNCTION\"):\n","            '''using multi dimensional dice'''\n","            hot_y = hot_encode(y)\n","            #dice = 1+ dice_coef_multilabel(hot_y,prediction)     #dice loss for verison 1\n","            #dice = generalized_dice_coeff(hot_y[:,:,:,:,0], prediction)\n","            #focal = generalized_focal_loss(hot_y[:,:,:,:,0], prediction)\n","            #hybrid,dice,focal,sep = find_hybrid_loss(hot_y[:,:,:,:,:,0], prediction, gamma=0.9,alpha=0.8)\n","            #mean_error = ddice_coeffiff_error(hot_y[:,:,:,:,0], prediction)\n","            main_loss,dice,focal = hybrid_loss(hot_y[:,:,:,:,:,0], prediction,gamma=0.9)\n","        '''----------------------------------------------------------------------------------------------------------------------------------------------------------------'''\n","        with tf.name_scope(\"COST_FUNCTION\"):\n","            '''Cost function''''''Remember to change max to min min to mx depending on loss function'''\n","            loss = tf.reduce_mean(main_loss, name=\"loss\")\n","\n","        saver = tf.train.Saver()\n","        \n","    else:\n","        '''RESTORED MODEL'''\n","        print(\"Reloading existing\")\n","        brand_new = False\n","        saver = tf.train.import_meta_graph(model_checkpoint_file_base + \".meta\")\n","        g = tf.get_default_graph()\n","        \n","        #sep = g.get_tensor_by_name(\"LOSS_FUNCTION/mse_loss:0\")\n","        dice = g.get_tensor_by_name(\"LOSS_FUNCTION/dice_coeff:0\")\n","        focal = g.get_tensor_by_name(\"LOSS_FUNCTION/focal_loss:0\")\n","        #hybrid = g.get_tensor_by_name(\"LOSS_FUNCTION/hybrid_loss:0\")\n","        main_loss = g.get_tensor_by_name(\"LOSS_FUNCTION/final_loss:0\")\n","        prediction = g.get_tensor_by_name(\"final_layer/Softmax:0\") \n","        loss = g.get_tensor_by_name(\"COST_FUNCTION/loss:0\")\n","        \n","        X = g.get_tensor_by_name(\"input_image:0\")\n","        y = g.get_tensor_by_name(\"hot_encode_label:0\")\n","        training = g.get_tensor_by_name(\"training:0\")\n","\n","    \n","    \n","    \n","    '''TRAINING'''\n","    '''starting session'''\n","    gpu_option = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n","    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_option)) as sess:\n","        '''Initializing optimizer'''\n","        if brand_new:\n","            optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n","            init = tf.global_variables_initializer()\n","            sess.run(init)\n","            tf.add_to_collection(\"optimizer\", optimizer)\n","        else:\n","            saver = tf.train.Saver()\n","            saver.restore(sess, model_checkpoint_file_base)\n","            optimizer = tf.get_collection(\"optimizer\")[0]\n","\n","        for epoch in range(19,n_epochs):\n","            current_batch_no = 0\n","            permute_mat = 0\n","            iteration = 0\n","            while(1):\n","                #with tf.device('/cpu:0'):\n","                epoch_x,epoch_y,current_batch_no,permute_mat,last = random_h5py_batch(current_batch_no,permute_mat,)\n","                sess_results = sess.run(optimizer, feed_dict={X: epoch_x, y: epoch_y, training: True})\n","                #print (\"epoch\",epoch+1,\"batch\",iteration+1)#,\"Cost\",sess_results[0])\n","                \n","                '''DICE Coefficient for iteration'''\n","                #with tf.device('/cpu:0'):\n","                if iteration%10==0:\n","                    #acc_train = 1-(dice.eval(feed_dict={X: epoch_x, y: epoch_y}))\n","                    train_loss,train_dice,train_focal = sess.run([main_loss,dice,focal], feed_dict={X: epoch_x, y: epoch_y, training: True})\n","                    test_images, test_labels = test_batch()\n","                    #acc_test = 1-(dice.eval(feed_dict={X: test_images, y: test_labels}))\n","                    test_loss,test_dice,test_focal = sess.run([main_loss,dice,focal], feed_dict={X: test_images, y: test_labels, training: True})\n","                    print(\"Minibatch at\",\"Epoch\", epoch+1,\"batch\",iteration+1, \"Train Loss:\", train_loss, \"Train Dice Coeff\",train_dice,\"Train Focal Loss\",train_focal,\"Test Loss:\", test_loss, \"Test Dice Coeff\",test_dice,\"Test Focal Loss\",test_focal)\n","                    #print(\"After Epoch\", epoch+1, \"Hybrid Train accuracy:\", 1-hybrid_train, \"Dice Train accuracy:\", 1-dice_train, \"Focal Train accuracy:\", 1-focal_train, \"MSE Train accuracy:\", 1-diff_train)\n","                if last ==1:\n","                    break\n","                iteration +=1\n","            test_images, test_labels = test_batch()\n","            #hybrid_test,dice_test,focal_test,diff_test = sess.run([hybrid,dice,focal,sep], feed_dict={X: test_images, y: test_labels})\n","            #diff_test = sess.run(dice, feed_dict={X: test_images, y: test_labels})\n","            test_loss,test_dice,test_focal = sess.run([main_loss,dice,focal], feed_dict={X: test_images, y: test_labels, training: False})\n","            print(\"-------------------------------------------------------------------------------------------------------\")\n","            #print(\"After Epoch\", epoch+1, \"Hybrid Test accuracy:\", 1-hybrid_test, \"Dice Test accuracy:\", 1-dice_test, \"Focal Test accuracy:\", 1-focal_test, \"MSE Test accuracy:\", 1-diff_test)\n","            print(\"After Epoch\", epoch+1,\"Test Loss:\", test_loss, \"Test Dice Coeff\",test_dice,\"Test Focal Loss\",test_focal)\n","            print(\"-------------------------------------------------------------------------------------------------------\")\n","            '''saving model after each epoch'''\n","            save_path = tf.train.Saver(max_to_keep=1).save(sess, model_checkpoint_file_base)\n","            \n","            if epoch % 1 == 0:\n","                test_example =   test_images\n","                test_example_gt = test_labels#np.rollaxis(test_labels,2,0)\n","                sess_results = sess.run(prediction,feed_dict={X:test_example})\n","\n","                sess_results = sess_results[0,100,:,:,1] + (2*sess_results[0,100,:,:,2]) + (3*sess_results[0,100,:,:,3])\n","                test_example = test_example[0,100,:,:,3]\n","                test_example_gt = test_example_gt[0,100,:,:,:]\n","                \n","                plt.figure()\n","                plt.imshow(np.squeeze(test_example),cmap='gray')\n","                plt.axis('off')\n","                plt.title('Original Image')\n","                plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/all_in_one/Wnet_dice_focal/result/'+str(epoch)+\"a_Original_Image.png\")\n","                 \n","                plt.figure()\n","                plt.imshow(np.squeeze(test_example_gt),cmap='gray')\n","                plt.axis('off')\n","                plt.title('Ground Truth Mask')\n","                plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/all_in_one/Wnet_dice_focal/result/'+str(epoch)+\"b_Original_Mask.png\")\n","\n","                plt.figure()\n","                plt.imshow(np.squeeze(sess_results),cmap='gray')\n","                plt.axis('off')\n","                plt.title('Generated Mask')\n","                plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/all_in_one/Wnet_dice_focal/result/'+str(epoch)+\"c_Generated_Mask.png\")\n","\n","                plt.close('all')\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sIDXJRhzqbNn","colab_type":"text"},"source":["COMMENTS ON DICE LOSS AND ACCURACY\n","\n","1. Under the name_scope \"LOSS FUNCTION\", the variable named dice corresponds to dice loss and since the function dice_multipleclass() returns a value between -1 and 0(both included) , we add 1. Also another reason for this is there is no maximize function in adam optimizer(or any other optimizing function).\n","\n","2. While printing  the accuracy (everywhere)  we have to print dice coefficient and not dice loss therefore we add 1 to the dice_loss calculation"]},{"cell_type":"code","metadata":{"id":"vLp7SRmzT6Jp","colab_type":"code","outputId":"c883e342-a821-4e95-e1c1-9afc8c8632ae","executionInfo":{"status":"error","timestamp":1558293168946,"user_tz":-330,"elapsed":32322,"user":{"displayName":"dwijay shanbhag","photoUrl":"","userId":"10252205309947413859"}},"colab":{"base_uri":"https://localhost:8080/","height":584}},"source":["chose_train_restore()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Reloading existing\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Brain_Tumour_segmentation/all_in_one/Wnet_dice_focal/saving_model/model.ckpt\n"],"name":"stdout"},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-1aedf54d4167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchose_train_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-e606460ed89a>\u001b[0m in \u001b[0;36mchose_train_restore\u001b[0;34m(learning_rate, n_epochs)\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0;31m#acc_train = 1-(dice.eval(feed_dict={X: epoch_x, y: epoch_y}))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_focal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfocal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0;31m#acc_test = 1-(dice.eval(feed_dict={X: test_images, y: test_labels}))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_focal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfocal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-7531812866cf>\u001b[0m in \u001b[0;36mtest_batch\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpermute_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m155\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m155\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m155\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mread_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.read\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.dset_rw\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.H5PY_H5Dread\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Can't read data (file read failed: time = Sun May 19 19:12:52 2019\n, filename = '/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_image.hdf5', file descriptor = 70, errno = 5, error message = 'Input/output error', buf = 0x14e49b80, total read size = 604, bytes this sub-read = 604, bytes actually read = 18446744073709551615, offset = 4325994443)"]}]}]}