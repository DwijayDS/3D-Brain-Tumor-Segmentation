{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Resnet_dice_focal_mse_loss.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RIqV48zuBpwM","colab_type":"text"},"source":["\"\"\"\n","COMPLETELY NEW VERSION OF UNET DESIGNED FOR BRAIN TUMOUR SEGMENTATION\n","\n","SPECS:\n","\n","1. Input size  is 240x240x4 for each image\n","\n","2. BRATS dataset \n","\n","3. DICE LOSS IS TAKEN AS A LOSS FUNCTION\n","\n","4. MULTICLASS SEGMENTATION HAS BEEN IMPLEMENTED\n","\n","\n","DESC:\n","\n","HERE OUR PREDICTION WILL HAVE 4 DIMENSIONS(because we have 4 classes) FOR EACH IMAGE. THESE 4 PREDICTIONS are compared with hot encoded label(Ground truth)\n","THIS IN A WAY TRAINS THE SYSTEM TO HOT ENCODE THE PREDICTIONS TOO.\n","WE ARE TRYING TO IMPLEMENT THE ABOVE STATED MODEL TO IMPLEMENT MULTICLASS SEGEMENTATION. BUT HAD TO CHANGE SOME THINGS WHICH ARE STATED BELOW\n","\n","PROBLEMS AND CHANGES:\n","\n","1. Faced the problem of class imbalance. So in this version we multiply dice coefficient for each class with certain weight. this weight is reciprocal of the frequency of that class\n","\n","2. The problem of class imbalance still persists and dice coeff is more than 1. So i this version we have implemented a new dice coefficient function.\n","\n","\n","FUTURE:\n","\n","1. IMPROVING DICE COEFFICIENT\n","\n","2. 3D IMPLEMENTATION\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"eSGVMeVbibw0","colab_type":"code","outputId":"3bb99f5f-24d2-4b5b-ffa2-8e0d07e10686","executionInfo":{"status":"ok","timestamp":1559999678170,"user_tz":-330,"elapsed":1500,"user":{"displayName":"DWIJAY SHANBHAG","photoUrl":"","userId":"01321982494498435915"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["'''Mounting Google Drive on the Colab notebook'''\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hxotR3CiirGu","colab_type":"code","colab":{}},"source":["#file_image = '/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_image.hdf5'\n","import h5py\n","#dataset has data of 484 patients. (155 images of each patient)\n","#data is extracted using 4 different techniques\n","#size of data of 1 patient is [240,240,155,4]\n","#for 2D segmentation we stack in 3rd dimension (axis=2)\n","#train_image\n","image_store = h5py.File(\"/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_image.hdf5\", \"r\")\n","#train_labels\n","label_store = h5py.File(\"/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_label.hdf5\", \"r\")\n","train_images = image_store[\"image\"]\n","train_labels = label_store[\"label\"]\n","#print('hi')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RIkjuDek_v5Q","colab_type":"code","colab":{}},"source":["'''IMPORTING LIBRARIES'''\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import time\n","import math\n","import os\n","'''Clearing tesorflow computation graph'''\n","tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SAFj-oXR_0Rs","colab_type":"code","colab":{}},"source":["'''DEFINING VARIABLES'''\n","\n","batch_size=1              #batch size taken at a time\n","n_class = 4                #number of classes in the label\n","\n","'''PLACEHOLDER for input and output of UNET'''\n","'''Here we crop the 155x240x240 image to  160x160x192 by repeating the last layer 5 times to convert 155 to 160'''\n","#X = tf.placeholder(shape=[None,160,160,192,4], dtype=tf.float32, name='input_image')\n","#y = tf.placeholder(shape=[None,160,160,192,1], dtype=tf.int64, name='hot_encode_label')\n","#training = tf.placeholder_with_default(False, shape = (), name = 'training')\n","#gamma = tf.placeholder(shape=[], dtype=tf.float32, name=\"dice_weight\")\n","#alpha = tf.placeholder(shape=[], dtype=tf.float32, name=\"mse_focal_weight\")\n","#learning_rate = tf.placeholder(shape=[], dtype=tf.float32, name=\"learning_rate\")\n","\n","\n","'''Batch variable exraction from h5py file (used by functions 'rnadom_h5py_batch' and 'test_batch')'''\n","out_img = np.empty((240,240,batch_size*155,4),dtype=np.float32)\n","out_label = np.empty((240,240,batch_size*155,1),dtype=np.int64)\n","\n","'''parameter constants'''\n","#LR = np.array([0.0001])\n","#gm = np.array([0.9])\n","#al = np.array([0.5])\n","LR = 0.0001\n","gm = 0.9\n","al = float(0.6)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"re3MWWJHLxuD","colab_type":"text"},"source":["DEFINING ALL THE REQUIRED FUNCTIONS"]},{"cell_type":"code","metadata":{"id":"No2sukbcBnCm","colab_type":"code","colab":{}},"source":["'''COMPUTATION GRAPH Function Definitions'''\n","\n","\n","def left_filter_def(ker_size,in_chan,out_chan,name='left_filter'):\n","    '''Defining a filter variable to perform convolution'''\n","    stddev = np.sqrt(4/(ker_size*ker_size*ker_size*ker_size*in_chan*out_chan))           #HE initialization\n","    if stddev < 0.0008:\n","        stddev = 0.0008\n","    return (tf.Variable(tf.truncated_normal([ker_size,ker_size,ker_size,in_chan,out_chan],stddev=stddev),name=name))\n","\n","\n","def right_filter_def(ker_size,in_chan,out_chan,name='right_filter'):\n","    '''Defining a filter variable to perform transpose convolution'''\n","    stddev = np.sqrt(4/(ker_size*ker_size*ker_size*ker_size*in_chan*out_chan))\n","    if stddev < 0.0008:\n","        stddev = 0.0008\n","    return (tf.Variable(tf.truncated_normal([ker_size,ker_size,ker_size,out_chan,in_chan],stddev=stddev),name=name))\n","\n","\n","def Conv_layer(input_im,filter_mask,stride,activation='None',name='conv'):\n","    '''Function to perform Convolution and apply activation filter'''\n","    '''Convolution'''\n","    conv = tf.nn.conv3d(input_im,filter_mask,strides = [1,stride,stride,stride,1], padding = \"SAME\",name=name)\n","    #norm_conv = tf.layers.batch_normalization(conv, training=training, momentum=0.9)\n","    '''Activation'''\n","    if activation == 'relu':\n","        return(tf.nn.relu(conv))\n","    elif activation == 'softmax':\n","        return(tf.nn.softmax(conv,axis=-1))\n","    elif activation == 'elu':\n","        return(tf.nn.elu(conv))\n","    else:\n","        #activation == 'None'\n","        return(conv)\n","    \n","\n","def Deconv_layer(input_im,filter_mask,stride,activation='None',name='De_conv'):\n","    '''Function to perform Transpose Convolution and apply activation filter'''\n","    '''Transpose Convolution'''\n","    inp_shape = np.shape(input_im) #tf.shape()\n","    out_shape = [batch_size]+[int(inp_shape[1].value*2), int(inp_shape[2].value*2),int(inp_shape[3].value*2), int(inp_shape[4].value/2)]\n","    \n","    conv = tf.nn.conv3d_transpose(input_im, filter_mask, out_shape, strides = [1,stride,stride,stride,1], padding = \"SAME\",name=name)\n","    #norm_conv = tf.layers.batch_normalization(conv, training=training, momentum=0.9)\n","    '''Activation'''\n","    if activation == 'relu':\n","        return(tf.nn.relu(conv))\n","    elif activation == 'softmax':\n","        return(tf.nn.softmax(conv,axis=-1))\n","    elif activation == 'elu':\n","        return(tf.nn.elu(conv))\n","    else:\n","        #activation == 'None'\n","        return(conv)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K2tyXeDFbpMy","colab_type":"code","colab":{}},"source":["'''Functions for batch Extraction and pre processing'''\n","\n","def normalizing_input():\n","    '''normalization of each input channels'''\n","    global out_img\n","    '''CHANNEL INFO'''\n","    # maximum value found using function called \"Finding_maximum_to_normalise \"\n","    #'''max value for dimension 4 is 5337.0'''\n","    #'''max value for dimension 3 is 11737.0'''\n","    #'''max value for dimension 2 is 9751.0'''\n","    #'''max value for dimension 1 is 6476.0'''\n","    out_img[:,:,:,0] = out_img[:,:,:,0]/6476.0\n","    out_img[:,:,:,1] = out_img[:,:,:,1]/9751.0\n","    out_img[:,:,:,2] = out_img[:,:,:,2]/11737.0\n","    out_img[:,:,:,3] = out_img[:,:,:,3]/5337.0\n","    \n","    \n","\n","def crop_image_fit_brain(in_image):\n","    '''cropping size was found using the code finding_brain.ipynb'''\n","    left = 19\n","    right= 210\n","    top  = 38\n","    bot  = 199\n","    out_image = in_image[top:(bot-1),left:(right+1),:,:]\n","    return (out_image)\n","\n","\n","def Pre_processing_3D(a):\n","    '''Function to roll axis to convert array into[depth,width,height,channels] and the divide it in batches'''\n","    #print(np.shape(a))\n","    b = np.rollaxis(a,2, 0)\n","    #print(np.shape(b))\n","    #image shape\n","    out_arr = np.empty(shape=[batch_size,160,np.shape(b)[1],np.shape(b)[2],np.shape(b)[3]])\n","    for i in range(batch_size):\n","        start = i*155\n","        end = start+155\n","        out_arr[i,0:155,:,:,:] = b[start:end,:,:,:]\n","    \n","    a = [out_arr[:,154:155,:,:,:]]*5\n","    out_arr[:,155:160,:,:,:] = a[0]\n","    \n","    '''clippig data from front of each batch'''\n","    '''to fit the model we remove first 3 slices of each batch'''\n","    '''shape of a is [batch_size,depth,width,height,channels]'''\n","    out_send = out_arr[:,:,:,:,:]\n","    #print(\"arr\",np.shape(out_arr),\"send\",np.shape(out_send))\n","    return (out_send)\n","\n","def random_rotate(in_image,in_label):\n","    \n","    check = np.random.random(1)[0]\n","    if check<0.25:\n","        out_image = in_image[:,:,::-1,:,:]\n","        out_lab = in_label[:,:,::-1,:,:]\n","        \n","    elif check<0.50:\n","        \n","        out_image = in_image[:,:,:,::-1,:]\n","        out_lab = in_label[:,:,:,::-1,:]\n","        \n","    elif check<0.75:\n","        \n","        out_image = in_image[:,::-1,:,:,:]\n","        out_lab = in_label[:,::-1,:,:,:]\n","        \n","    else:\n","        out_image =in_image\n","        out_lab = in_label\n","    \n","    return (out_image,out_lab)\n","\n","\n","\n","def random_h5py_batch(current_batch_no,permute_mat):\n","    '''Function to take batches randomly'''\n","    global out_img\n","    global out_label\n","    \n","    '''training info'''\n","    train_info = 380  #100 patients with 155 images each\n","\n","    if current_batch_no == 0:\n","        no_of_batches = train_info//batch_size  \n","        permute_mat = np.random.permutation(no_of_batches)\n","    \n","    start = permute_mat[current_batch_no]*batch_size*155\n","    end = start + (batch_size*155)\n","    train_images.read_direct(out_img,np.s_[:,:,start:end,:])\n","    train_labels.read_direct(out_label,np.s_[:,:,start:end,:])\n","    current_batch_no += 1\n","    #print(len(out_img))\n","    '''Input normalization'''\n","    normalizing_input()\n","    '''normalization oof labels'''\n","    #out_label = out_label\n","    #normalizing_label()\n","    '''converting multi class to dual class'''\n","    #out_label = convert_dual_class(out_label)\n","    '''cropping image and labels'''\n","    crop_out_image = crop_image_fit_brain(out_img)\n","    crop_out_label = crop_image_fit_brain(out_label)\n","    '''Rolling axes'''\n","    #out_img_send = np.rollaxis(crop_out_image,2, 0)\n","    '''hot encoding'''\n","    #out_label_send = crop_out_label\n","    '''3D conversion'''\n","    out_img_send = Pre_processing_3D(crop_out_image)\n","    out_label_send = Pre_processing_3D(crop_out_label)\n","    '''Data augmentation rotation'''\n","    #out_img_send,out_label_send = random_rotate(out_img_send,out_label_send)\n","     \n","    last=0\n","    if current_batch_no == len(permute_mat):\n","        last=1\n","    \n","    return (out_img_send,out_label_send,current_batch_no,permute_mat,last)\n","\n","def test_batch():\n","    '''Function to take next test batch''' \n","    global out_img\n","    global out_label\n","    \n","    '''training and testing info'''\n","    train_info = 380  #100 patients with 155 images each\n","    test_info = 484-train_info  #100 patients with 155 images each\n","    \n","    no_of_batches = test_info//batch_size  \n","    permute_mat = np.random.permutation(no_of_batches)\n","    start = (permute_mat[0]*batch_size*155) +(train_info*155)\n","    end = start + (155*batch_size)\n","    train_images.read_direct(out_img,np.s_[:,:,start:end,:])\n","    train_labels.read_direct(out_label,np.s_[:,:,start:end,:])\n","    \n","    '''normalization'''\n","    normalizing_input()\n","    #normalizing_label()\n","    '''croping images and labels'''\n","    crop_out_image = crop_image_fit_brain(out_img)\n","    crop_out_label = crop_image_fit_brain(out_label) \n","    '''3D processing'''\n","    out_img_send = Pre_processing_3D(crop_out_image)\n","    out_label_send = Pre_processing_3D(crop_out_label)\n","    \n","    return (out_img_send,out_label_send)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-NTV_zXbaY7","colab_type":"code","colab":{}},"source":["\n","  \n","def hot_encode(check_image,depth=n_class,name='hot_encode'):\n","    '''function for hot encoding images'''\n","    a = tf.one_hot(indices = check_image, depth=depth,name=name)\n","    b = tf.transpose(a,perm=[0,1,2,3,5,4])\n","    return b\n","\n","#############################################################################################################################\n","#GENERALIZED DICE LOSS FUNCTION\n","#############################################################################################################################\n","def generalized_dice_coeff(y_true, y_pred):\n","    Ncl = y_pred.shape[-1]\n","    print(Ncl)\n","    w = np.zeros(shape=(Ncl,))\n","    w = tf.reduce_sum(y_true, axis=[0,1,2,3]) + 1\n","    print(np.shape(w))\n","    w = 1/((w**2))\n","    print(np.shape(w))\n","    # Compute gen dice coef:\n","    numerator = tf.reduce_sum(y_true*y_pred, axis=[0,1,2,3])\n","    denominator = tf.reduce_sum(y_true+y_pred, axis=[0,1,2,3])\n","    num=den=0\n","    for i in range(np.shape(w)[0]):\n","        num += w[i]*numerator[i]\n","        den += w[i]*denominator[i]\n","            \n","    #num = tf.reduce_sum(a)\n","    #den = tf.reduce_sum(b)\n","    num = num + 0.000000001\n","    den = den + 0.000000001\n","\n","    gen_dice_coef = tf.identity(tf.divide((2*num),den),name='dice_coeff')\n","\n","    return (gen_dice_coef)\n","#############################################################################################################################\n","#GENERALIZED FOCAL LOSS FUNCTION\n","#############################################################################################################################\n","def generalized_focal_loss(y_true, y_pred, gamma=2.0, alpha=0.25):\n","    \n","    Ncl = y_pred.shape[-1]\n","    w = np.zeros(shape=(Ncl,))\n","    w = tf.reduce_sum(y_true, axis=[0,1,2,3]) + 1\n","    w = 1/((w))\n","    y_pred = y_pred + 0.000000001                                               #to ensure that logarithm in next step doenst give math error\n","    \n","    ce = tf.multiply(y_true, -tf.log(y_pred))                                   #cross entropy (multiclass)\n","    fl_var = tf.multiply(y_true, tf.pow(tf.subtract(1., y_pred), gamma))        #focal loss variables (gamma*(1-pt)*(graund_truth))\n","    #fl = tf.multiply(alpha, tf.multiply(fl_var, ce))\n","    fl = tf.multiply(fl_var, ce)\n","    #fl=ce\n","    final = tf.reduce_sum(fl, axis=[0,1,2,3])\n","    normalized_focal = 0\n","    \n","    for i in range(np.shape(w)[0]):\n","        #print(i)\n","        #a = w[i]#/tf.reduce_sum(w)\n","        #b = fl[:,:,:,:,i]\n","        #c = (b)/(tf.reduce_max(b)+1)\n","        #normalized_focal += tf.reduce_sum(a*b)\n","        #b += w[i]*denominator[:,:,:,i]\n","        normalized_focal += w[i]*final[i]\n","    weighted_focal = tf.divide(normalized_focal,4.0,name='focal_loss')\n","    return (weighted_focal)\n","#############################################################################################################################\n","#GENERALIZED Mean Square Error FUNCTION\n","#############################################################################################################################\n","def diff_error(y_true, y_pred):\n","    error = tf.square(y_true-y_pred)\n","    print (np.shape(error))\n","    a = tf.reduce_mean(error[:,:,:,:,0])\n","    b = tf.reduce_mean(error[:,:,:,:,1])\n","    c = tf.reduce_mean(error[:,:,:,:,2])\n","    d = tf.reduce_mean(error[:,:,:,:,3])\n","    e = (a+(1*b)+(2*c)+(3*d))/4\n","    print (np.shape(e))\n","    return tf.identity(e, name='mse_loss')\n","#############################################################################################################################\n","#LOSS FUNCTION\n","#############################################################################################################################\n","def hybrid_loss(y_true, y_pred, gamma=0.9, alpha=0.5):\n","    dice = generalized_dice_coeff(y_true, y_pred)\n","    focal = generalized_focal_loss(y_true, y_pred)\n","    #update = (gamma*dice) + ((1-gamma)*focal)\n","    MeanAndSquare = diff_error(y_true, y_pred)\n","    part1 = (gamma*(1-dice))\n","    part2 = ((1-gamma)*(((1-alpha)*MeanAndSquare)+(alpha*focal)))\n","    #part2 = ((1-(gamma+alpha))*focal) + (alpha*MeanAndSquare)\n","    final_loss = tf.add(part1,part2,name='final_loss')\n","    return final_loss,dice,focal,MeanAndSquare"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CQCK3RO4L3hl","colab_type":"text"},"source":["INITIALIZING THE MODEL FILTERS"]},{"cell_type":"markdown","metadata":{"id":"mf9Y3JjeMQnI","colab_type":"text"},"source":["DEFINING THE MODEL STRUCTURE"]},{"cell_type":"code","metadata":{"id":"3uIZEngOMVfS","colab_type":"code","colab":{}},"source":["def predict_model1(X):\n","    '''Function to define the UNET model'''\n","    '''MODEL1 Filter definition'''\n","    '''LEFT'''\n","    \n","    filter1 = left_filter_def(3,4,8,name='filter1')\n","    filter2 = left_filter_def(3,8,16,name='filter2')\n","    pre_resnet_filter1 = left_filter_def(1,16,8,name='pre_resnet_filter1')\n","    resnet_filter1 = left_filter_def(3,8,8,name='pre_resnet_filter1')\n","    \n","    filter3 = left_filter_def(3,8,16,name='filter3')\n","    filter4 = left_filter_def(3,16,32,name='filter4')\n","    pre_resnet_filter2 = left_filter_def(1,32,16,name='pre_resnet_filter2')\n","    resnet_filter2 = left_filter_def(3,16,16,name='pre_resnet_filter2')\n","    \n","    \n","    filter5 = left_filter_def(3,16,32,name='filter5')\n","    filter6 = left_filter_def(3,32,64,name='filter6')\n","    pre_resnet_filter3 = left_filter_def(1,64,32,name='pre_resnet_filter3')\n","    resnet_filter3 = left_filter_def(3,32,32,name='pre_resnet_filter3')\n","    \n","    \n","    filter7 = left_filter_def(3,32,64,name='filter7')\n","    filter8 = left_filter_def(3,64,128,name='filter8')\n","    pre_resnet_filter4 = left_filter_def(1,128,64,name='pre_resnet_filter4')\n","    resnet_filter4 = left_filter_def(3,64,64,name='pre_resnet_filter5')\n","    \n","    \n","    filter9 = left_filter_def(3,64,128,name='filter9')\n","    pre_resnet_filter5 = left_filter_def(3,128,128,name='pre_resnet_filter5')\n","    resnet_filter5 = left_filter_def(3,128,128,name='pre_resnet_filter5')\n","    filter10= left_filter_def(3,128,64,name='filter10')\n","    \n","    '''RIGHT'''\n","    \n","    filter11 = right_filter_def(3,128,64,name='filter11')\n","    filter12 = left_filter_def(3,64,64,name='filter12')\n","    resnet_filter6 = left_filter_def(3,64,64,name='pre_resnet_filter6')\n","    filter13 = left_filter_def(3,64,32,name='filter13')\n","    \n","    filter14 = right_filter_def(3,64,32,name='filter14')\n","    filter15 = left_filter_def(3,32,32,name='filter15')\n","    resnet_filter7 = left_filter_def(3,32,32,name='pre_resnet_filter7')\n","    filter16 = left_filter_def(3,32,16,name='filter16')\n","    \n","    filter17 = right_filter_def(3,32,16,name='filter17')\n","    filter18 = left_filter_def(3,16,16,name='filter18')\n","    resnet_filter8 = left_filter_def(3,16,16,name='pre_resnet_filter8')\n","    filter19 = left_filter_def(3,16,8,name='filter19')\n","    \n","    filter20 = right_filter_def(3,16,8,name='filter20')\n","    filter21 = left_filter_def(3,8,8,name='filter21')\n","    resnet_filter9 = left_filter_def(3,8,8,name='pre_resnet_filter8')\n","    filter22 = left_filter_def(3,8,n_class,name='filter22')\n","    \n","    \n","    with tf.name_scope(\"BLOCK1\"):\n","        '''BLOCK1'''\n","        CNN1 = Conv_layer(X,filter1,stride=1,activation='relu',name='CNN1')\n","        #print (\"CNN1\",np.shape(CNN1))\n","        CNN2 = Conv_layer(CNN1,filter2,stride=1,activation='relu',name='CNN2')\n","        #print (\"CNN2\",np.shape(CNN2))\n","        pre_CNN1 = Conv_layer(CNN2,pre_resnet_filter1,stride=1,activation='relu',name='pre_resnet_filter1CNN2')\n","        resnet_CNN1 = tf.add(Conv_layer(pre_CNN1,resnet_filter1,stride=1,activation='relu'),CNN1,name='resnet_filter1CNN2') \n","        pool1 = tf.nn.max_pool3d(resnet_CNN1,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID',name='POOL1')\n","    \n","    with tf.name_scope(\"BLOCK2\"):\n","        '''BLOCK2'''\n","        CNN3 = Conv_layer(pool1,filter3,stride=1,activation='relu',name='CNN3')\n","        #print (\"CNN3\",np.shape(CNN3))\n","        CNN4 = Conv_layer(CNN3,filter4,stride=1,activation='relu',name='CNN4')\n","        #print (\"CNN4\",np.shape(CNN4))\n","        pre_CNN2 = Conv_layer(CNN4,pre_resnet_filter2,stride=1,activation='relu',name='pre_resnet_filter2CNN2')\n","        resnet_CNN2 = tf.add(Conv_layer(pre_CNN2,resnet_filter2,stride=1,activation='relu'),CNN3,name='resnet_filter2CNN2') \n","\n","        pool2 = tf.nn.max_pool3d(resnet_CNN2,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID',name='POOL2')\n","    \n","    with tf.name_scope(\"BLOCK3\"):\n","        '''BLOCK3'''\n","        CNN5 = Conv_layer(pool2,filter5,stride=1,activation='relu',name='CNN5')\n","        #print (\"CNN5\",np.shape(CNN5))\n","        CNN6 = Conv_layer(CNN5,filter6,stride=1,activation='relu',name='CNN6')\n","        #print (\"CNN6\",np.shape(CNN6))\n","        pre_CNN3 = Conv_layer(CNN6,pre_resnet_filter3,stride=1,activation='relu',name='pre_resnet_filter3CNN2')\n","        resnet_CNN3 = tf.add(Conv_layer(pre_CNN3,resnet_filter3,stride=1,activation='relu'),CNN5,name='resnet_filter3CNN2')\n","        pool3 = tf.nn.max_pool3d(resnet_CNN3,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID',name='POOL3')\n","    \n","    with tf.name_scope(\"BLOCK4\"):\n","        '''BLOCK4'''\n","        CNN7 = Conv_layer(pool3,filter7,stride=1,activation='relu',name='CNN7')\n","        #print (\"CNN7\",np.shape(CNN7))\n","        CNN8 = Conv_layer(CNN7,filter8,stride=1,activation='relu',name='CNN8')\n","        #print (\"CNN8\",np.shape(CNN8))\n","        pre_CNN4 = Conv_layer(CNN8,pre_resnet_filter4,stride=1,activation='relu',name='pre_resnet_filter4CNN2')\n","        resnet_CNN4 = tf.add(Conv_layer(pre_CNN4,resnet_filter4,stride=1,activation='relu'),CNN7,name='resnet_filter4CNN2')\n","\n","        pool4 = tf.nn.max_pool3d(resnet_CNN4,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID',name='POOL4')\n","    \n","    with tf.name_scope(\"BLOCK5\"):\n","        '''BLOCK5'''\n","        CNN9 = Conv_layer(pool4,filter9,stride=1,activation='relu',name='CNN9')\n","        #print (\"CNN9\",np.shape(CNN9))\n","        pre_CNN5 = Conv_layer(CNN9,pre_resnet_filter5,stride=1,activation='relu',name='pre_resnet_filter5CNN2')\n","        resnet_CNN5 = tf.add(Conv_layer(pre_CNN5,resnet_filter5,stride=1,activation='relu'),CNN9,name='resnet_filter5CNN2')\n","        CNN10 = Conv_layer(resnet_CNN5,filter10,stride=1,activation='relu',name='CNN10')\n","        #print (\"CNN10\",np.shape(CNN10))\n","    \n","    '''Moving UP'''\n","    \n","    with tf.name_scope(\"BLOCK6\"):\n","        '''BLOCK6'''\n","        concat1 = tf.concat([CNN10,pool4],axis=4,name='CONCAT1')\n","        #print (\"concat1\",np.shape(concat1))\n","        DCNN1= Deconv_layer(concat1,filter11,stride=2,activation='relu',name='DE_CONV1')\n","        #print (\"DCNN1\",np.shape(DCNN1))\n","        CNN11 = Conv_layer(DCNN1,filter12,stride=1,activation='relu',name='CNN11')\n","        #print (\"CNN11\",np.shape(CNN11))\n","        resnet_CNN6 = tf.add(Conv_layer(CNN11,resnet_filter6,stride=1,activation='relu'),DCNN1,name='resnet_filter6CNN2')\n","        CNN12 = Conv_layer(resnet_CNN6,filter13,stride=1,activation='relu',name='CNN12')\n","        #print (\"CNN12\",np.shape(CNN12))\n","    \n","    with tf.name_scope(\"BLOCK7\"):\n","        '''BLOCK7'''\n","        concat2 = tf.concat([CNN12,pool3],axis=4,name='CONCAT2')\n","        #print (\"concat2\",np.shape(concat2))\n","        DCNN2= Deconv_layer(concat2,filter14,stride=2,activation='relu',name='DE_CONV2')\n","        #print (\"DCNN2\",np.shape(DCNN2))\n","        CNN13 = Conv_layer(DCNN2,filter15,stride=1,activation='relu',name='CNN13')\n","        #print (\"CNN13\",np.shape(CNN13))\n","        resnet_CNN7 = tf.add(Conv_layer(CNN13,resnet_filter7,stride=1,activation='relu'),DCNN2,name='resnet_filter7CNN2')\n","        CNN14 = Conv_layer(resnet_CNN7,filter16,stride=1,activation='relu',name='CNN14')\n","        #print (\"CNN14\",np.shape(CNN14))\n","    \n","    with tf.name_scope(\"BLOCK8\"):\n","        '''BLOCK8'''\n","        concat3 = tf.concat([CNN14,pool2],axis=4,name='CONCAT3')\n","        #print (\"concat3\",np.shape(concat3))\n","        DCNN3= Deconv_layer(concat3,filter17,stride=2,activation='relu',name='DE_CONV3')\n","        #print (\"DCNN3\",np.shape(DCNN3))\n","        CNN15 = Conv_layer(DCNN3,filter18,stride=1,activation='relu',name='CNN14')\n","        #print (\"CNN15\",np.shape(CNN15))\n","        resnet_CNN8 = tf.add(Conv_layer(CNN15,resnet_filter8,stride=1,activation='relu'),DCNN3,name='resnet_filter8CNN2')\n","        CNN16 = Conv_layer(resnet_CNN8,filter19,stride=1,activation='relu',name='CNN15')\n","        #print (\"CNN16\",np.shape(CNN16))\n","        \n","    with tf.name_scope(\"BLOCK9\"):\n","        '''BLOCK9'''\n","        concat4 = tf.concat([CNN16,pool1],axis=4,name='CONCAT4')\n","        #print (\"concat4\",np.shape(concat4))\n","        DCNN4= Deconv_layer(concat4,filter20,stride=2,activation='relu',name='DE_CONV4')\n","        #print (\"DCNN4\",np.shape(DCNN4))\n","        CNN17 = Conv_layer(DCNN4,filter21,stride=1,activation='relu',name='CNN17')\n","        #print (\"CNN17\",np.shape(CNN17))\n","        resnet_CNN9 = tf.add(Conv_layer(CNN17,resnet_filter9,stride=1,activation='relu'),DCNN4,name='resnet_filter9CNN2')\n","        CNN18 = Conv_layer(resnet_CNN9,filter22,stride=1,activation='softmax',name='CNN18')\n","        #print (\"CNN18\",np.shape(CNN18))\n","    return (CNN18)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8VWIc00uslsC","colab_type":"code","colab":{}},"source":["def chose_train_restore(n_epochs = 100):\n","    output_dir = \"/content/gdrive/My Drive/Brain_Tumour_segmentation/all_in_one/resnet_dice_focal_mse_loss/saving_model\"\n","    model_checkpoint_file_base = os.path.join(output_dir, \"model.ckpt\")\n","\n","    \n","    if not os.path.exists(model_checkpoint_file_base + \".meta\"):\n","        '''FIRST TIME TRAINING'''\n","        print(\"Making new\")\n","        brand_new = True\n","        \n","        prediction = predict_model1(X)#logits\n","        '''----------------------------------------------------------------------------------------------------------------------------------------------------------------'''\n","        with tf.name_scope(\"LOSS_FUNCTION\"):\n","            '''using multi dimensional dice'''\n","            hot_y = hot_encode(y)\n","            #dice = 1+ dice_coef_multilabel(hot_y,prediction)     #dice loss for verison 1\n","            #dice = generalized_dice_coeff(hot_y[:,:,:,:,0], prediction)\n","            #focal = generalized_focal_loss(hot_y[:,:,:,:,0], prediction)\n","            #hybrid,dice,focal,sep = find_hybrid_loss(hot_y[:,:,:,:,:,0], prediction, gamma=0.9,alpha=0.8)\n","            #mean_error = ddice_coeffiff_error(hot_y[:,:,:,:,0], prediction)\n","            main_loss,dice,focal,mean_error = hybrid_loss(hot_y[:,:,:,:,:,0], prediction,gamma=gamma,alpha=alpha)\n","        '''----------------------------------------------------------------------------------------------------------------------------------------------------------------'''\n","        with tf.name_scope(\"COST_FUNCTION\"):\n","            '''Cost function''''''Remember to change max to min min to mx depending on loss function'''\n","            loss = tf.reduce_mean(main_loss, name=\"loss\")\n","\n","        saver = tf.train.Saver()\n","        \n","    else:\n","        '''RESTORED MODEL'''\n","        print(\"Reloading existing\")\n","        brand_new = False\n","        saver = tf.train.import_meta_graph(model_checkpoint_file_base + \".meta\")\n","        g = tf.get_default_graph()\n","        \n","        mean_error = g.get_tensor_by_name(\"LOSS_FUNCTION/mse_loss:0\")\n","        dice = g.get_tensor_by_name(\"LOSS_FUNCTION/dice_coeff:0\")\n","        focal = g.get_tensor_by_name(\"LOSS_FUNCTION/focal_loss:0\")\n","        #hybrid = g.get_tensor_by_name(\"LOSS_FUNCTION/hybrid_loss:0\")\n","        main_loss = g.get_tensor_by_name(\"LOSS_FUNCTION/final_loss:0\")\n","        prediction = g.get_tensor_by_name(\"BLOCK9/Softmax:0\") \n","        loss = g.get_tensor_by_name(\"COST_FUNCTION/loss:0\")\n","        \n","        X = g.get_tensor_by_name(\"input_image:0\")\n","        y = g.get_tensor_by_name(\"hot_encode_label:0\")\n","        gamma = g.get_tensor_by_name(\"dice_weight:0\")\n","        alpha = g.get_tensor_by_name(\"mse_focal_weight:0\")\n","        learning_rate = g.get_tensor_by_name(\"learning_rate:0\")\n","        #gamma = tf.placeholder(shape=[], dtype=tf.float32, name=\"dice_weight\")\n","        #alpha = tf.placeholder(shape=[], dtype=tf.float32, name=\"mse_focal_weight\")\n","        #learning_rate = tf.placeholder(shape=[], dtype=tf.float32, name=\"learning_rate\")\n","\n","\n","\n","    \n","    \n","    \n","    '''TRAINING'''\n","    '''starting session'''\n","    gpu_option = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n","    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_option)) as sess:\n","        '''Initializing optimizer'''\n","        if brand_new:\n","            optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n","            init = tf.global_variables_initializer()\n","            sess.run(init)\n","            tf.add_to_collection(\"optimizer\", optimizer)\n","        else:\n","            saver = tf.train.Saver()\n","            saver.restore(sess, model_checkpoint_file_base)\n","            optimizer = tf.get_collection(\"optimizer\")[0]\n","\n","        for epoch in range(10,n_epochs):\n","            current_batch_no = 0\n","            permute_mat = 0\n","            iteration = 0\n","            while(1):\n","                #with tf.device('/cpu:0'):\n","                epoch_x,epoch_y,current_batch_no,permute_mat,last = random_h5py_batch(current_batch_no,permute_mat)\n","                sess_results = sess.run(optimizer, feed_dict={X: epoch_x, y: epoch_y, gamma: gm, alpha: al, learning_rate: LR})\n","                #print (\"epoch\",epoch+1,\"batch\",iteration+1)#,\"Cost\",sess_results[0])\n","                \n","                '''DICE Coefficient for iteration'''\n","                #with tf.device('/cpu:0'):\n","                if iteration%10==0:\n","                    #acc_train = 1-(dice.eval(feed_dict={X: epoch_x, y: epoch_y}))\n","                    train_loss,train_dice,train_focal,train_mse = sess.run([main_loss,dice,focal,mean_error], feed_dict={X: epoch_x, y: epoch_y, gamma: gm, alpha: al})\n","                    test_images, test_labels = test_batch()\n","                    #acc_test = 1-(dice.eval(feed_dict={X: test_images, y: test_labels}))\n","                    test_loss,test_dice,test_focal,test_mse = sess.run([main_loss,dice,focal,mean_error], feed_dict={X: test_images, y: test_labels, gamma: gm, alpha: al})\n","                    print(\"Minibatch at\",\"Epoch\", epoch+1,\"batch\",iteration+1, \"Train Loss:\", train_loss, \"Train Dice Coeff\",train_dice,\"Train Focal Loss\",train_focal,\"Train MSE\",train_mse,\"Test Loss:\", test_loss, \"Test Dice Coeff\",test_dice,\"Test Focal Loss\",test_focal,\"Test MSE\",test_mse)\n","                    #print(\"After Epoch\", epoch+1, \"Hybrid Train accuracy:\", 1-hybrid_train, \"Dice Train accuracy:\", 1-dice_train, \"Focal Train accuracy:\", 1-focal_train, \"MSE Train accuracy:\", 1-diff_train)\n","                    '''saving model after each epoch'''\n","                    save_path = tf.train.Saver(max_to_keep=1).save(sess, model_checkpoint_file_base)\n","                if last ==1:\n","                    break\n","                iteration +=1\n","            test_images, test_labels = test_batch()\n","            #hybrid_test,dice_test,focal_test,diff_test = sess.run([hybrid,dice,focal,sep], feed_dict={X: test_images, y: test_labels})\n","            #diff_test = sess.run(dice, feed_dict={X: test_images, y: test_labels})\n","            test_loss,test_dice,test_focal,test_mse = sess.run([main_loss,dice,focal,mean_error], feed_dict={X: test_images, y: test_labels, gamma: gm, alpha: al})\n","            print(\"-------------------------------------------------------------------------------------------------------\")\n","            #print(\"After Epoch\", epoch+1, \"Hybrid Test accuracy:\", 1-hybrid_test, \"Dice Test accuracy:\", 1-dice_test, \"Focal Test accuracy:\", 1-focal_test, \"MSE Test accuracy:\", 1-diff_test)\n","            print(\"After Epoch\", epoch+1,\"Test Loss:\", test_loss, \"Test Dice Coeff\",test_dice,\"Test Focal Loss\",test_focal,\"Test MSE\",test_mse)\n","            print(\"-------------------------------------------------------------------------------------------------------\")\n","            '''saving model after each epoch'''\n","            save_path = tf.train.Saver(max_to_keep=1).save(sess, model_checkpoint_file_base)\n","            \n","            if epoch % 1 == 0:\n","                test_example =   test_images\n","                test_example_gt = test_labels#np.rollaxis(test_labels,2,0)\n","                sess_results = sess.run(prediction,feed_dict={X:test_example})\n","\n","                sess_results = sess_results[0,100,:,:,1] + (2*sess_results[0,100,:,:,2]) + (3*sess_results[0,100,:,:,3])\n","                test_example = test_example[0,100,:,:,3]\n","                test_example_gt = test_example_gt[0,100,:,:,:]\n","                \n","                plt.figure()\n","                plt.imshow(np.squeeze(test_example),cmap='gray')\n","                plt.axis('off')\n","                plt.title('Original Image')\n","                plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/all_in_one/resnet_dice_focal_mse_loss/result/'+str(epoch)+\"a_Original_Image.png\")\n","                 \n","                plt.figure()\n","                plt.imshow(np.squeeze(test_example_gt),cmap='gray')\n","                plt.axis('off')\n","                plt.title('Ground Truth Mask')\n","                plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/all_in_one/resnet_dice_focal_mse_loss/result/'+str(epoch)+\"b_Original_Mask.png\")\n","\n","                plt.figure()\n","                plt.imshow(np.squeeze(sess_results),cmap='gray')\n","                plt.axis('off')\n","                plt.title('Generated Mask')\n","                plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/all_in_one/resnet_dice_focal_mse_loss/result/'+str(epoch)+\"c_Generated_Mask.png\")\n","\n","                plt.close('all')\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sIDXJRhzqbNn","colab_type":"text"},"source":["COMMENTS ON DICE LOSS AND ACCURACY\n","\n","1. Under the name_scope \"LOSS FUNCTION\", the variable named dice corresponds to dice loss and since the function dice_multipleclass() returns a value between -1 and 0(both included) , we add 1. Also another reason for this is there is no maximize function in adam optimizer(or any other optimizing function).\n","\n","2. While printing  the accuracy (everywhere)  we have to print dice coefficient and not dice loss therefore we add 1 to the dice_loss calculation"]},{"cell_type":"code","metadata":{"id":"vLp7SRmzT6Jp","colab_type":"code","outputId":"f91e29c5-e170-49ec-c25d-cfb5bab3bc7c","executionInfo":{"status":"error","timestamp":1559999716603,"user_tz":-330,"elapsed":39523,"user":{"displayName":"DWIJAY SHANBHAG","photoUrl":"","userId":"01321982494498435915"}},"colab":{"base_uri":"https://localhost:8080/","height":1851}},"source":["chose_train_restore()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Reloading existing\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Brain_Tumour_segmentation/all_in_one/resnet_dice_focal_mse_loss/saving_model/model.ckpt\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'mse_focal_weight' with dtype float\n\t [[{{node mse_focal_weight}}]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-1aedf54d4167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchose_train_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-39-044a4dad6c0b>\u001b[0m in \u001b[0;36mchose_train_restore\u001b[0;34m(n_epochs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;31m#with tf.device('/cpu:0'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_batch_no\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpermute_mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_h5py_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch_no\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpermute_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0msess_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;31m#print (\"epoch\",epoch+1,\"batch\",iteration+1)#,\"Cost\",sess_results[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'mse_focal_weight' with dtype float\n\t [[node mse_focal_weight (defined at <ipython-input-39-044a4dad6c0b>:33) ]]\n\nCaused by op 'mse_focal_weight', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-1aedf54d4167>\", line 1, in <module>\n    chose_train_restore()\n  File \"<ipython-input-39-044a4dad6c0b>\", line 33, in chose_train_restore\n    saver = tf.train.import_meta_graph(model_checkpoint_file_base + \".meta\")\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1435, in import_meta_graph\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1457, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\", line 235, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3433, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3433, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3325, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'mse_focal_weight' with dtype float\n\t [[node mse_focal_weight (defined at <ipython-input-39-044a4dad6c0b>:33) ]]\n"]}]}]}