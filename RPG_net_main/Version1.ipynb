{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Version1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOL16v0EjA87UuTgnLkvqvU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6TktNtKdaaLn","colab_type":"code","outputId":"86a43fff-0eef-412e-f624-9fd7891b6199","executionInfo":{"status":"ok","timestamp":1578979671447,"user_tz":300,"elapsed":24583,"user":{"displayName":"DWIJAY SHANBHAG","photoUrl":"","userId":"01321982494498435915"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["'''Mounting Google Drive on the Colab notebook'''\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g_CdJBJ7BfiG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-vMerzaakk2","colab_type":"code","colab":{}},"source":["#file_image = '/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_image.hdf5'\n","import h5py\n","#dataset has data of 484 patients. (155 images of each patient)\n","#data is extracted using 4 different techniques\n","#size of data of 1 patient is [240,240,155,4]\n","#for 2D segmentation we stack in 3rd dimension (axis=2)\n","#train_image\n","image_store = h5py.File(\"/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_image.hdf5\", \"r\")\n","#train_labels\n","label_store = h5py.File(\"/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_label.hdf5\", \"r\")\n","train_images = image_store[\"image\"]\n","train_labels = label_store[\"label\"]\n","#print('hi')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a3-PmATRaqjF","colab_type":"code","outputId":"7e75272d-634f-4048-d1b3-45cf644d8b03","executionInfo":{"status":"ok","timestamp":1578979675184,"user_tz":300,"elapsed":28233,"user":{"displayName":"DWIJAY SHANBHAG","photoUrl":"","userId":"01321982494498435915"}},"colab":{"base_uri":"https://localhost:8080/","height":64}},"source":["'''IMPORTING LIBRARIES'''\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import time\n","import math\n","import os\n","'''Clearing tesorflow computation graph'''\n","tf.reset_default_graph()"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"p9gmibzTauQY","colab_type":"code","colab":{}},"source":["'''DEFINING VARIABLES'''\n","\n","batch_size=1              #batch size taken at a time\n","n_class = 4                #number of classes in the label\n","\n","'''PLACEHOLDER for input and output of UNET'''\n","'''Here we crop the 155x240x240 image to  160x160x192 by repeating the last layer 5 times to convert 155 to 160'''\n","#X = tf.placeholder(shape=[None,160,160,192,4], dtype=tf.float32, name='input_image')\n","#y = tf.placeholder(shape=[None,160,160,192,1], dtype=tf.int64, name='hot_encode_label')\n","#loss_gamma = tf.placeholder(shape=[], dtype=tf.float32, name='loss_gamma')\n","#training = tf.placeholder_with_default(False, shape = (), name = 'training')\n","gm = 0.01\n","\n","'''Batch variable exraction from h5py file (used by functions 'rnadom_h5py_batch' and 'test_batch')'''\n","out_img = np.empty((240,240,batch_size*155,4),dtype=np.float32)\n","out_label = np.empty((240,240,batch_size*155,1),dtype=np.int64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VHsNrxQa1hL","colab_type":"code","colab":{}},"source":["'''COMPUTATION GRAPH Function Definitions'''\n","\n","\n","def left_filter_def(ker_size,in_chan,out_chan,name='left_filter'):\n","    '''Defining a filter variable to perform convolution'''\n","    stddev = np.sqrt(4/(ker_size*ker_size*ker_size*ker_size*in_chan*out_chan))           #HE initialization\n","    if stddev < 0.0008:\n","        stddev = 0.0008\n","    return (tf.Variable(tf.truncated_normal([ker_size,ker_size,ker_size,in_chan,out_chan],stddev=stddev),name=name))\n","\n","\n","def right_filter_def(ker_size,in_chan,out_chan,name='right_filter'):\n","    '''Defining a filter variable to perform transpose convolution'''\n","    stddev = np.sqrt(4/(ker_size*ker_size*ker_size*ker_size*in_chan*out_chan))\n","    if stddev < 0.0008:\n","        stddev = 0.0008\n","    return (tf.Variable(tf.truncated_normal([ker_size,ker_size,ker_size,out_chan,in_chan],stddev=stddev),name=name))\n","\n","\n","def Conv_layer(input_im,filter_mask,stride,activation='None',name='conv',padding=\"VALID\"):\n","    '''Function to perform Convolution and apply activation filter'''\n","    '''Convolution'''\n","    conv = tf.nn.conv3d(input_im,filter_mask,strides = [1,stride,stride,stride,1], padding = padding)\n","    #norm_conv = tf.layers.batch_normalization(conv, training=training, momentum=0.9)\n","    '''Activation'''\n","    if activation == 'relu':\n","        return(tf.nn.relu(conv,name=name))\n","    elif activation == 'softmax':\n","        return(tf.nn.softmax(conv,axis=-1,name=name))\n","    elif activation == 'elu':\n","        return(tf.nn.elu(conv,name=name))\n","    else:\n","        #activation == 'None'\n","        return(conv)\n","    \n","\n","def Deconv_layer(input_im,filter_mask,stride,activation='None',name='De_conv',padding=\"VALID\"):\n","    '''Function to perform Transpose Convolution and apply activation filter'''\n","    '''Transpose Convolution'''\n","    inp_shape = np.shape(input_im) #tf.shape()\n","    out_shape = [batch_size]+[int(inp_shape[1].value*2), int(inp_shape[2].value*2),int(inp_shape[3].value*2), int(inp_shape[4].value/2)]\n","    \n","    conv = tf.nn.conv3d_transpose(input_im, filter_mask, out_shape, strides = [1,stride,stride,stride,1], padding = padding,name=name)\n","    #norm_conv = tf.layers.batch_normalization(conv, training=training, momentum=0.9)\n","    '''Activation'''\n","    if activation == 'relu':\n","        return(tf.nn.relu(conv))\n","    elif activation == 'softmax':\n","        return(tf.nn.softmax(conv,axis=-1))\n","    elif activation == 'elu':\n","        return(tf.nn.elu(conv))\n","    else:\n","        #activation == 'None'\n","        return(conv)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L98G7mApa5Ch","colab_type":"code","colab":{}},"source":["'''Functions for batch Extraction and pre processing'''\n","\n","def normalizing_input():\n","    '''normalization of each input channels'''\n","    global out_img\n","    '''CHANNEL INFO'''\n","    # maximum value found using function called \"Finding_maximum_to_normalise \"\n","    #'''max value for dimension 4 is 5337.0'''\n","    #'''max value for dimension 3 is 11737.0'''\n","    #'''max value for dimension 2 is 9751.0'''\n","    #'''max value for dimension 1 is 6476.0'''\n","    out_img[:,:,:,0] = out_img[:,:,:,0]/6476.0\n","    out_img[:,:,:,1] = out_img[:,:,:,1]/9751.0\n","    out_img[:,:,:,2] = out_img[:,:,:,2]/11737.0\n","    out_img[:,:,:,3] = out_img[:,:,:,3]/5337.0\n","    \n","    \n","\n","def crop_image_fit_brain(in_image):\n","    '''cropping size was found using the code finding_brain.ipynb'''\n","    left = 19\n","    right= 210\n","    top  = 38\n","    bot  = 199\n","    out_image = in_image[top:(bot-1),left:(right+1),:,:]\n","    return (out_image)\n","\n","\n","def Pre_processing_3D(a):\n","    '''Function to roll axis to convert array into[depth,width,height,channels] and the divide it in batches'''\n","    #print(np.shape(a))\n","    b = np.rollaxis(a,2, 0)\n","    #print(np.shape(b))\n","    #image shape\n","    out_arr = np.empty(shape=[batch_size,160,np.shape(b)[1],np.shape(b)[2],np.shape(b)[3]])\n","    for i in range(batch_size):\n","        start = i*155\n","        end = start+155\n","        out_arr[i,0:155,:,:,:] = b[start:end,:,:,:]\n","    \n","    a = [out_arr[:,154:155,:,:,:]]*5\n","    out_arr[:,155:160,:,:,:] = a[0]\n","    \n","    '''clippig data from front of each batch'''\n","    '''to fit the model we remove first 3 slices of each batch'''\n","    '''shape of a is [batch_size,depth,width,height,channels]'''\n","    out_send = out_arr[:,:,:,:,:]\n","    #print(\"arr\",np.shape(out_arr),\"send\",np.shape(out_send))\n","    return (out_send)\n","\n","def random_rotate(in_image,in_label):\n","    \n","    check = np.random.random(1)[0]\n","    if check<0.25:\n","        out_image = in_image[:,:,::-1,:,:]\n","        out_lab = in_label[:,:,::-1,:,:]\n","        \n","    elif check<0.50:\n","        \n","        out_image = in_image[:,:,:,::-1,:]\n","        out_lab = in_label[:,:,:,::-1,:]\n","        \n","    elif check<0.75:\n","        \n","        out_image = in_image[:,::-1,:,:,:]\n","        out_lab = in_label[:,::-1,:,:,:]\n","        \n","    else:\n","        out_image =in_image\n","        out_lab = in_label\n","    \n","    return (out_image,out_lab)\n","\n","\n","\n","def random_h5py_batch(current_batch_no,permute_mat):\n","    '''Function to take batches randomly'''\n","    global out_img\n","    global out_label\n","    \n","    '''training info'''\n","    train_info = 380  #100 patients with 155 images each\n","\n","    if current_batch_no == 0:\n","        no_of_batches = train_info//batch_size  \n","        permute_mat = np.random.permutation(no_of_batches)\n","    \n","    start = permute_mat[current_batch_no]*batch_size*155\n","    end = start + (batch_size*155)\n","    train_images.read_direct(out_img,np.s_[:,:,start:end,:])\n","    train_labels.read_direct(out_label,np.s_[:,:,start:end,:])\n","    current_batch_no += 1\n","    #print(len(out_img))\n","    '''Input normalization'''\n","    normalizing_input()\n","    '''normalization oof labels'''\n","    #out_label = out_label\n","    #normalizing_label()\n","    '''converting multi class to dual class'''\n","    #out_label = convert_dual_class(out_label)\n","    '''cropping image and labels'''\n","    crop_out_image = crop_image_fit_brain(out_img)\n","    crop_out_label = crop_image_fit_brain(out_label)\n","    '''Rolling axes'''\n","    #out_img_send = np.rollaxis(crop_out_image,2, 0)\n","    '''hot encoding'''\n","    #out_label_send = crop_out_label\n","    '''3D conversion'''\n","    out_img_send = Pre_processing_3D(crop_out_image)\n","    out_label_send = Pre_processing_3D(crop_out_label)\n","    '''Data augmentation rotation'''\n","    #out_img_send,out_label_send = random_rotate(out_img_send,out_label_send)\n","     \n","    last=0\n","    if current_batch_no == len(permute_mat):\n","        last=1\n","    \n","    return (out_img_send,out_label_send,current_batch_no,permute_mat,last)\n","\n","def test_batch():\n","    '''Function to take next test batch''' \n","    global out_img\n","    global out_label\n","    \n","    '''training and testing info'''\n","    train_info = 380  #100 patients with 155 images each\n","    test_info = 484-train_info  #100 patients with 155 images each\n","    \n","    no_of_batches = test_info//batch_size  \n","    permute_mat = np.random.permutation(no_of_batches)\n","    start = (permute_mat[0]*batch_size*155) +(train_info*155)\n","    end = start + (155*batch_size)\n","    train_images.read_direct(out_img,np.s_[:,:,start:end,:])\n","    train_labels.read_direct(out_label,np.s_[:,:,start:end,:])\n","    \n","    '''normalization'''\n","    normalizing_input()\n","    #normalizing_label()\n","    '''croping images and labels'''\n","    crop_out_image = crop_image_fit_brain(out_img)\n","    crop_out_label = crop_image_fit_brain(out_label) \n","    '''3D processing'''\n","    out_img_send = Pre_processing_3D(crop_out_image)\n","    out_label_send = Pre_processing_3D(crop_out_label)\n","    \n","    return (out_img_send,out_label_send)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XXROtMDWa780","colab_type":"code","colab":{}},"source":["\n","  \n","def hot_encode(check_image,depth=n_class,name='hot_encode'):\n","    '''function for hot encoding images'''\n","    a = tf.one_hot(indices = check_image, depth=depth,name=name,)\n","    b = tf.transpose(a,perm=[0,1,2,3,5,4])\n","    return b\n","\n","#############################################################################################################################\n","#GENERALIZED DICE LOSS FUNCTION\n","#############################################################################################################################\n","def generalized_dice_coeff(y_true, y_pred):\n","    Ncl = y_pred.shape[-1]\n","    print(Ncl)\n","    w = np.zeros(shape=(Ncl,))\n","    w = tf.reduce_sum(y_true, axis=[0,1,2,3]) + 1\n","    print(np.shape(w))\n","    w = 1/((w**2))\n","    print(np.shape(w))\n","    # Compute gen dice coef:\n","    numerator = tf.reduce_sum(y_true*y_pred, axis=[0,1,2,3])\n","    denominator = tf.reduce_sum(y_true+y_pred, axis=[0,1,2,3])\n","    num=den=0\n","    for i in range(np.shape(w)[0]):\n","        num += w[i]*numerator[i]\n","        den += w[i]*denominator[i]\n","            \n","    #num = tf.reduce_sum(a)\n","    #den = tf.reduce_sum(b)\n","    num = num + 0.000000001\n","    den = den + 0.000000001\n","    \n","    gen_dice_coef = tf.identity(tf.divide((2*num),den),name='final_dice_coeff')\n","    \n","    return (gen_dice_coef)\n","#############################################################################################################################\n","#GENERALIZED FOCAL LOSS FUNCTION\n","#############################################################################################################################\n","def generalized_focal_loss(y_true, y_pred,gamma=2.0):\n","    \n","    Ncl = y_pred.shape[-1]\n","    w = np.zeros(shape=(Ncl,))\n","    w = tf.reduce_sum(y_true, axis=[0,1,2,3]) + 1\n","    w = 1/((w))\n","    y_pred = y_pred + 0.000000001                                               #to ensure that logarithm in next step doenst give math error\n","    \n","    ce = tf.multiply(y_true, -tf.log(y_pred))                                   #cross entropy (multiclass)\n","    fl_var = tf.multiply(y_true, tf.pow(tf.subtract(1., y_pred), gamma))        #focal loss variables (gamma*(1-pt)*(graund_truth))\n","    #fl = tf.multiply(alpha, tf.multiply(fl_var, ce))\n","    fl = tf.multiply(fl_var, ce)\n","    #fl=ce\n","    final = tf.reduce_sum(fl, axis=[0,1,2,3])\n","    normalized_focal = 0\n","    \n","    for i in range(np.shape(w)[0]):\n","        #print(i)\n","        #a = w[i]#/tf.reduce_sum(w)\n","        #b = fl[:,:,:,:,i]\n","        #c = (b)/(tf.reduce_max(b)+1)\n","        #normalized_focal += tf.reduce_sum(a*b)\n","        #b += w[i]*denominator[:,:,:,i]\n","        normalized_focal += w[i]*final[i]\n","    weighted_focal = tf.divide(normalized_focal,4.0,name='final_focal_loss')\n","    return (weighted_focal)\n","\n","def generalized_MSE(y_true, y_pred):\n","    error = tf.square(y_true-y_pred)\n","    mse_half = tf.reduce_mean(error,axis=[0,1,2,3])\n","    mse = tf.reduce_sum(tf.divide(mse_half,4.0),name='final_focal_loss')\n","    return mse\n","\n","\n","#############################################################################################################################\n","#LOSS FUNCTION\n","#############################################################################################################################\n","def hybrid_loss(y_true, y_pred, gamma):\n","    dice = generalized_dice_coeff(y_true, y_pred)\n","    #focal = generalized_focal_loss(y_true, y_pred)\n","    #update = (gamma*dice) + ((1-gamma)*focal)\n","    focal = generalized_MSE(y_true,y_pred)\n","    update = (gamma*(1-dice))\n","    final_loss = tf.add(update,((1-gamma)*focal),name='final_loss')\n","    return final_loss,dice,focal"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4hcpTyUma-x3","colab_type":"code","colab":{}},"source":["def predict_model1(X):\n","    '''Function to define the UNET model'''\n","    '''MODEL1 Filter definition'''\n","    '''LEFT'''\n","    \n","    #Combining_filter = left_filter_def(3,4,1,name='Combining_filter')\n","\n","    encoder_filter1 = left_filter_def(2,4,16,name='encoder_filter1')\n","    encoder_filter2 = left_filter_def(2,16,32,name='encoder_filter2')\n","    encoder_filter3 = left_filter_def(2,32,64,name='encoder_filter3')\n","    encoder_filter4 = left_filter_def(2,64,128,name='encoder_filter4')\n","    \n","    one_cross_filter1 = left_filter_def(1,16,8,name='one_cross_filter1')\n","    one_cross_filter2 = left_filter_def(1,32,16,name='one_cross_filter2')\n","    one_cross_filter3 = left_filter_def(1,64,32,name='one_cross_filter3')\n","    one_cross_filter4 = left_filter_def(1,128,64,name='one_cross_filter4')\n","\n","    down_conv1 = left_filter_def(2,8,16,name='down_conv1')\n","    down_conv2 = left_filter_def(2,16,32,name='down_conv2')\n","    down_conv3 = left_filter_def(2,32,64,name='down_conv3')\n","\n","    up_conv0 = right_filter_def(3,8,4,name='up_conv1')\n","    up_conv1 = right_filter_def(3,16,8,name='up_conv1')\n","    up_conv2 = right_filter_def(3,32,16,name='up_conv2')\n","    up_conv3 = right_filter_def(3,64,32,name='up_conv3')\n","\n","    end_conv1 = left_filter_def(3,8*2,8,name='end_conv1')\n","    end_conv2 = left_filter_def(3,16*3,16,name='end_conv1')\n","    end_conv3 = left_filter_def(3,32*3,32,name='end_conv1')\n","    end_conv4 = left_filter_def(3,64*2,64,name='end_conv1')\n","\n","    final_filter = left_filter_def(1,4,4,name='Final_filter')\n","    \n","    \n","    with tf.name_scope(\"BACKBONE_STRUCTURE\"):\n","        '''BLOCK1'''\n","        Backbone_cnn_pool1 = Conv_layer(X,encoder_filter1,stride=2,activation='relu',name='Backbone_cnn_pool1',padding='VALID')\n","        print('Backbone_cnn_pool1:',np.shape(Backbone_cnn_pool1))\n","        Backbone_cnn_pool2 = Conv_layer(Backbone_cnn_pool1,encoder_filter2,stride=2,activation='relu',name='Backbone_cnn_pool2',padding='VALID')\n","        print('Backbone_cnn_pool2:',np.shape(Backbone_cnn_pool2))\n","        Backbone_cnn_pool3 = Conv_layer(Backbone_cnn_pool2,encoder_filter3,stride=2,activation='relu',name='Backbone_cnn_pool3',padding='VALID')\n","        print('Backbone_cnn_pool3:',np.shape(Backbone_cnn_pool3))\n","        Backbone_cnn_pool4 = Conv_layer(Backbone_cnn_pool3,encoder_filter4,stride=2,activation='relu',name='Backbone_cnn_pool4',padding='VALID')\n","        print('Backbone_cnn_pool4:',np.shape(Backbone_cnn_pool4))\n","\n","    with tf.name_scope(\"One_cross_one_block\"):\n","        \n","        One_cross1 = Conv_layer(Backbone_cnn_pool1,one_cross_filter1,stride=1,activation='relu',name='one_cross1',padding=\"SAME\")\n","        print('One_cross1:',np.shape(One_cross1))\n","        One_cross2 = Conv_layer(Backbone_cnn_pool2,one_cross_filter2,stride=1,activation='relu',name='one_cross2',padding=\"SAME\")\n","        print('One_cross2:',np.shape(One_cross2))\n","        One_cross3 = Conv_layer(Backbone_cnn_pool3,one_cross_filter3,stride=1,activation='relu',name='one_cross3',padding=\"SAME\")\n","        print('One_cross3:',np.shape(One_cross3))\n","        One_cross4 = Conv_layer(Backbone_cnn_pool4,one_cross_filter4,stride=1,activation='relu',name='one_cross4',padding=\"SAME\")\n","        print('One_cross4:',np.shape(One_cross4))\n","\n","    with tf.name_scope(\"Droping_from_one_cross\"):\n","\n","        drop1 = Conv_layer(One_cross1,down_conv1,stride=2,activation='relu',name='drop1',padding='VALID')\n","        print('drop1:',np.shape(drop1))\n","        drop2 = Conv_layer(One_cross2,down_conv2,stride=2,activation='relu',name='drop2',padding='VALID')\n","        print('drop2:',np.shape(drop2))\n","        drop3 = Conv_layer(One_cross3,down_conv3,stride=2,activation='relu',name='drop3',padding='VALID')\n","        print('drop3:',np.shape(drop3))\n","\n","    with tf.name_scope(\"Concat_and_move_up\"):\n","\n","        '''Concat1'''\n","        concat1 = tf.concat([One_cross4,drop3],axis=4,name='CONCAT1')\n","        print('concat1:',np.shape(concat1))\n","        CNN1 = Conv_layer(concat1,end_conv4,stride=1,activation='relu',name='CNN1',padding='SAME')\n","        print('CNN1:',np.shape(CNN1))\n","        DCNN1= Deconv_layer(CNN1,up_conv3,stride=2,activation='relu',name='DE_CONV1',padding='SAME')\n","        print('DCNN1:',np.shape(DCNN1))\n","\n","        '''Concat2'''\n","        concat2 = tf.concat([One_cross3,drop2,DCNN1],axis=4,name='CONCAT2')\n","        print('concat2:',np.shape(concat2))\n","        CNN2 = Conv_layer(concat2,end_conv3,stride=1,activation='relu',name='CNN2',padding='SAME')\n","        print('CNN2:',np.shape(CNN2))\n","        DCNN2= Deconv_layer(CNN2,up_conv2,stride=2,activation='relu',name='DE_CONV2',padding='SAME')\n","        print('DCNN2:',np.shape(DCNN2))\n","\n","        '''Concat3'''\n","        concat3 = tf.concat([One_cross2,drop1,DCNN2],axis=4,name='CONCAT3')\n","        print('concat3:',np.shape(concat3))\n","        CNN3 = Conv_layer(concat3,end_conv2,stride=1,activation='relu',name='CNN3',padding='SAME')\n","        print('CNN3:',np.shape(CNN3))\n","        DCNN3= Deconv_layer(CNN3,up_conv1,stride=2,activation='relu',name='DE_CONV3',padding='SAME')\n","        print('DCNN3:',np.shape(DCNN3))\n","\n","        '''Concat4'''\n","        concat4 = tf.concat([One_cross1,DCNN3],axis=4,name='CONCAT4')\n","        print('concat4:',np.shape(concat4))\n","        CNN4 = Conv_layer(concat4,end_conv1,stride=1,activation='relu',name='CNN4',padding='SAME')\n","        print('CNN4:',np.shape(CNN4))\n","\n","\n","    DCNN4= Deconv_layer(CNN4,up_conv0,stride=2,activation='relu',name='DE_CONV4',padding='SAME')\n","    print('DCNN4:',np.shape(DCNN4))\n","    final_conv = Conv_layer(DCNN4,final_filter,stride=1,activation='softmax',name='final',padding='SAME')\n","    print('final_conv:',np.shape(final_conv))\n","\n","        \n","    return (final_conv)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1XK--FgFgbf2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVYvs8VRa_5S","colab_type":"code","colab":{}},"source":["def chose_train_restore(learning_rate =0.0001,n_epochs = 100):\n","    \n","    output_dir = \"/content/gdrive/My Drive/Brain_Tumour_segmentation/RPG_net_main/version1_store/saving_model\"\n","    model_checkpoint_file_base = os.path.join(output_dir, \"model.ckpt\")\n","\n","    \n","    if not os.path.exists(model_checkpoint_file_base + \".meta\"):\n","        '''FIRST TIME TRAINING'''\n","        print(\"Making new\")\n","        brand_new = True\n","        \n","        prediction = predict_model1(X)#logits\n","        '''----------------------------------------------------------------------------------------------------------------------------------------------------------------'''\n","        with tf.name_scope(\"LOSS_FUNCTION\"):\n","            '''using multi dimensional dice'''\n","            hot_y = hot_encode(y)\n","            #dice = 1+ dice_coef_multilabel(hot_y,prediction)     #dice loss for verison 1\n","            #dice = generalized_dice_coeff(hot_y[:,:,:,:,0], prediction)\n","            #focal = generalized_focal_loss(hot_y[:,:,:,:,0], prediction)\n","            #hybrid,dice,focal,sep = find_hybrid_loss(hot_y[:,:,:,:,:,0], prediction, gamma=0.9,alpha=0.8)\n","            #mean_error = ddice_coeffiff_error(hot_y[:,:,:,:,0], prediction)\n","            final_loss,final_dice,final_focal = hybrid_loss(hot_y[:,:,:,:,:,0], prediction,gamma=loss_gamma)\n","            #Ynet_loss,Ynet_dice,Ynet_focal = hybrid_loss(hot_y[:,:,:,:,:,0], Ynet_pred,gamma=0.9,Ynet_or_not=1)\n","        '''----------------------------------------------------------------------------------------------------------------------------------------------------------------'''\n","        with tf.name_scope(\"COST_FUNCTION\"):\n","            '''Cost function''''''Remember to change max to min min to mx depending on loss function'''\n","            loss1 = tf.reduce_mean(final_loss, name=\"loss1\")\n","            #loss2 = tf.reduce_mean(Ynet_loss, name=\"loss2\")\n","\n","        saver = tf.train.Saver()\n","        \n","    else:\n","        '''RESTORED MODEL'''\n","        print(\"Reloading existing\")\n","        brand_new = False\n","        saver = tf.train.import_meta_graph(model_checkpoint_file_base + \".meta\")\n","        g = tf.get_default_graph()\n","        '''Main variables'''\n","        #sep = g.get_tensor_by_name(\"LOSS_FUNCTION/mse_loss:0\")\n","        final_dice = g.get_tensor_by_name(\"LOSS_FUNCTION/final_dice_coeff:0\")\n","        final_focal = g.get_tensor_by_name(\"LOSS_FUNCTION/final_focal_loss:0\")\n","        #hybrid = g.get_tensor_by_name(\"LOSS_FUNCTION/hybrid_loss:0\")\n","        final_loss = g.get_tensor_by_name(\"LOSS_FUNCTION/final_loss:0\")\n","        prediction = g.get_tensor_by_name(\"final:0\") \n","        loss1 = g.get_tensor_by_name(\"COST_FUNCTION/loss1:0\")\n","        '''ynet variables'''\n","        #Ynet_dice = g.get_tensor_by_name(\"LOSS_FUNCTION/Ynet_dice_coeff:0\")\n","        #Ynet_focal = g.get_tensor_by_name(\"LOSS_FUNCTION/Ynet_focal_loss:0\")\n","        #hybrid = g.get_tensor_by_name(\"LOSS_FUNCTION/hybrid_loss:0\")\n","        #Ynet_loss = g.get_tensor_by_name(\"LOSS_FUNCTION/Ynet_loss:0\")\n","        #Ynet_pred = g.get_tensor_by_name(\"YNET/Softmax:0\") \n","        #loss2 = g.get_tensor_by_name(\"COST_FUNCTION/loss2:0\")\n","        \n","        X = g.get_tensor_by_name(\"input_image:0\")\n","        y = g.get_tensor_by_name(\"hot_encode_label:0\")\n","        loss_gamma = g.get_tensor_by_name(\"loss_gamma:0\")\n","\n","\n","    \n","    \n","    \n","    '''TRAINING'''\n","    '''starting session'''\n","    gpu_option = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n","    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_option)) as sess:\n","        '''Initializing optimizer'''\n","        if brand_new:\n","            optimizer1 = tf.train.AdamOptimizer(learning_rate).minimize(loss1)\n","            #optimizer2 = tf.train.AdamOptimizer(learning_rate).minimize(loss2)\n","            init = tf.global_variables_initializer()\n","            sess.run(init)\n","            tf.add_to_collection(\"optimizer1\", optimizer1)\n","            #tf.add_to_collection(\"optimizer2\", optimizer2)\n","        else:\n","            saver = tf.train.Saver()\n","            saver.restore(sess, model_checkpoint_file_base)\n","            optimizer1 = tf.get_collection(\"optimizer1\")[0]\n","            #optimizer2 = tf.get_collection(\"optimizer2\")[0]\n","        \n","        for epoch in range(12,n_epochs):\n","            current_batch_no = 0\n","            permute_mat = 0\n","            iteration = 0\n","            while(1):\n","                #with tf.device('/cpu:0'):\n","                epoch_x,epoch_y,current_batch_no,permute_mat,last = random_h5py_batch(current_batch_no,permute_mat)\n","                sess_result1 = sess.run(optimizer1, feed_dict={X: epoch_x, y: epoch_y, loss_gamma: gm})\n","                #print (\"epoch\",epoch+1,\"batch\",iteration+1)#,\"Cost\",sess_results[0])\n","                \n","                '''DICE Coefficient for iteration'''\n","                #with tf.device('/cpu:0'):\n","                if iteration%10==0:\n","                    #acc_train = 1-(dice.eval(feed_dict={X: epoch_x, y: epoch_y}))\n","                    final_train_loss,final_train_dice,final_train_focal = sess.run([final_loss,final_dice,final_focal], feed_dict={X: epoch_x, y: epoch_y, loss_gamma: gm})\n","                    test_images, test_labels = test_batch()\n","                    #acc_test = 1-(dice.eval(feed_dict={X: test_images, y: test_labels}))\n","                    final_test_loss,final_test_dice,final_test_focal = sess.run([final_loss,final_dice,final_focal], feed_dict={X: test_images, y: test_labels, loss_gamma: gm})\n","                    #print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n","                    print(\"MAIN: Minibatch at\",\"Epoch\", epoch+1,\"batch\",iteration+1, \"Train Loss:\", final_train_loss, \"Train Dice Coeff\",final_train_dice,\"Train Focal Loss\",final_train_focal,\"Test Loss:\", final_test_loss, \"Test Dice Coeff\",final_test_dice,\"Test Focal Loss\",final_test_focal)\n","                    #print(\"YNET: Minibatch at\",\"Epoch\", epoch+1,\"batch\",iteration+1, \"Train Loss:\", Ynet_train_loss, \"Train Dice Coeff\",Ynet_train_dice,\"Train Focal Loss\",Ynet_train_focal,\"Test Loss:\", Ynet_test_loss, \"Test Dice Coeff\",Ynet_test_dice,\"Test Focal Loss\",Ynet_test_focal)\n","                    #print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n","                    #print(\"After Epoch\", epoch+1, \"Hybrid Train accuracy:\", 1-hybrid_train, \"Dice Train accuracy:\", 1-dice_train, \"Focal Train accuracy:\", 1-focal_train, \"MSE Train accuracy:\", 1-diff_train)\n","                    '''saving model after every 10 iterations'''\n","                    save_path = tf.train.Saver(max_to_keep=1).save(sess, model_checkpoint_file_base)\n","                if last ==1:\n","                    break\n","                iteration +=1\n","            test_images, test_labels = test_batch()\n","            #hybrid_test,dice_test,focal_test,diff_test = sess.run([hybrid,dice,focal,sep], feed_dict={X: test_images, y: test_labels})\n","            #diff_test = sess.run(dice, feed_dict={X: test_images, y: test_labels})\n","            final_test_loss,final_test_dice,final_test_focal = sess.run([final_loss,final_dice,final_focal], feed_dict={X: test_images, y: test_labels, loss_gamma: gm})\n","            print(\"#################################################################################################################################\")\n","            #print(\"After Epoch\", epoch+1, \"Hybrid Test accuracy:\", 1-hybrid_test, \"Dice Test accuracy:\", 1-dice_test, \"Focal Test accuracy:\", 1-focal_test, \"MSE Test accuracy:\", 1-diff_test)\n","            print(\"MAIN: After Epoch\", epoch+1,\"Test Loss:\", final_test_loss, \"Test Dice Coeff\",final_test_dice,\"Test Focal Loss\",final_test_focal)\n","            #print(\"YNET: After Epoch\", epoch+1,\"Test Loss:\", Ynet_test_loss, \"Test Dice Coeff\",Ynet_test_dice,\"Test Focal Loss\",Ynet_test_focal)\n","            print(\"#################################################################################################################################\")\n","            '''saving model after each epoch'''\n","            save_path = tf.train.Saver(max_to_keep=1).save(sess, model_checkpoint_file_base)\n","            \n","            if epoch % 1 == 0:\n","                test_example =   test_images\n","                test_example_gt = test_labels#np.rollaxis(test_labels,2,0)\n","                sess_results = sess.run(prediction,feed_dict={X:test_example})\n","\n","                sess_results = sess_results[0,100,:,:,1] + (2*sess_results[0,100,:,:,2]) + (3*sess_results[0,100,:,:,3])\n","                test_example = test_example[0,100,:,:,3]\n","                test_example_gt = test_example_gt[0,100,:,:,:]\n","                \n","                plt.figure()\n","                plt.imshow(np.squeeze(test_example),cmap='gray')\n","                plt.axis('off')\n","                plt.title('Original Image')\n","                plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/RPG_net_main/version1_store/result/'+str(epoch)+\"a_Original_Image.png\")\n","                 \n","                plt.figure()\n","                plt.imshow(np.squeeze(test_example_gt),cmap='gray')\n","                plt.axis('off')\n","                plt.title('Ground Truth Mask')\n","                plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/RPG_net_main/version1_store/result/'+str(epoch)+\"b_Original_Mask.png\")\n","\n","                plt.figure()\n","                plt.imshow(np.squeeze(sess_results),cmap='gray')\n","                plt.axis('off')\n","                plt.title('Generated Mask')\n","                plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/RPG_net_main/version1_store/result/'+str(epoch)+\"c_Generated_Mask.png\")\n","\n","                plt.close('all')\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SiU2R6iDbCyb","colab_type":"code","outputId":"e647a325-24b7-4913-faa0-8e81a4953715","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["chose_train_restore()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Reloading existing\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Brain_Tumour_segmentation/RPG_net_main/version1_store/saving_model/model.ckpt\n","MAIN: Minibatch at Epoch 13 batch 1 Train Loss: 0.01939648 Train Dice Coeff 0.0014935876 Train Focal Loss 0.009506481 Test Loss: 0.028032174 Test Dice Coeff 0.0015279648 Test Focal Loss 0.01822975\n","MAIN: Minibatch at Epoch 13 batch 11 Train Loss: 0.019132014 Train Dice Coeff 0.0031647296 Train Focal Loss 0.009256224 Test Loss: 0.019713068 Test Dice Coeff 0.0011830204 Test Focal Loss 0.00982313\n","MAIN: Minibatch at Epoch 13 batch 21 Train Loss: 0.016259726 Train Dice Coeff 0.001061222 Train Focal Loss 0.0063336743 Test Loss: 0.024616022 Test Dice Coeff 0.0053913933 Test Focal Loss 0.014818118\n","MAIN: Minibatch at Epoch 13 batch 31 Train Loss: 0.019284979 Train Dice Coeff 0.0025942116 Train Focal Loss 0.00940497 Test Loss: 0.033407792 Test Dice Coeff 0.00532449 Test Focal Loss 0.023698017\n","MAIN: Minibatch at Epoch 13 batch 41 Train Loss: 0.01617423 Train Dice Coeff 0.00085638295 Train Focal Loss 0.0062452476 Test Loss: 0.026461324 Test Dice Coeff 0.00049430033 Test Focal Loss 0.016632592\n","MAIN: Minibatch at Epoch 13 batch 51 Train Loss: 0.018700443 Train Dice Coeff 0.0017238249 Train Focal Loss 0.008805739 Test Loss: 0.016156971 Test Dice Coeff 0.0003110407 Test Focal Loss 0.006222305\n","MAIN: Minibatch at Epoch 13 batch 61 Train Loss: 0.018860748 Train Dice Coeff 0.0021722617 Train Focal Loss 0.008972193 Test Loss: 0.023212358 Test Dice Coeff 0.004583654 Test Focal Loss 0.013392118\n","MAIN: Minibatch at Epoch 13 batch 71 Train Loss: 0.021025658 Train Dice Coeff 0.001392859 Train Focal Loss 0.011151099 Test Loss: 0.026442844 Test Dice Coeff 0.004689336 Test Focal Loss 0.016656302\n","MAIN: Minibatch at Epoch 13 batch 81 Train Loss: 0.030890927 Train Dice Coeff 0.001972924 Train Focal Loss 0.021121874 Test Loss: 0.019147843 Test Dice Coeff 0.0034900021 Test Focal Loss 0.009275498\n","MAIN: Minibatch at Epoch 13 batch 91 Train Loss: 0.014737006 Train Dice Coeff 0.00030081824 Train Focal Loss 0.0047878935 Test Loss: 0.029371174 Test Dice Coeff 0.0041017397 Test Focal Loss 0.019608274\n","MAIN: Minibatch at Epoch 13 batch 101 Train Loss: 0.023006432 Train Dice Coeff 0.00069801905 Train Focal Loss 0.013144862 Test Loss: 0.01944625 Test Dice Coeff 0.003008878 Test Focal Loss 0.00957206\n","MAIN: Minibatch at Epoch 13 batch 111 Train Loss: 0.019426152 Train Dice Coeff 0.00037405253 Train Focal Loss 0.009525145 Test Loss: 0.017542686 Test Dice Coeff 0.0015287685 Test Focal Loss 0.0076343175\n","MAIN: Minibatch at Epoch 13 batch 121 Train Loss: 0.01726805 Train Dice Coeff 0.0015541103 Train Focal Loss 0.0073571624 Test Loss: 0.016149638 Test Dice Coeff 0.00047291597 Test Focal Loss 0.0062165326\n","MAIN: Minibatch at Epoch 13 batch 131 Train Loss: 0.029127207 Train Dice Coeff 0.0043445765 Train Focal Loss 0.019364296 Test Loss: 0.013413314 Test Dice Coeff 0.00033674718 Test Focal Loss 0.0034511937\n","MAIN: Minibatch at Epoch 13 batch 141 Train Loss: 0.01782997 Train Dice Coeff 0.00022553417 Train Focal Loss 0.0079113385 Test Loss: 0.020313835 Test Dice Coeff 0.0005149911 Test Focal Loss 0.010423217\n","MAIN: Minibatch at Epoch 13 batch 151 Train Loss: 0.03192643 Train Dice Coeff 0.005194157 Train Focal Loss 0.022200374 Test Loss: 0.013494393 Test Dice Coeff 1.7471679e-05 Test Focal Loss 0.0035298662\n","MAIN: Minibatch at Epoch 13 batch 161 Train Loss: 0.014316618 Train Dice Coeff 2.484197e-05 Train Focal Loss 0.0043604714 Test Loss: 0.026461305 Test Dice Coeff 0.0004943031 Test Focal Loss 0.016632574\n","MAIN: Minibatch at Epoch 13 batch 171 Train Loss: 0.011577424 Train Dice Coeff 9.08065e-05 Train Focal Loss 0.0015942744 Test Loss: 0.02911235 Test Dice Coeff 0.006220202 Test Focal Loss 0.019368235\n","MAIN: Minibatch at Epoch 13 batch 181 Train Loss: 0.029002093 Train Dice Coeff 0.0049348897 Train Focal Loss 0.019243881 Test Loss: 0.019444998 Test Dice Coeff 0.00070029637 Test Focal Loss 0.009547475\n","MAIN: Minibatch at Epoch 13 batch 191 Train Loss: 0.027306184 Train Dice Coeff 0.0039613564 Train Focal Loss 0.017521009 Test Loss: 0.027709525 Test Dice Coeff 0.0012838461 Test Focal Loss 0.017901376\n","MAIN: Minibatch at Epoch 13 batch 201 Train Loss: 0.026465455 Train Dice Coeff 0.0059031495 Train Focal Loss 0.0166914 Test Loss: 0.013557631 Test Dice Coeff 0.000321721 Test Focal Loss 0.0035968167\n","MAIN: Minibatch at Epoch 13 batch 211 Train Loss: 0.030141845 Train Dice Coeff 0.0047702184 Train Focal Loss 0.020393483 Test Loss: 0.02012844 Test Dice Coeff 0.0014870897 Test Focal Loss 0.010245768\n","MAIN: Minibatch at Epoch 13 batch 221 Train Loss: 0.016543865 Train Dice Coeff 0.0012004676 Train Focal Loss 0.0066220914 Test Loss: 0.013317576 Test Dice Coeff 1.4945886e-05 Test Focal Loss 0.0033512379\n","MAIN: Minibatch at Epoch 13 batch 231 Train Loss: 0.019022752 Train Dice Coeff 2.0468435e-07 Train Focal Loss 0.009113892 Test Loss: 0.027007718 Test Dice Coeff 0.005672535 Test Focal Loss 0.01723681\n","MAIN: Minibatch at Epoch 13 batch 241 Train Loss: 0.017692093 Train Dice Coeff 0.0028464652 Train Focal Loss 0.0077985427 Test Loss: 0.011557162 Test Dice Coeff 8.65837e-06 Test Focal Loss 0.0015729784\n","MAIN: Minibatch at Epoch 13 batch 251 Train Loss: 0.032150246 Train Dice Coeff 8.5611784e-05 Train Focal Loss 0.022374852 Test Loss: 0.02943533 Test Dice Coeff 0.0016420336 Test Focal Loss 0.019648233\n","MAIN: Minibatch at Epoch 13 batch 261 Train Loss: 0.026502274 Train Dice Coeff 7.685449e-08 Train Focal Loss 0.016668964 Test Loss: 0.021809718 Test Dice Coeff 0.0036718661 Test Focal Loss 0.011966098\n","MAIN: Minibatch at Epoch 13 batch 271 Train Loss: 0.014690032 Train Dice Coeff 0.00017257467 Train Focal Loss 0.00473915 Test Loss: 0.025857117 Test Dice Coeff 0.005339499 Test Focal Loss 0.016071225\n","MAIN: Minibatch at Epoch 13 batch 281 Train Loss: 0.020073064 Train Dice Coeff 0.0016973444 Train Focal Loss 0.010191956 Test Loss: 0.02625072 Test Dice Coeff 0.0023354394 Test Focal Loss 0.016438458\n","MAIN: Minibatch at Epoch 13 batch 291 Train Loss: 0.015475614 Train Dice Coeff 0.000935501 Train Focal Loss 0.005540373 Test Loss: 0.026319169 Test Dice Coeff 0.0003370799 Test Focal Loss 0.016487412\n","MAIN: Minibatch at Epoch 13 batch 301 Train Loss: 0.023140233 Train Dice Coeff 0.0033733288 Train Focal Loss 0.013307037 Test Loss: 0.020234149 Test Dice Coeff 0.0028336828 Test Focal Loss 0.010366147\n","MAIN: Minibatch at Epoch 13 batch 311 Train Loss: 0.012522899 Train Dice Coeff 1.989469e-05 Train Focal Loss 0.0025485842 Test Loss: 0.031289577 Test Dice Coeff 0.0023801588 Test Focal Loss 0.021528665\n","MAIN: Minibatch at Epoch 13 batch 321 Train Loss: 0.01906627 Train Dice Coeff 0.0016188737 Train Focal Loss 0.009174201 Test Loss: 0.019444998 Test Dice Coeff 0.00070029637 Test Focal Loss 0.009547475\n","MAIN: Minibatch at Epoch 13 batch 331 Train Loss: 0.021467902 Train Dice Coeff 0.00011203824 Train Focal Loss 0.0115848705 Test Loss: 0.021287568 Test Dice Coeff 0.0040307473 Test Focal Loss 0.0114423\n","MAIN: Minibatch at Epoch 13 batch 341 Train Loss: 0.018454466 Train Dice Coeff 0.00026030708 Train Focal Loss 0.008542495 Test Loss: 0.023513041 Test Dice Coeff 0.0051671583 Test Focal Loss 0.013701731\n","MAIN: Minibatch at Epoch 13 batch 351 Train Loss: 0.01611609 Train Dice Coeff 0.0018400801 Train Focal Loss 0.006196454 Test Loss: 0.016156964 Test Dice Coeff 0.00031104087 Test Focal Loss 0.0062222974\n","MAIN: Minibatch at Epoch 13 batch 361 Train Loss: 0.03467885 Train Dice Coeff 0.00094914064 Train Focal Loss 0.02493772 Test Loss: 0.014306497 Test Dice Coeff 0.000488064 Test Focal Loss 0.0043549268\n","MAIN: Minibatch at Epoch 13 batch 371 Train Loss: 0.014652204 Train Dice Coeff 4.0512703e-05 Train Focal Loss 0.0046996055 Test Loss: 0.023739308 Test Dice Coeff 0.004028439 Test Focal Loss 0.013918782\n","#################################################################################################################################\n","MAIN: After Epoch 13 Test Loss: 0.027253289 Test Dice Coeff 0.0054418463 Test Focal Loss 0.017482534\n","#################################################################################################################################\n","MAIN: Minibatch at Epoch 14 batch 1 Train Loss: 0.020243052 Train Dice Coeff 0.0006485986 Train Focal Loss 0.010353069 Test Loss: 0.011557162 Test Dice Coeff 8.658374e-06 Test Focal Loss 0.0015729782\n","MAIN: Minibatch at Epoch 14 batch 11 Train Loss: 0.023140233 Train Dice Coeff 0.0033733288 Train Focal Loss 0.013307037 Test Loss: 0.022860123 Test Dice Coeff 0.0005239295 Test Focal Loss 0.012995316\n","MAIN: Minibatch at Epoch 14 batch 21 Train Loss: 0.027408391 Train Dice Coeff 0.0018920947 Train Focal Loss 0.017603345 Test Loss: 0.013682516 Test Dice Coeff 0.00029613706 Test Focal Loss 0.003722705\n","MAIN: Minibatch at Epoch 14 batch 31 Train Loss: 0.022662759 Train Dice Coeff 0.0010153776 Train Focal Loss 0.012800922 Test Loss: 0.021809716 Test Dice Coeff 0.0036718664 Test Focal Loss 0.011966096\n","MAIN: Minibatch at Epoch 14 batch 41 Train Loss: 0.017938148 Train Dice Coeff 0.00079504953 Train Focal Loss 0.008026361 Test Loss: 0.011557162 Test Dice Coeff 8.658376e-06 Test Focal Loss 0.0015729782\n","MAIN: Minibatch at Epoch 14 batch 51 Train Loss: 0.019867063 Train Dice Coeff 0.0020934227 Train Focal Loss 0.009987876 Test Loss: 0.02321218 Test Dice Coeff 0.004583885 Test Focal Loss 0.013391939\n","MAIN: Minibatch at Epoch 14 batch 61 Train Loss: 0.013599277 Train Dice Coeff 0.000737909 Train Focal Loss 0.0036430866 Test Loss: 0.026934713 Test Dice Coeff 0.003882488 Test Focal Loss 0.017144987\n","MAIN: Minibatch at Epoch 14 batch 71 Train Loss: 0.023000542 Train Dice Coeff 0.0016411897 Train Focal Loss 0.013148438 Test Loss: 0.028959395 Test Dice Coeff 0.0062910803 Test Focal Loss 0.019214451\n","MAIN: Minibatch at Epoch 14 batch 81 Train Loss: 0.016493827 Train Dice Coeff 0.000989568 Train Focal Loss 0.0065694177 Test Loss: 0.028032174 Test Dice Coeff 0.0015279651 Test Focal Loss 0.01822975\n","MAIN: Minibatch at Epoch 14 batch 91 Train Loss: 0.032156512 Train Dice Coeff 0.008507315 Train Focal Loss 0.022466248 Test Loss: 0.014930205 Test Dice Coeff 0.0015586317 Test Focal Loss 0.0049957493\n","MAIN: Minibatch at Epoch 14 batch 101 Train Loss: 0.019370068 Train Dice Coeff 0.001983992 Train Focal Loss 0.009484757 Test Loss: 0.024616022 Test Dice Coeff 0.005391395 Test Focal Loss 0.014818117\n","MAIN: Minibatch at Epoch 14 batch 111 Train Loss: 0.027653053 Train Dice Coeff 0.0010886524 Train Focal Loss 0.017842364 Test Loss: 0.02937116 Test Dice Coeff 0.0041017453 Test Focal Loss 0.01960826\n","MAIN: Minibatch at Epoch 14 batch 121 Train Loss: 0.02154059 Train Dice Coeff 7.0607784e-06 Train Focal Loss 0.0116572315 Test Loss: 0.012719456 Test Dice Coeff 0.0004208652 Test Focal Loss 0.0027511765\n","MAIN: Minibatch at Epoch 14 batch 131 Train Loss: 0.024686076 Train Dice Coeff 0.002202655 Train Focal Loss 0.014856669 Test Loss: 0.018559558 Test Dice Coeff 0.002148584 Test Focal Loss 0.008667721\n","MAIN: Minibatch at Epoch 14 batch 141 Train Loss: 0.020329267 Train Dice Coeff 0.003228861 Train Focal Loss 0.010466216 Test Loss: 0.026934713 Test Dice Coeff 0.0038824882 Test Focal Loss 0.017144987\n","MAIN: Minibatch at Epoch 14 batch 151 Train Loss: 0.020073064 Train Dice Coeff 0.0016973444 Train Focal Loss 0.010191956 Test Loss: 0.030465292 Test Dice Coeff 0.008734911 Test Focal Loss 0.020760244\n","MAIN: Minibatch at Epoch 14 batch 161 Train Loss: 0.017027853 Train Dice Coeff 0.0012970428 Train Focal Loss 0.0071119433 Test Loss: 0.01592639 Test Dice Coeff 0.0016467947 Test Focal Loss 0.0060028885\n","MAIN: Minibatch at Epoch 14 batch 171 Train Loss: 0.020510824 Train Dice Coeff 0.002332046 Train Focal Loss 0.01064055 Test Loss: 0.02288019 Test Dice Coeff 0.0031195886 Test Focal Loss 0.013041802\n","MAIN: Minibatch at Epoch 14 batch 181 Train Loss: 0.016493795 Train Dice Coeff 0.0009895776 Train Focal Loss 0.006569384 Test Loss: 0.026461266 Test Dice Coeff 0.0004943083 Test Focal Loss 0.016632535\n","MAIN: Minibatch at Epoch 14 batch 191 Train Loss: 0.013735926 Train Dice Coeff 3.866955e-06 Train Focal Loss 0.003773702 Test Loss: 0.018479493 Test Dice Coeff 0.0002951468 Test Focal Loss 0.008568125\n","MAIN: Minibatch at Epoch 14 batch 201 Train Loss: 0.0317833 Train Dice Coeff 0.0063420753 Train Focal Loss 0.022067394 Test Loss: 0.013494393 Test Dice Coeff 1.7471679e-05 Test Focal Loss 0.0035298662\n","MAIN: Minibatch at Epoch 14 batch 211 Train Loss: 0.019447487 Train Dice Coeff 0.0013578114 Train Focal Loss 0.009556631 Test Loss: 0.025601273 Test Dice Coeff 0.004891671 Test Focal Loss 0.015808273\n","MAIN: Minibatch at Epoch 14 batch 221 Train Loss: 0.025207676 Train Dice Coeff 0.0051551242 Train Focal Loss 0.015413361 Test Loss: 0.01789775 Test Dice Coeff 0.00058158365 Test Focal Loss 0.007983399\n","MAIN: Minibatch at Epoch 14 batch 231 Train Loss: 0.037274875 Train Dice Coeff 0.004385941 Train Focal Loss 0.027594682 Test Loss: 0.026319157 Test Dice Coeff 0.0003370801 Test Focal Loss 0.016487401\n","MAIN: Minibatch at Epoch 14 batch 241 Train Loss: 0.022768032 Train Dice Coeff 0.0015858889 Train Focal Loss 0.012913019 Test Loss: 0.021287555 Test Dice Coeff 0.0040307683 Test Focal Loss 0.011442285\n","MAIN: Minibatch at Epoch 14 batch 251 Train Loss: 0.025667492 Train Dice Coeff 0.0006553673 Train Focal Loss 0.015832368 Test Loss: 0.015756005 Test Dice Coeff 0.0020129362 Test Focal Loss 0.0058344784\n","MAIN: Minibatch at Epoch 14 batch 261 Train Loss: 0.028030112 Train Dice Coeff 0.002540747 Train Focal Loss 0.0182379 Test Loss: 0.014930202 Test Dice Coeff 0.001558635 Test Focal Loss 0.004995746\n","MAIN: Minibatch at Epoch 14 batch 271 Train Loss: 0.019129526 Train Dice Coeff 0.0028666626 Train Focal Loss 0.009250701 Test Loss: 0.031289574 Test Dice Coeff 0.002380159 Test Focal Loss 0.021528661\n","MAIN: Minibatch at Epoch 14 batch 281 Train Loss: 0.016792294 Train Dice Coeff 5.8776055e-05 Train Focal Loss 0.0068614963 Test Loss: 0.02911235 Test Dice Coeff 0.006220209 Test Focal Loss 0.019368235\n","MAIN: Minibatch at Epoch 14 batch 291 Train Loss: 0.01847475 Train Dice Coeff 0.0019062329 Train Focal Loss 0.00857961 Test Loss: 0.027253289 Test Dice Coeff 0.00544185 Test Focal Loss 0.017482532\n","MAIN: Minibatch at Epoch 14 batch 301 Train Loss: 0.020353619 Train Dice Coeff 0.0012612503 Train Focal Loss 0.01047094 Test Loss: 0.028211836 Test Dice Coeff 0.00386244 Test Focal Loss 0.018434808\n","MAIN: Minibatch at Epoch 14 batch 311 Train Loss: 0.024665453 Train Dice Coeff 0.00078047876 Train Focal Loss 0.014821473 Test Loss: 0.016361453 Test Dice Coeff 0.00070227083 Test Focal Loss 0.006432802\n","MAIN: Minibatch at Epoch 14 batch 321 Train Loss: 0.025225397 Train Dice Coeff 0.0019377036 Train Focal Loss 0.015398763 Test Loss: 0.028274484 Test Dice Coeff 0.0070286673 Test Focal Loss 0.01853007\n","MAIN: Minibatch at Epoch 14 batch 331 Train Loss: 0.016798658 Train Dice Coeff 0.0022698871 Train Focal Loss 0.0068902588 Test Loss: 0.023513034 Test Dice Coeff 0.0051671783 Test Focal Loss 0.013701722\n","MAIN: Minibatch at Epoch 14 batch 341 Train Loss: 0.02311458 Train Dice Coeff 0.005268996 Train Focal Loss 0.013300274 Test Loss: 0.016361453 Test Dice Coeff 0.0007022709 Test Focal Loss 0.006432802\n","MAIN: Minibatch at Epoch 14 batch 351 Train Loss: 0.01851241 Train Dice Coeff 0.00056006684 Train Focal Loss 0.00860405 Test Loss: 0.012192321 Test Dice Coeff 3.7670696e-05 Test Focal Loss 0.0022148457\n","MAIN: Minibatch at Epoch 14 batch 361 Train Loss: 0.01553753 Train Dice Coeff 2.266883e-05 Train Focal Loss 0.0055936943 Test Loss: 0.025417078 Test Dice Coeff 0.0038213811 Test Focal Loss 0.015611407\n","MAIN: Minibatch at Epoch 14 batch 371 Train Loss: 0.02567289 Train Dice Coeff 0.00011316286 Train Focal Loss 0.015832344 Test Loss: 0.026461255 Test Dice Coeff 0.0004943095 Test Focal Loss 0.016632523\n","#################################################################################################################################\n","MAIN: After Epoch 14 Test Loss: 0.023017086 Test Dice Coeff 0.0031727508 Test Focal Loss 0.013180621\n","#################################################################################################################################\n","MAIN: Minibatch at Epoch 15 batch 1 Train Loss: 0.028431654 Train Dice Coeff 0.006883607 Train Focal Loss 0.018687364 Test Loss: 0.02937115 Test Dice Coeff 0.004101748 Test Focal Loss 0.01960825\n","MAIN: Minibatch at Epoch 15 batch 11 Train Loss: 0.026983123 Train Dice Coeff 0.0012512315 Train Focal Loss 0.017167307 Test Loss: 0.025601272 Test Dice Coeff 0.004891675 Test Focal Loss 0.015808271\n","MAIN: Minibatch at Epoch 15 batch 21 Train Loss: 0.021134667 Train Dice Coeff 0.004127192 Train Focal Loss 0.011288829 Test Loss: 0.021445526 Test Dice Coeff 0.00063344574 Test Focal Loss 0.011567535\n","MAIN: Minibatch at Epoch 15 batch 31 Train Loss: 0.02996847 Train Dice Coeff 4.6139066e-05 Train Focal Loss 0.020170638 Test Loss: 0.02911235 Test Dice Coeff 0.00622021 Test Focal Loss 0.019368235\n","MAIN: Minibatch at Epoch 15 batch 41 Train Loss: 0.012551122 Train Dice Coeff 9.527225e-11 Train Focal Loss 0.0025768913 Test Loss: 0.024078825 Test Dice Coeff 0.0001578135 Test Focal Loss 0.01422263\n","MAIN: Minibatch at Epoch 15 batch 51 Train Loss: 0.025040608 Train Dice Coeff 0.0056299698 Train Focal Loss 0.015249402 Test Loss: 0.027709506 Test Dice Coeff 0.0012838509 Test Focal Loss 0.01790136\n","MAIN: Minibatch at Epoch 15 batch 61 Train Loss: 0.01971037 Train Dice Coeff 0.0038055177 Train Focal Loss 0.009846893 Test Loss: 0.011557161 Test Dice Coeff 8.658386e-06 Test Focal Loss 0.0015729779\n","MAIN: Minibatch at Epoch 15 batch 71 Train Loss: 0.029262502 Train Dice Coeff 0.0052473387 Train Focal Loss 0.019510075 Test Loss: 0.029371148 Test Dice Coeff 0.0041017486 Test Focal Loss 0.019608248\n","MAIN: Minibatch at Epoch 15 batch 81 Train Loss: 0.019104354 Train Dice Coeff 0.0024541127 Train Focal Loss 0.009221107 Test Loss: 0.021699805 Test Dice Coeff 0.0028320649 Test Focal Loss 0.011846591\n","MAIN: Minibatch at Epoch 15 batch 91 Train Loss: 0.028229188 Train Dice Coeff 0.0029677837 Train Focal Loss 0.0184433 Test Loss: 0.02023412 Test Dice Coeff 0.002833705 Test Focal Loss 0.0103661185\n","MAIN: Minibatch at Epoch 15 batch 101 Train Loss: 0.020821009 Train Dice Coeff 0.002087003 Train Focal Loss 0.010951393 Test Loss: 0.020607159 Test Dice Coeff 0.0037197268 Test Focal Loss 0.010751873\n","MAIN: Minibatch at Epoch 15 batch 111 Train Loss: 0.020848561 Train Dice Coeff 0.0040240968 Train Focal Loss 0.01099879 Test Loss: 0.017544808 Test Dice Coeff 0.001716025 Test Focal Loss 0.007638352\n","MAIN: Minibatch at Epoch 15 batch 121 Train Loss: 0.024619538 Train Dice Coeff 0.0039342255 Train Focal Loss 0.014806949 Test Loss: 0.017544806 Test Dice Coeff 0.0017160261 Test Focal Loss 0.00763835\n","MAIN: Minibatch at Epoch 15 batch 131 Train Loss: 0.016144557 Train Dice Coeff 0.0009130792 Train Focal Loss 0.006215846 Test Loss: 0.02031383 Test Dice Coeff 0.00051499147 Test Focal Loss 0.01042321\n","MAIN: Minibatch at Epoch 15 batch 141 Train Loss: 0.029677939 Train Dice Coeff 0.0017679343 Train Focal Loss 0.019894565 Test Loss: 0.023212021 Test Dice Coeff 0.0045840936 Test Focal Loss 0.01339178\n","MAIN: Minibatch at Epoch 15 batch 151 Train Loss: 0.012577692 Train Dice Coeff 5.8481946e-05 Train Focal Loss 0.0026043209 Test Loss: 0.016981486 Test Dice Coeff 0.0025008332 Test Focal Loss 0.007077268\n","MAIN: Minibatch at Epoch 15 batch 161 Train Loss: 0.014542891 Train Dice Coeff 0.00040225132 Train Focal Loss 0.004592841 Test Loss: 0.020410582 Test Dice Coeff 0.0020348814 Test Focal Loss 0.010536295\n","MAIN: Minibatch at Epoch 15 batch 171 Train Loss: 0.020241886 Train Dice Coeff 0.0021896863 Train Focal Loss 0.010367458 Test Loss: 0.020250382 Test Dice Coeff 0.0032940109 Test Focal Loss 0.010387194\n","MAIN: Minibatch at Epoch 15 batch 181 Train Loss: 0.018386982 Train Dice Coeff 0.00065145927 Train Focal Loss 0.008478281 Test Loss: 0.02211855 Test Dice Coeff 0.0020439397 Test Focal Loss 0.012261607\n","MAIN: Minibatch at Epoch 15 batch 191 Train Loss: 0.027138017 Train Dice Coeff 9.985363e-05 Train Focal Loss 0.017312137 Test Loss: 0.01789775 Test Dice Coeff 0.00058158376 Test Focal Loss 0.007983399\n","MAIN: Minibatch at Epoch 15 batch 201 Train Loss: 0.011492762 Train Dice Coeff 2.5067708e-05 Train Focal Loss 0.0015080931 Test Loss: 0.026442837 Test Dice Coeff 0.00468934 Test Focal Loss 0.016656294\n","MAIN: Minibatch at Epoch 15 batch 211 Train Loss: 0.013555109 Train Dice Coeff 1.2636311e-10 Train Focal Loss 0.0035910192 Test Loss: 0.013682509 Test Dice Coeff 0.00029613767 Test Focal Loss 0.0037226982\n","MAIN: Minibatch at Epoch 15 batch 221 Train Loss: 0.031926412 Train Dice Coeff 0.005194256 Train Focal Loss 0.022200357 Test Loss: 0.018473972 Test Dice Coeff 0.0023115173 Test Focal Loss 0.008582916\n","MAIN: Minibatch at Epoch 15 batch 231 Train Loss: 0.011208089 Train Dice Coeff 0.000107735 Train Focal Loss 0.0012213802 Test Loss: 0.024758313 Test Dice Coeff 0.001090458 Test Focal Loss 0.014918401\n","MAIN: Minibatch at Epoch 15 batch 241 Train Loss: 0.016542505 Train Dice Coeff 0.001201233 Train Focal Loss 0.006620725 Test Loss: 0.024263266 Test Dice Coeff 0.0026821003 Test Focal Loss 0.014434433\n","MAIN: Minibatch at Epoch 15 batch 251 Train Loss: 0.022205975 Train Dice Coeff 0.004334126 Train Focal Loss 0.012373047 Test Loss: 0.032833777 Test Dice Coeff 0.0032707152 Test Focal Loss 0.02309746\n","MAIN: Minibatch at Epoch 15 batch 261 Train Loss: 0.022662755 Train Dice Coeff 0.0010153833 Train Focal Loss 0.012800919 Test Loss: 0.012192319 Test Dice Coeff 3.7670703e-05 Test Focal Loss 0.0022148439\n","MAIN: Minibatch at Epoch 15 batch 271 Train Loss: 0.026673555 Train Dice Coeff 0.0016211538 Train Focal Loss 0.01685835 Test Loss: 0.025941536 Test Dice Coeff 0.00124814 Test Focal Loss 0.01611517\n","MAIN: Minibatch at Epoch 15 batch 281 Train Loss: 0.017641053 Train Dice Coeff 0.0004965772 Train Focal Loss 0.007723251 Test Loss: 0.021445526 Test Dice Coeff 0.00063344586 Test Focal Loss 0.011567535\n","MAIN: Minibatch at Epoch 15 batch 291 Train Loss: 0.03307581 Train Dice Coeff 0.00097146264 Train Focal Loss 0.023318712 Test Loss: 0.020313825 Test Dice Coeff 0.0005149915 Test Focal Loss 0.010423209\n","MAIN: Minibatch at Epoch 15 batch 301 Train Loss: 0.01699788 Train Dice Coeff 0.00090061116 Train Focal Loss 0.0070776623 Test Loss: 0.015926383 Test Dice Coeff 0.001646797 Test Focal Loss 0.0060028816\n","MAIN: Minibatch at Epoch 15 batch 311 Train Loss: 0.016591998 Train Dice Coeff 1.553284e-10 Train Focal Loss 0.006658584 Test Loss: 0.017632097 Test Dice Coeff 6.939589e-07 Test Focal Loss 0.0077091977\n","MAIN: Minibatch at Epoch 15 batch 321 Train Loss: 0.019426014 Train Dice Coeff 0.00037406868 Train Focal Loss 0.009525006 Test Loss: 0.02211855 Test Dice Coeff 0.00204394 Test Focal Loss 0.012261607\n","MAIN: Minibatch at Epoch 15 batch 331 Train Loss: 0.022079635 Train Dice Coeff 0.0016277208 Train Focal Loss 0.0122180935 Test Loss: 0.026250714 Test Dice Coeff 0.0023354401 Test Focal Loss 0.016438453\n","MAIN: Minibatch at Epoch 15 batch 341 Train Loss: 0.028721161 Train Dice Coeff 0.003142961 Train Focal Loss 0.018942012 Test Loss: 0.03128957 Test Dice Coeff 0.0023801592 Test Focal Loss 0.021528658\n","MAIN: Minibatch at Epoch 15 batch 351 Train Loss: 0.012826298 Train Dice Coeff 0.00044530572 Train Focal Loss 0.0028593445 Test Loss: 0.02012844 Test Dice Coeff 0.00148709 Test Focal Loss 0.010245768\n","MAIN: Minibatch at Epoch 15 batch 361 Train Loss: 0.01669422 Train Dice Coeff 0.00025100991 Train Focal Loss 0.0067643737 Test Loss: 0.020234108 Test Dice Coeff 0.002833713 Test Focal Loss 0.010366107\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HT87A937pAim","colab_type":"code","colab":{}},"source":["print(np.shape(test_example))"],"execution_count":0,"outputs":[]}]}