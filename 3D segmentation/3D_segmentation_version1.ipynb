{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3D_segmentation_version1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RIqV48zuBpwM","colab_type":"text"},"source":["\"\"\"\n","COMPLETELY NEW VERSION OF UNET DESIGNED FOR BRAIN TUMOUR SEGMENTATION\n","\n","SPECS:\n","\n","1. Input size  is 240x240x4 for each image\n","\n","2. BRATS dataset \n","\n","3. DICE LOSS IS TAKEN AS A LOSS FUNCTION\n","\n","4. MULTICLASS SEGMENTATION HAS BEEN IMPLEMENTED\n","\n","\n","DESC:\n","\n","HERE OUR PREDICTION WILL HAVE 4 DIMENSIONS(because we have 4 classes) FOR EACH IMAGE. THESE 4 PREDICTIONS are compared with hot encoded label(Ground truth)\n","THIS IN A WAY TRAINS THE SYSTEM TO HOT ENCODE THE PREDICTIONS TOO.\n","WE ARE TRYING TO IMPLEMENT THE ABOVE STATED MODEL TO IMPLEMENT MULTICLASS SEGEMENTATION. BUT HAD TO CHANGE SOME THINGS WHICH ARE STATED BELOW\n","\n","PROBLEMS AND CHANGES:\n","\n","1. Faced the problem of class imbalance. So in this version we multiply dice coefficient for each class with certain weight. this weight is reciprocal of the frequency of that class\n","\n","2. The problem of class imbalance still persists and dice coeff is more than 1. So i this version we have implemented a new dice coefficient function.\n","\n","\n","FUTURE:\n","\n","1. IMPROVING DICE COEFFICIENT\n","\n","2. 3D IMPLEMENTATION\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"eSGVMeVbibw0","colab_type":"code","outputId":"54687c96-5310-48b1-c838-6ab0f25a6507","executionInfo":{"status":"ok","timestamp":1557743833825,"user_tz":-330,"elapsed":31522,"user":{"displayName":"JAHANVI PATEL","photoUrl":"","userId":"14445844665407264126"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["'''Mounting Google Drive on the Colab notebook'''\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hxotR3CiirGu","colab_type":"code","colab":{}},"source":["#file_image = '/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_image.hdf5'\n","import h5py\n","#dataset has data of 484 patients. (155 images of each patient)\n","#data is extracted using 4 different techniques\n","#size of data of 1 patient is [240,240,155,4]\n","#for 2D segmentation we stack in 3rd dimension (axis=2)\n","#train_image\n","image_store = h5py.File(\"/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_image.hdf5\", \"r\")\n","#train_labels\n","label_store = h5py.File(\"/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_label.hdf5\", \"r\")\n","train_images = image_store[\"image\"]\n","train_labels = label_store[\"label\"]\n","#print('hi')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RIkjuDek_v5Q","colab_type":"code","colab":{}},"source":["'''IMPORTING LIBRARIES'''\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import time\n","import math\n","import os\n","'''Clearing tesorflow computation graph'''\n","tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SAFj-oXR_0Rs","colab_type":"code","colab":{}},"source":["'''DEFINING VARIABLES'''\n","\n","batch_size=1              #batch size taken at a time\n","n_class = 4                #number of classes in the label\n","\n","'''PLACEHOLDER for input and output of UNET'''\n","'''Here we crop the 155x240x240 image to  160x160x192 by repeating the last layer 5 times to convert 155 to 160'''\n","X = tf.placeholder(shape=[None,160,160,192,4], dtype=tf.float32, name='input_image')\n","y = tf.placeholder(shape=[None,160,160,192,1], dtype=tf.int64, name='hot_encode_label')\n","\n","\n","'''Batch variable exraction from h5py file (used by functions 'rnadom_h5py_batch' and 'test_batch')'''\n","out_img = np.empty((240,240,batch_size*155,4),dtype=np.float32)\n","out_label = np.empty((240,240,batch_size*155,1),dtype=np.int64)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"re3MWWJHLxuD","colab_type":"text"},"source":["DEFINING ALL THE REQUIRED FUNCTIONS"]},{"cell_type":"code","metadata":{"id":"No2sukbcBnCm","colab_type":"code","colab":{}},"source":["'''COMPUTATION GRAPH Function Definitions'''\n","\n","\n","def left_filter_def(ker_size,in_chan,out_chan,name='left_filter'):\n","    '''Defining a filter variable to perform convolution'''\n","    stddev = np.sqrt(4/(ker_size*ker_size*ker_size*ker_size*in_chan*out_chan))           #HE initialization\n","    if stddev < 0.0008:\n","        stddev = 0.0008\n","    return (tf.Variable(tf.truncated_normal([ker_size,ker_size,ker_size,in_chan,out_chan],stddev=stddev),name=name))\n","\n","\n","def right_filter_def(ker_size,in_chan,out_chan,name='right_filter'):\n","    '''Defining a filter variable to perform transpose convolution'''\n","    stddev = np.sqrt(4/(ker_size*ker_size*ker_size*ker_size*in_chan*out_chan))\n","    if stddev < 0.0008:\n","        stddev = 0.0008\n","    return (tf.Variable(tf.truncated_normal([ker_size,ker_size,ker_size,out_chan,in_chan],stddev=stddev),name=name))\n","\n","\n","def Conv_layer(input_im,filter_mask,stride,activation='None',name='conv'):\n","    '''Function to perform Convolution and apply activation filter'''\n","    '''Convolution'''\n","    conv = tf.nn.conv3d(input_im,filter_mask,strides = [1,stride,stride,stride,1], padding = \"SAME\",name=name)\n","    #norm_conv = tf.layers.batch_normalization(conv, training=training, momentum=0.9)\n","    '''Activation'''\n","    if activation == 'relu':\n","        return(tf.nn.relu(conv))\n","    elif activation == 'softmax':\n","        return(tf.nn.softmax(conv,axis=-1))\n","    elif activation == 'elu':\n","        return(tf.nn.elu(conv))\n","    else:\n","        #activation == 'None'\n","        return(conv)\n","    \n","\n","def Deconv_layer(input_im,filter_mask,stride,activation='None',name='De_conv'):\n","    '''Function to perform Transpose Convolution and apply activation filter'''\n","    '''Transpose Convolution'''\n","    inp_shape = np.shape(input_im) #tf.shape()\n","    out_shape = [batch_size]+[int(inp_shape[1].value*2), int(inp_shape[2].value*2),int(inp_shape[3].value*2), int(inp_shape[4].value/2)]\n","    \n","    conv = tf.nn.conv3d_transpose(input_im, filter_mask, out_shape, strides = [1,stride,stride,stride,1], padding = \"SAME\",name=name)\n","    #norm_conv = tf.layers.batch_normalization(conv, training=training, momentum=0.9)\n","    '''Activation'''\n","    if activation == 'relu':\n","        return(tf.nn.relu(conv))\n","    elif activation == 'softmax':\n","        return(tf.nn.softmax(conv,axis=-1))\n","    elif activation == 'elu':\n","        return(tf.nn.elu(conv))\n","    else:\n","        #activation == 'None'\n","        return(conv)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K2tyXeDFbpMy","colab_type":"code","colab":{}},"source":["'''Functions for batch Extraction and pre processing'''\n","\n","def normalizing_input():\n","    '''normalization of each input channels'''\n","    global out_img\n","    '''CHANNEL INFO'''\n","    # maximum value found using function called \"Finding_maximum_to_normalise \"\n","    #'''max value for dimension 4 is 5337.0'''\n","    #'''max value for dimension 3 is 11737.0'''\n","    #'''max value for dimension 2 is 9751.0'''\n","    #'''max value for dimension 1 is 6476.0'''\n","    out_img[:,:,:,0] = out_img[:,:,:,0]/6476.0\n","    out_img[:,:,:,1] = out_img[:,:,:,1]/9751.0\n","    out_img[:,:,:,2] = out_img[:,:,:,2]/11737.0\n","    out_img[:,:,:,3] = out_img[:,:,:,3]/5337.0\n","    \n","    \n","\n","def crop_image_fit_brain(in_image):\n","    '''cropping size was found using the code finding_brain.ipynb'''\n","    left = 19\n","    right= 210\n","    top  = 38\n","    bot  = 199\n","    out_image = in_image[top:(bot-1),left:(right+1),:,:]\n","    return (out_image)\n","\n","\n","def Pre_processing_3D(a):\n","    '''Function to roll axis to convert array into[depth,width,height,channels] and the divide it in batches'''\n","    #print(np.shape(a))\n","    b = np.rollaxis(a,2, 0)\n","    #print(np.shape(b))\n","    #image shape\n","    out_arr = np.empty(shape=[batch_size,160,np.shape(b)[1],np.shape(b)[2],np.shape(b)[3]])\n","    for i in range(batch_size):\n","        start = i*155\n","        end = start+155\n","        out_arr[i,0:155,:,:,:] = b[start:end,:,:,:]\n","    \n","    a = [out_arr[:,154:155,:,:,:]]*5\n","    out_arr[:,155:160,:,:,:] = a[0]\n","    \n","    '''clippig data from front of each batch'''\n","    '''to fit the model we remove first 3 slices of each batch'''\n","    '''shape of a is [batch_size,depth,width,height,channels]'''\n","    out_send = out_arr[:,:,:,:,:]\n","    #print(\"arr\",np.shape(out_arr),\"send\",np.shape(out_send))\n","    return (out_send)\n","\n","def random_rotate(in_image,in_label):\n","    \n","    check = np.random.random(1)[0]\n","    if check<0.25:\n","        out_image = in_image[:,:,::-1,:,:]\n","        out_lab = in_label[:,:,::-1,:,:]\n","        \n","    elif check<0.50:\n","        \n","        out_image = in_image[:,:,:,::-1,:]\n","        out_lab = in_label[:,:,:,::-1,:]\n","        \n","    elif check<0.75:\n","        \n","        out_image = in_image[:,::-1,:,:,:]\n","        out_lab = in_label[:,::-1,:,:,:]\n","        \n","    else:\n","        out_image =in_image\n","        out_lab = in_label\n","    \n","    return (out_image,out_lab)\n","\n","\n","\n","def random_h5py_batch(current_batch_no,permute_mat):\n","    '''Function to take batches randomly'''\n","    global out_img\n","    global out_label\n","    \n","    '''training info'''\n","    train_info = 384  #100 patients with 155 images each\n","\n","    if current_batch_no == 0:\n","        no_of_batches = train_info//batch_size  \n","        permute_mat = np.random.permutation(no_of_batches)\n","    \n","    start = permute_mat[current_batch_no]*batch_size*155\n","    end = start + (batch_size*155)\n","    train_images.read_direct(out_img,np.s_[:,:,start:end,:])\n","    train_labels.read_direct(out_label,np.s_[:,:,start:end,:])\n","    current_batch_no += 1\n","    #print(len(out_img))\n","    '''Input normalization'''\n","    normalizing_input()\n","    '''normalization oof labels'''\n","    #out_label = out_label\n","    #normalizing_label()\n","    '''converting multi class to dual class'''\n","    #out_label = convert_dual_class(out_label)\n","    '''cropping image and labels'''\n","    crop_out_image = crop_image_fit_brain(out_img)\n","    crop_out_label = crop_image_fit_brain(out_label)\n","    '''Rolling axes'''\n","    #out_img_send = np.rollaxis(crop_out_image,2, 0)\n","    '''hot encoding'''\n","    #out_label_send = crop_out_label\n","    '''3D conversion'''\n","    out_img_send = Pre_processing_3D(crop_out_image)\n","    out_label_send = Pre_processing_3D(crop_out_label)\n","    '''Data augmentation rotation'''\n","    #out_img_send,out_label_send = random_rotate(out_img_send,out_label_send)\n","     \n","    last=0\n","    if current_batch_no == len(permute_mat):\n","        last=1\n","    \n","    return (out_img_send,out_label_send,current_batch_no,permute_mat,last)\n","\n","def test_batch():\n","    '''Function to take next test batch''' \n","    global out_img\n","    global out_label\n","    \n","    '''training and testing info'''\n","    train_info = 380  #100 patients with 155 images each\n","    test_info = 484-train_info  #100 patients with 155 images each\n","    \n","    no_of_batches = test_info//batch_size  \n","    permute_mat = np.random.permutation(no_of_batches)\n","    start = (permute_mat[0]*batch_size*155) +(train_info*155)\n","    end = start + (155*batch_size)\n","    train_images.read_direct(out_img,np.s_[:,:,start:end,:])\n","    train_labels.read_direct(out_label,np.s_[:,:,start:end,:])\n","    \n","    '''normalization'''\n","    normalizing_input()\n","    #normalizing_label()\n","    '''croping images and labels'''\n","    crop_out_image = crop_image_fit_brain(out_img)\n","    crop_out_label = crop_image_fit_brain(out_label) \n","    '''3D processing'''\n","    out_img_send = Pre_processing_3D(crop_out_image)\n","    out_label_send = Pre_processing_3D(crop_out_label)\n","    \n","    return (out_img_send,out_label_send)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-NTV_zXbaY7","colab_type":"code","colab":{}},"source":["\n","  \n","def hot_encode(check_image,depth=n_class,name='hot_encode'):\n","    '''function for hot encoding images'''\n","    a = tf.one_hot(indices = check_image, depth=depth,name=name)\n","    b = tf.transpose(a,perm=[0,1,2,3,5,4])\n","    return b\n","\n","\n","#############################################################################################################################\n","#GENERALIZED DICE LOSS FUNCTION\n","#############################################################################################################################\n","def generalized_dice_coeff(y_true, y_pred):\n","    Ncl = y_pred.shape[-1]\n","    w = np.zeros(shape=(Ncl,))\n","    w = tf.reduce_sum(y_true, axis=[0,1,2,3]) + 1\n","    w = 1/((w**2))\n","    print(np.shape(w))\n","    # Compute gen dice coef:\n","    numerator = y_true*y_pred\n","    denominator = y_true+y_pred\n","    a=b=0\n","    for i in range(np.shape(w)[0]):\n","        a += w[i]*numerator[:,:,:,:,i]\n","        b += w[i]*denominator[:,:,:,:,i]\n","            \n","    num = tf.reduce_sum(a)\n","    den = tf.reduce_sum(b)\n","\n","    gen_dice_coef = tf.subtract(1.0,tf.divide((2*num),den),name='dice_loss')\n","\n","    return (gen_dice_coef)\n","  \n","#############################################################################################################################\n","#GENERALIZED FOCAL LOSS FUNCTION\n","#############################################################################################################################\n","def generalized_focal_loss(y_true, y_pred, gamma=2.0, alpha=0.25):\n","    \n","    Ncl = y_pred.shape[-1]\n","    w = np.zeros(shape=(Ncl,))\n","    w = tf.reduce_sum(y_true, axis=[0,1,2,3]) + 1\n","    w = 1/((w))\n","    y_pred = y_pred + 0.000000001                                               #to ensure that logarithm in next step doenst give math error\n","    \n","    ce = tf.multiply(y_true, -tf.log(y_pred))                                   #cross entropy (multiclass)\n","    fl_var = tf.multiply(y_true, tf.pow(tf.subtract(1., y_pred), gamma))        #focal loss variables (gamma*(1-pt)*(graund_truth))\n","    #fl = tf.multiply(alpha, tf.multiply(fl_var, ce))\n","    fl = tf.multiply(fl_var, ce)\n","    #fl=ce\n","    normalized_focal = 0\n","    \n","    for i in range(np.shape(w)[0]):\n","        #print(i)\n","        a = w[i]#/tf.reduce_sum(w)\n","        b = fl[:,:,:,:,i]\n","        #c = (b)/(tf.reduce_max(b)+1)\n","        normalized_focal += tf.reduce_sum(a*b)\n","        #b += w[i]*denominator[:,:,:,i]\n","    weighted_focal = tf.divide(normalized_focal,4.0,name='focal_loss')\n","    return (weighted_focal)\n","\n","#############################################################################################################################\n","#MEAN SQUARE ERROR(MSE) FUNCTION\n","#############################################################################################################################\n","def diff_error(y_true, y_pred):\n","    error = tf.square(y_true-y_pred)\n","    #error = (error+0.00000000001-tf.reduce_min(error))/(tf.reduce_max(error)+0.0000001-tf.reduce_min(error))\n","    #a = np.shape(error)#/(1.0)\n","    #size = batch_size*a[1]*a[2]*a[3]*a[4]\n","    #size = 19660800.0\n","    #error = tf.divide(tf.reduce_mean(error),size, name='mse_loss')\n","    return tf.reduce_mean(error, name='mse_loss')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Njl2knP5ue5C","colab_type":"code","colab":{}},"source":["def find_hybrid_loss(y_true,y_pred,gamma=0.6,alpha=0.5):\n","    dice = generalized_dice_coeff(y_true, y_pred)\n","    focal = generalized_focal_loss(y_true, y_pred)\n","    MeanAndSquare = diff_error(y_true, y_pred)\n","    hybrid = tf.identity((gamma*dice)+((1-gamma)*((alpha*focal)+((1-alpha)*MeanAndSquare))),name='hybrid_loss')\n","    return hybrid,dice,focal,MeanAndSquare"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CQCK3RO4L3hl","colab_type":"text"},"source":["INITIALIZING THE MODEL FILTERS"]},{"cell_type":"code","metadata":{"id":"oHMGiKsBL-QK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"c75c9afb-3395-4337-dd56-e6d7413da099","executionInfo":{"status":"ok","timestamp":1557743941131,"user_tz":-330,"elapsed":990,"user":{"displayName":"JAHANVI PATEL","photoUrl":"","userId":"14445844665407264126"}}},"source":["'''MODEL1 Filter definition'''\n","'''LEFT'''\n","\n","filter1 = left_filter_def(3,4,8,name='filter1')\n","filter2 = left_filter_def(3,8,8,name='filter2')\n","\n","filter3 = left_filter_def(3,8,16,name='filter3')\n","filter4 = left_filter_def(3,16,16,name='filter4')\n","\n","filter5 = left_filter_def(3,16,32,name='filter5')\n","filter6 = left_filter_def(3,32,32,name='filter6')\n","\n","filter7 = left_filter_def(3,32,64,name='filter7')\n","filter8 = left_filter_def(3,64,64,name='filter8')\n","\n","filter9 = left_filter_def(3,64,128,name='filter9')\n","filter10= left_filter_def(3,128,64,name='filter10')\n","\n","'''RIGHT'''\n","\n","filter11 = right_filter_def(3,128,64,name='filter11')\n","filter12 = left_filter_def(3,64,64,name='filter12')\n","filter13 = left_filter_def(3,64,32,name='filter13')\n","\n","filter14 = right_filter_def(3,64,32,name='filter14')\n","filter15 = left_filter_def(3,32,32,name='filter15')\n","filter16 = left_filter_def(3,32,16,name='filter16')\n","\n","filter17 = right_filter_def(3,32,16,name='filter17')\n","filter18 = left_filter_def(3,16,16,name='filter18')\n","filter19 = left_filter_def(3,16,8,name='filter19')\n","\n","filter20 = right_filter_def(3,16,8,name='filter20')\n","filter21 = left_filter_def(3,8,8,name='filter21')\n","filter22 = left_filter_def(3,8,n_class,name='filter22')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mf9Y3JjeMQnI","colab_type":"text"},"source":["DEFINING THE MODEL STRUCTURE"]},{"cell_type":"code","metadata":{"id":"3uIZEngOMVfS","colab_type":"code","colab":{}},"source":["def predict_model1(X):\n","    '''Function to define the UNET model'''\n","    with tf.name_scope(\"BLOCK1\"):\n","        '''BLOCK1'''\n","        CNN1 = Conv_layer(X,filter1,stride=1,activation='relu',name='CNN1')\n","        print (\"CNN1\",np.shape(CNN1))\n","        CNN2 = Conv_layer(CNN1,filter2,stride=1,activation='relu',name='CNN2')\n","        print (\"CNN2\",np.shape(CNN2))\n","        pool1 = tf.nn.max_pool3d(CNN2,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID',name='POOL1')\n","    \n","    with tf.name_scope(\"BLOCK2\"):\n","        '''BLOCK2'''\n","        CNN3 = Conv_layer(pool1,filter3,stride=1,activation='relu',name='CNN3')\n","        print (\"CNN3\",np.shape(CNN3))\n","        CNN4 = Conv_layer(CNN3,filter4,stride=1,activation='relu',name='CNN4')\n","        print (\"CNN4\",np.shape(CNN4))\n","        pool2 = tf.nn.max_pool3d(CNN4,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID',name='POOL2')\n","    \n","    with tf.name_scope(\"BLOCK3\"):\n","        '''BLOCK3'''\n","        CNN5 = Conv_layer(pool2,filter5,stride=1,activation='relu',name='CNN5')\n","        print (\"CNN5\",np.shape(CNN5))\n","        CNN6 = Conv_layer(CNN5,filter6,stride=1,activation='relu',name='CNN6')\n","        print (\"CNN6\",np.shape(CNN6))\n","        pool3 = tf.nn.max_pool3d(CNN6,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID',name='POOL3')\n","    \n","    with tf.name_scope(\"BLOCK4\"):\n","        '''BLOCK4'''\n","        CNN7 = Conv_layer(pool3,filter7,stride=1,activation='relu',name='CNN7')\n","        print (\"CNN7\",np.shape(CNN7))\n","        CNN8 = Conv_layer(CNN7,filter8,stride=1,activation='relu',name='CNN8')\n","        print (\"CNN8\",np.shape(CNN8))\n","        pool4 = tf.nn.max_pool3d(CNN8,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID',name='POOL4')\n","    \n","    with tf.name_scope(\"BLOCK5\"):\n","        '''BLOCK5'''\n","        CNN9 = Conv_layer(pool4,filter9,stride=1,activation='relu',name='CNN9')\n","        print (\"CNN9\",np.shape(CNN9))\n","        CNN10 = Conv_layer(CNN9,filter10,stride=1,activation='relu',name='CNN10')\n","        print (\"CNN10\",np.shape(CNN10))\n","    \n","    '''Moving UP'''\n","    \n","    with tf.name_scope(\"BLOCK6\"):\n","        '''BLOCK6'''\n","        concat1 = tf.concat([CNN10,pool4],axis=4,name='CONCAT1')\n","        print (\"concat1\",np.shape(concat1))\n","        DCNN1= Deconv_layer(concat1,filter11,stride=2,activation='relu',name='DE_CONV1')\n","        print (\"DCNN1\",np.shape(DCNN1))\n","        CNN11 = Conv_layer(DCNN1,filter12,stride=1,activation='relu',name='CNN11')\n","        #print (\"CNN11\",np.shape(CNN11))\n","        CNN12 = Conv_layer(CNN11,filter13,stride=1,activation='relu',name='CNN12')\n","        #print (\"CNN12\",np.shape(CNN12))\n","    \n","    with tf.name_scope(\"BLOCK7\"):\n","        '''BLOCK7'''\n","        concat2 = tf.concat([CNN12,pool3],axis=4,name='CONCAT2')\n","        #print (\"concat2\",np.shape(concat2))\n","        DCNN2= Deconv_layer(concat2,filter14,stride=2,activation='relu',name='DE_CONV2')\n","        #print (\"DCNN2\",np.shape(DCNN2))\n","        CNN13 = Conv_layer(DCNN2,filter15,stride=1,activation='relu',name='CNN13')\n","        #print (\"CNN13\",np.shape(CNN13))\n","        CNN14 = Conv_layer(CNN13,filter16,stride=1,activation='relu',name='CNN14')\n","        #print (\"CNN14\",np.shape(CNN14))\n","    \n","    with tf.name_scope(\"BLOCK8\"):\n","        '''BLOCK8'''\n","        concat3 = tf.concat([CNN14,pool2],axis=4,name='CONCAT3')\n","        #print (\"concat3\",np.shape(concat3))\n","        DCNN3= Deconv_layer(concat3,filter17,stride=2,activation='relu',name='DE_CONV3')\n","        #print (\"DCNN3\",np.shape(DCNN3))\n","        CNN15 = Conv_layer(DCNN3,filter18,stride=1,activation='relu',name='CNN14')\n","        #print (\"CNN15\",np.shape(CNN15))\n","        CNN16 = Conv_layer(CNN15,filter19,stride=1,activation='relu',name='CNN15')\n","        #print (\"CNN16\",np.shape(CNN16))\n","        \n","    with tf.name_scope(\"BLOCK9\"):\n","        '''BLOCK9'''\n","        concat4 = tf.concat([CNN16,pool1],axis=4,name='CONCAT4')\n","        #print (\"concat4\",np.shape(concat4))\n","        DCNN4= Deconv_layer(concat4,filter20,stride=2,activation='relu',name='DE_CONV4')\n","        #print (\"DCNN4\",np.shape(DCNN4))\n","        CNN17 = Conv_layer(DCNN4,filter21,stride=1,activation='relu',name='CNN17')\n","        #print (\"CNN17\",np.shape(CNN17))\n","        CNN18 = Conv_layer(CNN17,filter22,stride=1,activation='relu',name='CNN18')\n","        print (\"CNN18\",np.shape(CNN18))\n","    return (CNN18)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8VWIc00uslsC","colab_type":"code","colab":{}},"source":["def chose_train_restore(learning_rate =0.0001,n_epochs = 100):\n","    output_dir = \"/content/gdrive/My Drive/Brain_Tumour_segmentation/3D segmentation/saving_model\"\n","    model_checkpoint_file_base = os.path.join(output_dir, \"model.ckpt\")\n","\n","    \n","    if not os.path.exists(model_checkpoint_file_base + \".meta\"):\n","        '''FIRST TIME TRAINING'''\n","        print(\"Making new\")\n","        brand_new = True\n","        \n","        prediction = predict_model1(X)#logits\n","        '''----------------------------------------------------------------------------------------------------------------------------------------------------------------'''\n","        with tf.name_scope(\"LOSS_FUNCTION\"):\n","            '''using multi dimensional dice'''\n","            hot_y = hot_encode(y)\n","            #dice = 1+ dice_coef_multilabel(hot_y,prediction)     #dice loss for verison 1\n","            #dice = generalized_dice_coeff(hot_y[:,:,:,:,0], prediction)\n","            #focal = generalized_focal_loss(hot_y[:,:,:,:,0], prediction)\n","            hybrid,dice,focal,sep = find_hybrid_loss(hot_y[:,:,:,:,:,0], prediction, gamma=0.9,alpha=0.8)\n","            #mean_error = diff_error(hot_y[:,:,:,:,0], prediction)\n","        '''----------------------------------------------------------------------------------------------------------------------------------------------------------------'''\n","        with tf.name_scope(\"COST_FUNCTION\"):\n","            '''Cost function''''''Remember to change max to min min to mx depending on loss function'''\n","            loss = tf.reduce_mean(hybrid, name=\"loss\")\n","\n","        saver = tf.train.Saver()\n","        \n","    else:\n","        '''RESTORED MODEL'''\n","        print(\"Reloading existing\")\n","        brand_new = False\n","        saver = tf.train.import_meta_graph(model_checkpoint_file_base + \".meta\")\n","        g = tf.get_default_graph()\n","        \n","        sep = g.get_tensor_by_name(\"LOSS_FUNCTION/mse_loss:0\")\n","        dice = g.get_tensor_by_name(\"LOSS_FUNCTION/dice_loss:0\")\n","        focal = g.get_tensor_by_name(\"LOSS_FUNCTION/focal_loss:0\")\n","        hybrid = g.get_tensor_by_name(\"LOSS_FUNCTION/hybrid_loss:0\")\n","        prediction = g.get_tensor_by_name(\"BLOCK9/Softmax:0\") \n","        loss = g.get_tensor_by_name(\"COST_FUNCTION/loss:0\")\n","        \n","        #X = g.get_tensor_by_name(\"input_image:0\")\n","        #y = g.get_tensor_by_name(\"hot_encode_label:0\")\n","\n","\n","    \n","    \n","    \n","    '''TRAINING'''\n","    '''starting session'''\n","    gpu_option = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n","    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_option)) as sess:\n","        '''Initializing optimizer'''\n","        if brand_new:\n","            optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n","            init = tf.global_variables_initializer()\n","            sess.run(init)\n","            tf.add_to_collection(\"optimizer\", optimizer)\n","        else:\n","            saver = tf.train.Saver()\n","            saver.restore(sess, model_checkpoint_file_base)\n","            optimizer = tf.get_collection(\"optimizer\")[0]\n","\n","        for epoch in range(9,n_epochs):\n","            current_batch_no = 0\n","            permute_mat = 0\n","            iteration = 0\n","            while(1):\n","                #with tf.device('/cpu:0'):\n","                epoch_x,epoch_y,current_batch_no,permute_mat,last = random_h5py_batch(current_batch_no,permute_mat)\n","                sess_results = sess.run(optimizer, feed_dict={X: epoch_x, y: epoch_y})\n","                #print (\"epoch\",epoch+1,\"batch\",iteration+1)#,\"Cost\",sess_results[0])\n","                \n","                '''DICE Coefficient for iteration'''\n","                #with tf.device('/cpu:0'):\n","                if iteration%10==0:\n","                    acc_train = 1-(hybrid.eval(feed_dict={X: epoch_x, y: epoch_y}))\n","                    hybrid_train,dice_train,focal_train,diff_train = sess.run([hybrid,dice,focal,sep], feed_dict={X: epoch_x, y: epoch_y})\n","                    #test_images, test_labels = test_batch()\n","                    #acc_test = 1-(hybrid.eval(feed_dict={X: test_images, y: test_labels}))\n","                    #print(\"Minibatch at\",\"Epoch\", epoch+1,\"batch\",iteration+1, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n","                    print(\"After Epoch\", epoch+1, \"Hybrid Train accuracy:\", 1-hybrid_train, \"Dice Train accuracy:\", 1-dice_train, \"Focal Train accuracy:\", 1-focal_train, \"MSE Train accuracy:\", 1-diff_train)\n","                if last ==1:\n","                    break\n","                iteration +=1\n","            test_images, test_labels = test_batch()\n","            hybrid_test,dice_test,focal_test,diff_test = sess.run([hybrid,dice,focal,sep], feed_dict={X: test_images, y: test_labels})\n","            #diff_test = sess.run(mean_error, feed_dict={X: test_images, y: test_labels})\n","            print(\"-------------------------------------------------------------------------------------------------------\")\n","            print(\"After Epoch\", epoch+1, \"Hybrid Test accuracy:\", 1-hybrid_test, \"Dice Test accuracy:\", 1-dice_test, \"Focal Test accuracy:\", 1-focal_test, \"MSE Test accuracy:\", 1-diff_test)\n","            #print(\"mse\",1-diff_test)\n","            print(\"-------------------------------------------------------------------------------------------------------\")\n","            '''saving model after each epoch'''\n","            save_path = tf.train.Saver(max_to_keep=1).save(sess, model_checkpoint_file_base)\n","            \n","            if epoch % 1 == 0:\n","                test_example =   test_images\n","                test_example_gt = test_labels#np.rollaxis(test_labels,2,0)\n","                sess_results = sess.run(prediction,feed_dict={X:test_example})\n","\n","                sess_results = sess_results[0,100,:,:,1] + (2*sess_results[0,100,:,:,2]) + (3*sess_results[0,100,:,:,3])\n","                test_example = test_example[0,100,:,:,3]\n","                test_example_gt = test_example_gt[0,100,:,:,:]\n","                \n","                plt.figure()\n","                plt.imshow(np.squeeze(test_example),cmap='gray')\n","                plt.axis('off')\n","                plt.title('Original Image')\n","                plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/3D segmentation/result/'+str(epoch)+\"a_Original_Image.png\")\n","                 \n","                plt.figure()\n","                plt.imshow(np.squeeze(test_example_gt),cmap='gray')\n","                plt.axis('off')\n","                plt.title('Ground Truth Mask')\n","                plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/3D segmentation/result/'+str(epoch)+\"b_Original_Mask.png\")\n","\n","                plt.figure()\n","                plt.imshow(np.squeeze(sess_results),cmap='gray')\n","                plt.axis('off')\n","                plt.title('Generated Mask')\n","                plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/3D segmentation/result/'+str(epoch)+\"c_Generated_Mask.png\")\n","\n","                plt.close('all')\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sIDXJRhzqbNn","colab_type":"text"},"source":["COMMENTS ON DICE LOSS AND ACCURACY\n","\n","1. Under the name_scope \"LOSS FUNCTION\", the variable named dice corresponds to dice loss and since the function dice_multipleclass() returns a value between -1 and 0(both included) , we add 1. Also another reason for this is there is no maximize function in adam optimizer(or any other optimizing function).\n","\n","2. While printing  the accuracy (everywhere)  we have to print dice coefficient and not dice loss therefore we add 1 to the dice_loss calculation"]},{"cell_type":"code","metadata":{"id":"vLp7SRmzT6Jp","colab_type":"code","outputId":"e9982f12-1b7f-4e00-d87d-1f3381cbba3f","executionInfo":{"status":"error","timestamp":1557745049497,"user_tz":-330,"elapsed":185165,"user":{"displayName":"JAHANVI PATEL","photoUrl":"","userId":"14445844665407264126"}},"colab":{"base_uri":"https://localhost:8080/","height":615}},"source":["chose_train_restore()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Making new\n","CNN1 (?, 160, 160, 192, 8)\n","CNN2 (?, 160, 160, 192, 8)\n","CNN3 (?, 80, 80, 96, 16)\n","CNN4 (?, 80, 80, 96, 16)\n","CNN5 (?, 40, 40, 48, 32)\n","CNN6 (?, 40, 40, 48, 32)\n","CNN7 (?, 20, 20, 24, 64)\n","CNN8 (?, 20, 20, 24, 64)\n","CNN9 (?, 10, 10, 12, 128)\n","CNN10 (?, 10, 10, 12, 64)\n","concat1 (?, 10, 10, 12, 128)\n","DCNN1 (1, 20, 20, 24, 64)\n","CNN18 (1, 160, 160, 192, 4)\n","(4,)\n","After Epoch 10 Hybrid Train accuracy: -1.3168888092041016 Dice Train accuracy: 6.258487701416016e-06 Focal Train accuracy: -16.648681640625 MSE Train accuracy: 0.7500009089708328\n","After Epoch 10 Hybrid Train accuracy: -1.0222878456115723 Dice Train accuracy: 6.794929504394531e-05 Focal Train accuracy: -12.966863632202148 MSE Train accuracy: 0.7500047832727432\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-1aedf54d4167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchose_train_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-5fabbca283fb>\u001b[0m in \u001b[0;36mchose_train_restore\u001b[0;34m(learning_rate, n_epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;31m#with tf.device('/cpu:0'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_batch_no\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpermute_mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_h5py_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch_no\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpermute_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0msess_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;31m#print (\"epoch\",epoch+1,\"batch\",iteration+1)#,\"Cost\",sess_results[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-eba05f5dac84>\u001b[0m in \u001b[0;36mrandom_h5py_batch\u001b[0;34m(current_batch_no, permute_mat)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpermute_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_batch_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m155\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m155\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mcurrent_batch_no\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mread_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Icc3WNqr_ZYR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}