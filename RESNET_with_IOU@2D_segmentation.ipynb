{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RESNET_with_IOU@2D_segmentation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"RIqV48zuBpwM","colab_type":"text"},"cell_type":"markdown","source":["\"\"\"\n","COMPLETELY NEW VERSION OF UNET DESIGNED FOR BRAIN TUMOUR SEGMENTATION\n","\n","\n","residual network in each convolutional block\n","\n","SPECS:\n","\n","1. Input size  is 240x240x4 for each image\n","\n","2. BRATS dataset \n","\n","3. DICE LOSS IS TAKEN AS A LOSS FUNCTION\n","\n","4. MULTICLASS SEGMENTATION HAS BEEN IMPLEMENTED\n","\n","\n","DESC:\n","\n","HERE OUR PREDICTION WILL HAVE 4 DIMENSIONS(because we have 4 classes) FOR EACH IMAGE. THESE 4 PREDICTIONS are compared with hot encoded label(Ground truth)\n","THIS IN A WAY TRAINS THE SYSTEM TO HOT ENCODE THE PREDICTIONS TOO.\n","WE ARE TRYING TO IMPLEMENT THE ABOVE STATED MODEL TO IMPLEMENT MULTICLASS SEGEMENTATION. BUT HAD TO CHANGE SOME THINGS WHICH ARE STATED BELOW\n","\n","PROBLEMS AND CHANGES:\n","\n","1. Faced the problem of class imbalance. So in this version we multiply dice coefficient for each class with certain weight. this weight is reciprocal of the frequency of that class\n","\n","2. The problem of class imbalance still persists and dice coeff is more than 1. So i this version we have implemented a new dice coefficient function.\n","\n","\n","FUTURE:\n","\n","1. IMPROVING DICE COEFFICIENT\n","\n","2. 3D IMPLEMENTATION\n","\n","\n"]},{"metadata":{"id":"eSGVMeVbibw0","colab_type":"code","outputId":"38893138-3a84-4cce-ee46-ab9016be96ae","executionInfo":{"status":"ok","timestamp":1556192758811,"user_tz":-330,"elapsed":302669,"user":{"displayName":"DWIJAY SHANBHAG","photoUrl":"","userId":"01321982494498435915"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"cell_type":"code","source":["'''Mounting Google Drive on the Colab notebook'''\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"hxotR3CiirGu","colab_type":"code","colab":{}},"cell_type":"code","source":["#file_image = '/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_image.hdf5'\n","import h5py\n","#dataset has data of 484 patients. (155 images of each patient)\n","#data is extracted using 4 different techniques\n","#size of data of 1 patient is [240,240,155,4]\n","#for 2D segmentation we stack in 3rd dimension (axis=2)\n","#train_image\n","image_store = h5py.File(\"/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_image.hdf5\", \"r\")\n","#train_labels\n","label_store = h5py.File(\"/content/gdrive/My Drive/Brain_Tumour_segmentation/Train_label.hdf5\", \"r\")\n","train_images = image_store[\"image\"]\n","train_labels = label_store[\"label\"]\n","#print('hi')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RIkjuDek_v5Q","colab_type":"code","colab":{}},"cell_type":"code","source":["'''IMPORTING LIBRARIES'''\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import time\n","import math\n","'''Clearing tesorflow computation graph'''\n","tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SAFj-oXR_0Rs","colab_type":"code","colab":{}},"cell_type":"code","source":["'''DEFINING VARIABLES'''\n","\n","batch_size=155              #batch size taken at a time\n","n_class = 4                #number of classes in the label\n","\n","'''PLACEHOLDER for input and output of UNET'''\n","X = tf.placeholder(shape=[None,240,240,4], dtype=tf.float32, name='input_image')\n","y = tf.placeholder(shape=[240,240,None,1], dtype=tf.int64, name='hot_encode_label')\n","\n","\n","'''Batch variable exraction from h5py file (used by functions 'rnadom_h5py_batch' and 'test_batch')'''\n","out_img = np.empty((240,240,batch_size,4),dtype=np.float32)\n","out_label = np.empty((240,240,batch_size,1),dtype=np.int64)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"re3MWWJHLxuD","colab_type":"text"},"cell_type":"markdown","source":["DEFINING ALL THE REQUIRED FUNCTIONS"]},{"metadata":{"id":"No2sukbcBnCm","colab_type":"code","colab":{}},"cell_type":"code","source":["'''COMPUTATION GRAPH Function Definitions'''\n","\n","\n","def left_filter_def(ker_size,in_chan,out_chan,name='left_filter'):\n","  '''Defining a filter variable to perform convolution'''\n","  return (tf.Variable(tf.random_normal([ker_size,ker_size,in_chan,out_chan],stddev=0.05),name=name))\n","\n","\n","def right_filter_def(ker_size,in_chan,out_chan,name='right_filter'):\n","  '''Defining a filter variable to perform transpose convolution'''\n","  return (tf.Variable(tf.random_normal([ker_size,ker_size,out_chan,in_chan],stddev=0.05),name=name))\n","\n","\n","def Conv_layer(input_im,filter_mask,stride,activation='None',name='conv'):\n","  '''Function to perform Convolution and apply activation filter'''\n","  '''Convolution'''\n","  conv = tf.nn.conv2d(input_im,filter_mask,strides = [1,stride,stride,1], padding = \"SAME\",name=name)\n","  #norm_conv = tf.layers.batch_normalization(conv, training=training, momentum=0.9)\n","  '''Activation'''\n","  if activation == 'relu':\n","      return(tf.nn.relu(conv))\n","  elif activation == 'softmax':\n","      return(tf.nn.softmax(conv,axis=-1))\n","  elif activation == 'elu':\n","      return(tf.nn.elu(conv))\n","  else:\n","      #activation == 'None'\n","      return(conv)\n","    \n","\n","def Deconv_layer(input_im,filter_mask,stride,activation='None',name='De_conv'):\n","  '''Function to perform Transpose Convolution and apply activation filter'''\n","  '''Transpose Convolution'''\n","  inp_shape = np.shape(input_im) #tf.shape()\n","  out_shape = [batch_size]+[int(inp_shape[1].value*2), int(inp_shape[2].value*2), int(inp_shape[3].value/2)]\n","    \n","  conv = tf.nn.conv2d_transpose(input_im, filter_mask, out_shape, strides = [1,stride,stride,1], padding = \"SAME\",name=name)\n","  #norm_conv = tf.layers.batch_normalization(conv, training=training, momentum=0.9)\n","  '''Activation'''\n","  if activation == 'relu':\n","      return(tf.nn.relu(conv))\n","  elif activation == 'softmax':\n","      return(tf.nn.softmax(conv,axis=-1))\n","  elif activation == 'elu':\n","      return(tf.nn.elu(conv))\n","  else:\n","      #activation == 'None'\n","      return(conv)\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K2tyXeDFbpMy","colab_type":"code","colab":{}},"cell_type":"code","source":["'''Functions for batch Extraction and pre processing'''\n","\n","def normalizing_input():\n","  '''normalization of each input channels'''\n","  global out_img\n","  '''CHANNEL INFO'''\n","  # maximum value found using function called \"Finding_maximum_to_normalise \"\n","  #'''max value for dimension 4 is 5337.0'''\n","  #'''max value for dimension 3 is 11737.0'''\n","  #'''max value for dimension 2 is 9751.0'''\n","  #'''max value for dimension 1 is 6476.0'''\n","  out_img[:,:,:,0] = out_img[:,:,:,0]/6476.0\n","  out_img[:,:,:,1] = out_img[:,:,:,1]/9751.0\n","  out_img[:,:,:,2] = out_img[:,:,:,2]/11737.0\n","  out_img[:,:,:,3] = out_img[:,:,:,3]/5337.0\n","\n","\n","\n","\n","def random_h5py_batch(current_batch_no,permute_mat):\n","  '''Function to take batches randomly'''\n","  global out_img\n","  global out_label\n","  \n","  '''training info'''\n","  train_info = 50*155  #100 patients with 155 images each\n","\n","  if current_batch_no == 0:\n","      no_of_batches = train_info//batch_size  \n","      permute_mat = np.random.permutation(no_of_batches)\n","  \n","  start = permute_mat[current_batch_no]*batch_size\n","  end = start + batch_size\n","  train_images.read_direct(out_img,np.s_[:,:,start:end,:])\n","  train_labels.read_direct(out_label,np.s_[:,:,start:end,:])\n","  current_batch_no += 1\n","  #print(len(out_img))\n","  '''Input normalization'''\n","  normalizing_input()\n","  '''normalization oof labels'''\n","  #out_label = out_label\n","  '''converting multi class to dual class'''\n","  #out_label = convert_dual_class(out_label)\n","  \n","  '''Rolling axes'''\n","  out_img_send = np.rollaxis(out_img,2, 0)\n","  '''hot encoding'''\n","  out_label_send = out_label\n","    \n","  last=0\n","  if current_batch_no == len(permute_mat):\n","      last=1\n","    \n","  return (out_img_send,out_label_send,current_batch_no,permute_mat,last)\n","\n","\n","def test_batch():\n","  '''Function to take next test batch'''\n","  \n","  global out_img\n","  global out_label\n","    \n","  '''training and testing info'''\n","  train_info = 50*155  #100 patients with 155 images each\n","  test_info = 184*155  #100 patients with 155 images each\n","    \n","  no_of_batches = test_info//batch_size  \n","  permute_mat = np.random.permutation(no_of_batches)\n","  start = (permute_mat[0]*batch_size) +train_info\n","  end = start + batch_size\n","  train_images.read_direct(out_img,np.s_[:,:,start:end,:])\n","  train_labels.read_direct(out_label,np.s_[:,:,start:end,:])\n","    \n","  '''normalization'''\n","  normalizing_input()\n","  '''Converting multiclass to dual class'''\n","  #out_label = convert_dual_class(out_label) \n","  '''rolling axis'''\n","  out_img_send = np.rollaxis(out_img,2, 0)\n","  '''hot encoding'''\n","  out_label_send = (out_label)\n","    \n","  return (out_img_send,out_label_send)\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CQCK3RO4L3hl","colab_type":"text"},"cell_type":"markdown","source":["INITIALIZING THE MODEL FILTERS\n","\n","\n","Filters with Resnet modifications"]},{"metadata":{"id":"8gltgoRN2psk","colab_type":"code","colab":{}},"cell_type":"code","source":["'''loss function definition'''\n","\n","\n","###############################################################################################################################\n","#LOSS FUNCTION IN VERSION 1 OF TRIAL 2\n","###############################################################################################################################\n","def dice_coeff(y_true, y_pred):\n","  '''Finding dice coefficient for one class'''\n","  #flat_layer = tf.layers.Flatten()\n","  #y_true_f = flat_layer(y_true)\n","  #y_pred_f = flat_layer(y_pred)\n","  intersection = tf.math.reduce_sum(y_true*y_pred)\n","  #union = (tf.square(tf.math.reduce_sum(y_true))+tf.square(tf.math.reduce_sum(y_pred)))\n","  union = ((tf.math.reduce_sum(y_true*y_true))+(tf.math.reduce_sum(y_pred*y_pred)))\n","  #print (np.sum(y_true*y_pred))\n","  #return ((2*intersection)+1)/(union+1)\n","  return(intersection,union)\n","\n","  \n","def dice_coef_multilabel(y_true, y_pred, numLabels = n_class):\n","  '''Finding dice loss for each class'''\n","  dice = denominator = numerator = 0\n","  Ncl = y_pred.shape[-1]\n","  w = np.zeros(shape=(Ncl,))\n","  #print(np.shape(y_true))\n","  w = tf.reduce_sum(y_true, axis=[0,1,2]) + 1\n","  #w = 1/((w**2))\n","  #w = np.sum(y_true, axis=(0,1,2))\n","  weight = np.zeros(shape=(Ncl,))\n","  weight = 1/w\n","  #for i in range(numLabels):\n","  #  if w[i]==0:\n","  #    w[i] = 1\n","  #  else:\n","  #    w[i] = (1/w[i])\n","    #weight[i] = a\n","      \n","  for index in range(numLabels):\n","    \n","    #if w[index] == 0:\n","    #  weight = 1\n","    #else:\n","    #  weight = tf.square(w[index]/tf.reduce_sum(w))\n","    a = weight[index]/(tf.reduce_sum(weight))     #for removing the weight added in all\n","    '''Here, as of now we are neglecting the background class'''\n","    #dice -= (weight*dice_coeff(y_true[:,:,:,index,0],y_pred[:,:,:,index]))\n","    num,den = (dice_coeff(y_true[:,:,:,index,0],y_pred[:,:,:,index]))\n","    denominator += den\n","    numerator += a*(num)\n","    #print(weight)\n","  dice = -((2*numerator)/denominator)\n","  return (dice)\n","#############################################################################################################################\n","  \n","def hot_encode(check_image,depth=n_class,name='hot_encode'):\n","  '''function for hot encoding images'''\n","  a = tf.one_hot(indices = check_image, depth=depth,name=name)\n","  b = tf.transpose(a,perm=[2,0,1,4,3])\n","  return b\n","\n","\n","#############################################################################################################################\n","#NEW DICE LOSS FUNCTION\n","#############################################################################################################################\n","def generalized_dice_coeff(y_true, y_pred):\n","    Ncl = y_pred.shape[-1]\n","    w = np.zeros(shape=(Ncl,))\n","    w = tf.reduce_sum(y_true, axis=[0,1,2])\n","    w = 1/((w**2)+0.000001)\n","    print(np.shape(w))\n","    # Compute gen dice coef:\n","    numerator = y_true*y_pred\n","    denominator = y_true+y_pred\n","    a=b=0\n","    for i in range(np.shape(w)[0]):\n","      a += w[i]*numerator[:,:,:,i]\n","      b += w[i]*denominator[:,:,:,i]\n","      \n","    \n","    num = tf.reduce_sum(a)\n","    den = tf.reduce_sum(b)\n","\n","    gen_dice_coef = num/den\n","\n","    return (-gen_dice_coef)\n","  \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oHMGiKsBL-QK","colab_type":"code","outputId":"fdc5b7c6-aa2d-4687-cf7b-15787828bfb6","executionInfo":{"status":"ok","timestamp":1555935766049,"user_tz":-330,"elapsed":897,"user":{"displayName":"DWIJAY SHANBHAG","photoUrl":"","userId":"01321982494498435915"}},"colab":{"base_uri":"https://localhost:8080/","height":92}},"cell_type":"code","source":["'''MODEL1 Filter definition'''\n","'''LEFT'''\n","\n","filter1 = left_filter_def(3,4,8,name='filter1')\n","filter2 = left_filter_def(3,8,8,name='filter2')\n","filter3 = left_filter_def(3,8,8,name='filter3')\n","\n","filter4 = left_filter_def(3,8,16,name='filter4')\n","filter5 = left_filter_def(3,16,16,name='filter5')\n","filter6 = left_filter_def(3,16,16,name='filter6')\n","\n","filter7 = left_filter_def(3,16,32,name='filter7')\n","filter8 = left_filter_def(3,32,32,name='filter8')\n","filter9 = left_filter_def(3,32,32,name='filter9')\n","\n","filter10 = left_filter_def(3,32,64,name='filter10')\n","filter11 = left_filter_def(3,64,64,name='filter11')\n","filter12 = left_filter_def(3,64,64,name='filter12')\n","\n","filter13 = left_filter_def(3,64,128,name='filter13')\n","filter14= left_filter_def(3,128,64,name='filter14')\n","filter15= left_filter_def(3,128,64,name='filter15')\n","\n","'''RIGHT'''\n","\n","filter16 = right_filter_def(3,128,64,name='filter16')\n","filter17 = left_filter_def(3,64,64,name='filter17')\n","filter18 = left_filter_def(3,64,64,name='filter18')\n","filter19 = left_filter_def(3,64,32,name='filter19')\n","\n","filter20 = right_filter_def(3,64,32,name='filter20')\n","filter21 = left_filter_def(3,32,32,name='filter21')\n","filter22 = left_filter_def(3,32,32,name='filter22')\n","filter23 = left_filter_def(3,32,16,name='filter23')\n","\n","filter24 = right_filter_def(3,32,16,name='filter24')\n","filter25 = left_filter_def(3,16,16,name='filter25')\n","filter26 = left_filter_def(3,16,16,name='filter26')\n","filter27 = left_filter_def(3,16,8,name='filter27')\n","\n","filter28 = right_filter_def(3,16,8,name='filter28')\n","filter29 = left_filter_def(3,8,8,name='filter29')\n","filter30 = left_filter_def(3,8,8,name='filter30')\n","filter31 = left_filter_def(3,8,n_class,name='filter31')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"metadata":{"id":"mf9Y3JjeMQnI","colab_type":"text"},"cell_type":"markdown","source":["DEFINING THE MODEL STRUCTURE\n","\n","Model with Resnet Modification"]},{"metadata":{"id":"3uIZEngOMVfS","colab_type":"code","colab":{}},"cell_type":"code","source":["def predict_model1(X):\n","    '''Function to define the UNET model'''\n","    with tf.name_scope(\"BLOCK1\"):\n","      '''BLOCK1'''\n","      CNN1 = Conv_layer(X,filter1,stride=1,activation='relu',name='CNN1')\n","      #rint (\"CNN1\",np.shape(CNN1))\n","      CNN2 = Conv_layer(CNN1,filter2,stride=1,activation='relu',name='CNN2')\n","      #rint (\"CNN2\",np.shape(CNN2))\n","      CNNR1 = tf.add(Conv_layer(CNN2,filter3,stride=1,activation='relu',name='CNNR1'), CNN1, name='Resnet1')\n","      #rint (\"CNNR1\",np.shape(CNNR1))\n","      pool1 = tf.nn.max_pool(CNNR1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID',name='POOL1')\n","    \n","    with tf.name_scope(\"BLOCK2\"):\n","      '''BLOCK2'''\n","      CNN3 = Conv_layer(pool1,filter4,stride=1,activation='relu',name='CNN3')\n","      #rint (\"CNN3\",np.shape(CNN3))\n","      CNN4 = Conv_layer(CNN3,filter5,stride=1,activation='relu',name='CNN4')\n","      #rint (\"CNN4\",np.shape(CNN4))\n","      CNNR2 = tf.add(Conv_layer(CNN4,filter6,stride=1,activation='relu',name='CNNR2'), CNN3, name='Resnet2')\n","      #rint (\"CNNR2\",np.shape(CNNR2))\n","      pool2 = tf.nn.max_pool(CNNR2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID',name='POOL2')\n","    \n","    with tf.name_scope(\"BLOCK3\"):\n","      '''BLOCK3'''\n","      CNN5 = Conv_layer(pool2,filter7,stride=1,activation='relu',name='CNN5')\n","      #rint (\"CNN5\",np.shape(CNN5))\n","      CNN6 = Conv_layer(CNN5,filter8,stride=1,activation='relu',name='CNN6')\n","      #rint (\"CNN6\",np.shape(CNN6))\n","      CNNR3 = tf.add(Conv_layer(CNN6,filter9,stride=1,activation='relu',name='CNNR3'), CNN5, name='Resnet3')\n","      #rint (\"CNNR3N\",np.shape(CNNR3))\n","      pool3 = tf.nn.max_pool(CNNR3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID',name='POOL3')\n","    \n","    with tf.name_scope(\"BLOCK4\"):\n","      '''BLOCK4'''\n","      CNN7 = Conv_layer(pool3,filter10,stride=1,activation='relu',name='CNN7')\n","      #rint (\"CNN7\",np.shape(CNN7))\n","      CNN8 = Conv_layer(CNN7,filter11,stride=1,activation='relu',name='CNN8')\n","      #rint (\"CNN8\",np.shape(CNN8))\n","      CNNR4 = tf.add(Conv_layer(CNN8,filter12,stride=1,activation='relu',name='CNNR4'), CNN7, name='Resnet4')\n","      #rint (\"CNNR4\",np.shape(CNNR4))\n","      pool4 = tf.nn.max_pool(CNNR4,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID',name='POOL4')\n","    \n","    with tf.name_scope(\"BLOCK5\"):\n","      '''BLOCK5'''\n","      CNN9 = Conv_layer(pool4,filter13,stride=1,activation='relu',name='CNN9')\n","      #rint (\"CNN9\",np.shape(CNN9))\n","      CNN10 = Conv_layer(CNN9,filter14,stride=1,activation='relu',name='CNN10')\n","      #rint (\"CNN10\",np.shape(CNN10))\n","      #NNR5 = tf.add(Conv_layer(CNN10,filter15,stride=1,activation='relu',name='CNNR5'), CNN9, name='Resnet5')\n","      #rint (\"CNNR5\",np.shape(CNNR5))\n","    \n","    '''Moving UP'''\n","    \n","    with tf.name_scope(\"BLOCK6\"):\n","      '''BLOCK6'''\n","      concat1 = tf.concat([CNN10,pool4],axis=3,name='CONCAT1')\n","      #rint (\"concat1\",np.shape(concat1))\n","      DCNN1= Deconv_layer(concat1,filter16,stride=2,activation='relu',name='DE_CONV1')\n","      #rint (\"DCNN1\",np.shape(DCNN1))\n","      CNN11 = Conv_layer(DCNN1,filter17,stride=1,activation='relu',name='CNN11')\n","      #rint (\"CNN11\",np.shape(CNN11))\n","      CNNR6 = tf.add(Conv_layer(CNN11,filter18,stride=1,activation='relu',name='CNNR6'), DCNN1, name='Resnet6')\n","      #rint (\"CNNR6\",np.shape(CNNR6))\n","      CNN12 = Conv_layer(CNNR6,filter19,stride=1,activation='relu',name='CNN12')\n","      #rint (\"CNN12\",np.shape(CNN12))\n","    \n","    with tf.name_scope(\"BLOCK7\"):\n","      '''BLOCK7'''\n","      concat2 = tf.concat([CNN12,pool3],axis=3,name='CONCAT2')\n","      #rint (\"concat2\",np.shape(concat2))\n","      DCNN2= Deconv_layer(concat2,filter20,stride=2,activation='relu',name='DE_CONV2')\n","      #rint (\"DCNN2\",np.shape(DCNN2))\n","      CNN13 = Conv_layer(DCNN2,filter21,stride=1,activation='relu',name='CNN13')\n","      #rint (\"CNN13\",np.shape(CNN13))\n","      CNNR7 = tf.add(Conv_layer(CNN13,filter22,stride=1,activation='relu',name='CNNR7'), DCNN2, name='Resnet7')\n","      #rint (\"CNNR7\",np.shape(CNNR7))\n","      CNN14 = Conv_layer(CNNR7,filter23,stride=1,activation='relu',name='CNN14')\n","      #rint (\"CNN14\",np.shape(CNN14))\n","    \n","    with tf.name_scope(\"BLOCK8\"):\n","      '''BLOCK8'''\n","      concat3 = tf.concat([CNN14,pool2],axis=3,name='CONCAT3')\n","      #rint (\"concat3\",np.shape(concat3))\n","      DCNN3= Deconv_layer(concat3,filter24,stride=2,activation='relu',name='DE_CONV3')\n","      #rint (\"DCNN3\",np.shape(DCNN3))\n","      CNN15 = Conv_layer(DCNN3,filter25,stride=1,activation='relu',name='CNN15')\n","      #rint (\"CNN15\",np.shape(CNN15))\n","      CNNR8 = tf.add(Conv_layer(CNN15,filter26,stride=1,activation='relu',name='CNNR8'), DCNN3, name='Resnet8')\n","      #rint (\"CNNR8\",np.shape(CNNR8))\n","      CNN16 = Conv_layer(CNNR8,filter27,stride=1,activation='relu',name='CNN16')\n","      #rint (\"CNN16\",np.shape(CNN16))\n","      \n","    with tf.name_scope(\"BLOCK9\"):\n","      '''BLOCK9'''\n","      concat4 = tf.concat([CNN16,pool1],axis=3,name='CONCAT4')\n","      #rint (\"concat4\",np.shape(concat4))\n","      DCNN4= Deconv_layer(concat4,filter28,stride=2,activation='relu',name='DE_CONV4')\n","      #rint (\"DCNN4\",np.shape(DCNN4))\n","      CNN17 = Conv_layer(DCNN4,filter29,stride=1,activation='relu',name='CNN17')\n","      #rint (\"CNN17\",np.shape(CNN17))\n","      CNNR9 = tf.add(Conv_layer(CNN17,filter30,stride=1,activation='relu',name='CNNR8'), DCNN4, name='Resnet9')\n","      #rint (\"CNNR9\",np.shape(CNNR9))\n","      CNN18 = Conv_layer(CNNR9,filter31,stride=1,activation='softmax',name='CNN18')\n","      #rint (\"CNN18\",np.shape(CNN18))\n","      return (CNN18)\n","\n","# = (predict_model1(X))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fT5KULA5sfK3","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"c_ROD14VTzmB","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_unet(learning_rate =0.0001,n_epochs = 100):\n","  '''Function to Train U-Net'''\n","  prediction = predict_model1(X)#logits\n","  '''----------------------------------------------------------------------------------------------------------------------------------------------------------------'''\n","  with tf.name_scope(\"LOSS_FUNCTION\"):\n","    '''using multi dimensional dice'''\n","    hot_y = hot_encode(y)\n","    dice = 1+ dice_coef_multilabel(hot_y,prediction)     #dice loss for verison 1\n","    #dice = 1 + generalized_dice_coeff(hot_y[:,:,:,:,0], prediction)\n","  '''----------------------------------------------------------------------------------------------------------------------------------------------------------------'''\n","  with tf.name_scope(\"COST_FUNCTION\"):\n","    '''Cost function''''''Remember to change max to min min to mx depending on loss function'''\n","    loss = tf.reduce_mean(dice, name=\"loss\")\n","\n","  with tf.name_scope(\"OPTIMIZER\"):\n","    '''Optimizer'''\n","    optimize = tf.train.AdamOptimizer(learning_rate = learning_rate)\n","    training_output = optimize.minimize(loss)\n","\n","\n","  '''initializing'''\n","  init = tf.global_variables_initializer()\n","  saver = tf.train.Saver()\n","\n","  '''Timing'''\n","  start = time.time()\n","  '''Session'''\n","  with tf.Session() as sess:\n","    init.run()\n","    for epoch in range(n_epochs):\n","      current_batch_no = 0\n","      permute_mat = 0\n","      iteration = 0\n","      while(1):\n","        epoch_x,epoch_y,current_batch_no,permute_mat,last = random_h5py_batch(current_batch_no,permute_mat)\n","        dice_val,sess_results = sess.run([dice,training_output], feed_dict={X: epoch_x, y: epoch_y})\n","        #print (\"epoch\",epoch+1,\"batch\",iteration+1)#,\"Cost\",sess_results[0])\n","            \n","        '''DICE Coefficient for iteration'''\n","        if iteration%10==0:\n","          acc_train = 1-(dice.eval(feed_dict={X: epoch_x, y: epoch_y}))\n","          test_images, test_labels = test_batch()\n","          acc_test = 1-(dice.eval(feed_dict={X: test_images, y: test_labels}))\n","          print(\"Minibatch at\",\"Epoch\", epoch+1,\"batch\",iteration+1, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n","        if last ==1:\n","          break\n","        iteration +=1\n","      test_images, test_labels = test_batch()\n","      acc_test = 1-dice.eval(feed_dict={X: test_images, y: test_labels})\n","      print(\"-------------------------------------------------------------------------------------------------------\")\n","      print(\"After Epoch\", epoch+1, \"Test accuracy:\", acc_test)\n","      print(\"-------------------------------------------------------------------------------------------------------\")\n","        \n","        \n","      if epoch % 1 == 0:\n","        test_example =   test_images\n","        test_example_gt = np.rollaxis(test_labels,2,0)\n","        sess_results = sess.run(prediction,feed_dict={X:test_example})\n","\n","        sess_results = sess_results[0,:,:,1] + (2*sess_results[0,:,:,2]) + (3*sess_results[0,:,:,3])\n","        test_example = test_example[0,:,:,3]\n","        test_example_gt = test_example_gt[0,:,:,:]\n","\n","        plt.figure()\n","        plt.imshow(np.squeeze(test_example),cmap='gray')\n","        plt.axis('off')\n","        plt.title('Original Image')\n","        plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/Resnet_with_dice/'+str(epoch)+\"a_Original_Image.png\")\n","              \n","              \n","        plt.figure()\n","        plt.imshow(np.squeeze(test_example_gt),cmap='gray')\n","        plt.axis('off')\n","        plt.title('Ground Truth Mask')\n","        plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/Resnet_with_dice/'+str(epoch)+\"b_Original_Mask.png\")\n","\n","        plt.figure()\n","        plt.imshow(np.squeeze(sess_results),cmap='gray')\n","        plt.axis('off')\n","        plt.title('Generated Mask')\n","        plt.savefig('/content/gdrive/My Drive/Brain_Tumour_segmentation/Resnet_with_dice/'+str(epoch)+\"c_Generated_Mask.png\")\n","\n","        plt.close('all')\n","\n","    '''Saving the graph'''\n","    save_path = saver.save(sess, \"/content/gdrive/My Drive/Brain_Tumour_segmentation/final_madel_graph\")\n","  end = time.time()\n","  total_time = end-start\n","  return (total_time)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sIDXJRhzqbNn","colab_type":"text"},"cell_type":"markdown","source":["COMMENTS ON DICE LOSS AND ACCURACY\n","\n","1. Under the name_scope \"LOSS FUNCTION\", the variable named dice corresponds to dice loss and since the function dice_multipleclass() returns a value between -1 and 0(both included) , we add 1. Also another reason for this is there is no maximize function in adam optimizer(or any other optimizing function).\n","\n","2. While printing  the accuracy (everywhere)  we have to print dice coefficient and not dice loss therefore we add 1 to the dice_loss calculation"]},{"metadata":{"id":"vLp7SRmzT6Jp","colab_type":"code","outputId":"cac5b5d9-7c27-4c4c-c2c1-4d448aa1c644","executionInfo":{"status":"error","timestamp":1555950104345,"user_tz":-330,"elapsed":14278498,"user":{"displayName":"DWIJAY SHANBHAG","photoUrl":"","userId":"01321982494498435915"}},"colab":{"base_uri":"https://localhost:8080/","height":4415}},"cell_type":"code","source":["train_unet()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Minibatch at Epoch 1 batch 1 Train accuracy: [5.9604645e-08] Test accuracy: [0.00251377]\n","Minibatch at Epoch 1 batch 11 Train accuracy: [2.3841858e-07] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 1 batch 21 Train accuracy: [0.00130755] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 1 batch 31 Train accuracy: [0.00090533] Test accuracy: [0.00171882]\n","Minibatch at Epoch 1 batch 41 Train accuracy: [0.00046486] Test accuracy: [0.00639528]\n","Minibatch at Epoch 1 batch 51 Train accuracy: [0.00032926] Test accuracy: [0.00021386]\n","Minibatch at Epoch 1 batch 61 Train accuracy: [0.00099146] Test accuracy: [0.0018689]\n","Minibatch at Epoch 1 batch 71 Train accuracy: [4.172325e-07] Test accuracy: [0.00070763]\n","Minibatch at Epoch 1 batch 81 Train accuracy: [0.00044018] Test accuracy: [0.00089467]\n","Minibatch at Epoch 1 batch 91 Train accuracy: [2.3841858e-07] Test accuracy: [8.606911e-05]\n","Minibatch at Epoch 1 batch 101 Train accuracy: [5.9604645e-08] Test accuracy: [0.00231403]\n","Minibatch at Epoch 1 batch 111 Train accuracy: [5.9604645e-08] Test accuracy: [8.85725e-05]\n","Minibatch at Epoch 1 batch 121 Train accuracy: [4.172325e-07] Test accuracy: [0.00189185]\n","Minibatch at Epoch 1 batch 131 Train accuracy: [5.9604645e-08] Test accuracy: [0.00071102]\n","Minibatch at Epoch 1 batch 141 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 1 batch 151 Train accuracy: [5.9604645e-08] Test accuracy: [0.00231504]\n","-------------------------------------------------------------------------------------------------------\n","After Epoch 1 Test accuracy: [5.9604645e-08]\n","-------------------------------------------------------------------------------------------------------\n","Minibatch at Epoch 2 batch 1 Train accuracy: [5.9604645e-08] Test accuracy: [0.00582886]\n","Minibatch at Epoch 2 batch 11 Train accuracy: [0.0055626] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 2 batch 21 Train accuracy: [2.9802322e-07] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 2 batch 31 Train accuracy: [0.00030863] Test accuracy: [0.00116128]\n","Minibatch at Epoch 2 batch 41 Train accuracy: [1.1920929e-07] Test accuracy: [0.00012344]\n","Minibatch at Epoch 2 batch 51 Train accuracy: [0.00179511] Test accuracy: [2.9802322e-07]\n","Minibatch at Epoch 2 batch 61 Train accuracy: [5.9604645e-08] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 2 batch 71 Train accuracy: [5.9604645e-08] Test accuracy: [0.00900006]\n","Minibatch at Epoch 2 batch 81 Train accuracy: [5.9604645e-08] Test accuracy: [0.00021076]\n","Minibatch at Epoch 2 batch 91 Train accuracy: [4.172325e-07] Test accuracy: [9.536743e-07]\n","Minibatch at Epoch 2 batch 101 Train accuracy: [0.00352859] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 2 batch 111 Train accuracy: [1.1920929e-07] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 2 batch 121 Train accuracy: [5.9604645e-08] Test accuracy: [0.00165105]\n","Minibatch at Epoch 2 batch 131 Train accuracy: [7.390976e-06] Test accuracy: [0.0013814]\n","Minibatch at Epoch 2 batch 141 Train accuracy: [0.00043237] Test accuracy: [0.00137222]\n","Minibatch at Epoch 2 batch 151 Train accuracy: [4.172325e-07] Test accuracy: [5.9604645e-08]\n","-------------------------------------------------------------------------------------------------------\n","After Epoch 2 Test accuracy: [0.00606257]\n","-------------------------------------------------------------------------------------------------------\n","Minibatch at Epoch 3 batch 1 Train accuracy: [1.1920929e-07] Test accuracy: [0.0013206]\n","Minibatch at Epoch 3 batch 11 Train accuracy: [0.00602001] Test accuracy: [0.0047552]\n","Minibatch at Epoch 3 batch 21 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 3 batch 31 Train accuracy: [5.9604645e-08] Test accuracy: [0.00010192]\n","Minibatch at Epoch 3 batch 41 Train accuracy: [0.00326329] Test accuracy: [0.00037283]\n","Minibatch at Epoch 3 batch 51 Train accuracy: [0.00380266] Test accuracy: [0.00445569]\n","Minibatch at Epoch 3 batch 61 Train accuracy: [5.9604645e-08] Test accuracy: [0.00288582]\n","Minibatch at Epoch 3 batch 71 Train accuracy: [4.172325e-07] Test accuracy: [3.5762787e-07]\n","Minibatch at Epoch 3 batch 81 Train accuracy: [2.9802322e-07] Test accuracy: [1.579523e-05]\n","Minibatch at Epoch 3 batch 91 Train accuracy: [0.00177491] Test accuracy: [0.00166434]\n","Minibatch at Epoch 3 batch 101 Train accuracy: [0.00144261] Test accuracy: [0.0012666]\n","Minibatch at Epoch 3 batch 111 Train accuracy: [5.9604645e-08] Test accuracy: [0.00495148]\n","Minibatch at Epoch 3 batch 121 Train accuracy: [0.00104022] Test accuracy: [8.881092e-06]\n","Minibatch at Epoch 3 batch 131 Train accuracy: [0.00306714] Test accuracy: [3.5762787e-07]\n","Minibatch at Epoch 3 batch 141 Train accuracy: [1.1920929e-07] Test accuracy: [0.00270677]\n","Minibatch at Epoch 3 batch 151 Train accuracy: [0.00062376] Test accuracy: [0.00412619]\n","-------------------------------------------------------------------------------------------------------\n","After Epoch 3 Test accuracy: [2.2470951e-05]\n","-------------------------------------------------------------------------------------------------------\n","Minibatch at Epoch 4 batch 1 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 4 batch 11 Train accuracy: [1.1920929e-07] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 4 batch 21 Train accuracy: [3.5762787e-07] Test accuracy: [1.0728836e-06]\n","Minibatch at Epoch 4 batch 31 Train accuracy: [1.1920929e-07] Test accuracy: [2.9802322e-07]\n","Minibatch at Epoch 4 batch 41 Train accuracy: [5.9604645e-08] Test accuracy: [3.5762787e-07]\n","Minibatch at Epoch 4 batch 51 Train accuracy: [0.00412822] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 4 batch 61 Train accuracy: [1.5854836e-05] Test accuracy: [0.00499845]\n","Minibatch at Epoch 4 batch 71 Train accuracy: [1.1920929e-07] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 4 batch 81 Train accuracy: [0.00084263] Test accuracy: [0.00261426]\n","Minibatch at Epoch 4 batch 91 Train accuracy: [4.172325e-07] Test accuracy: [1.9431114e-05]\n","Minibatch at Epoch 4 batch 101 Train accuracy: [5.9604645e-08] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 4 batch 111 Train accuracy: [5.9604645e-08] Test accuracy: [4.172325e-07]\n","Minibatch at Epoch 4 batch 121 Train accuracy: [0.00209343] Test accuracy: [0.00013179]\n","Minibatch at Epoch 4 batch 131 Train accuracy: [0.00146168] Test accuracy: [0.00293416]\n","Minibatch at Epoch 4 batch 141 Train accuracy: [0.00300288] Test accuracy: [0.00198358]\n","Minibatch at Epoch 4 batch 151 Train accuracy: [5.9604645e-08] Test accuracy: [0.00085378]\n","-------------------------------------------------------------------------------------------------------\n","After Epoch 4 Test accuracy: [1.1920929e-07]\n","-------------------------------------------------------------------------------------------------------\n","Minibatch at Epoch 5 batch 1 Train accuracy: [0.00276113] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 5 batch 11 Train accuracy: [1.1920929e-07] Test accuracy: [0.00036865]\n","Minibatch at Epoch 5 batch 21 Train accuracy: [5.9604645e-08] Test accuracy: [0.00137186]\n","Minibatch at Epoch 5 batch 31 Train accuracy: [5.9604645e-08] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 5 batch 41 Train accuracy: [0.00023323] Test accuracy: [0.00011069]\n","Minibatch at Epoch 5 batch 51 Train accuracy: [2.3841858e-07] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 5 batch 61 Train accuracy: [0.00182694] Test accuracy: [5.8591366e-05]\n","Minibatch at Epoch 5 batch 71 Train accuracy: [5.9604645e-08] Test accuracy: [6.300211e-05]\n","Minibatch at Epoch 5 batch 81 Train accuracy: [1.7881393e-07] Test accuracy: [0.00457186]\n","Minibatch at Epoch 5 batch 91 Train accuracy: [1.1920929e-07] Test accuracy: [0.00247014]\n","Minibatch at Epoch 5 batch 101 Train accuracy: [5.9604645e-08] Test accuracy: [4.130602e-05]\n","Minibatch at Epoch 5 batch 111 Train accuracy: [0.00079185] Test accuracy: [0.005687]\n","Minibatch at Epoch 5 batch 121 Train accuracy: [0.00404233] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 5 batch 131 Train accuracy: [0.00089198] Test accuracy: [3.5226345e-05]\n","Minibatch at Epoch 5 batch 141 Train accuracy: [0.00359935] Test accuracy: [0.00101608]\n","Minibatch at Epoch 5 batch 151 Train accuracy: [0.00128132] Test accuracy: [5.9604645e-08]\n","-------------------------------------------------------------------------------------------------------\n","After Epoch 5 Test accuracy: [1.1920929e-07]\n","-------------------------------------------------------------------------------------------------------\n","Minibatch at Epoch 6 batch 1 Train accuracy: [3.5762787e-07] Test accuracy: [3.5762787e-07]\n","Minibatch at Epoch 6 batch 11 Train accuracy: [2.8967857e-05] Test accuracy: [0.00359541]\n","Minibatch at Epoch 6 batch 21 Train accuracy: [5.9604645e-08] Test accuracy: [1.7881393e-07]\n","Minibatch at Epoch 6 batch 31 Train accuracy: [0.00020826] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 6 batch 41 Train accuracy: [5.9604645e-08] Test accuracy: [1.6093254e-06]\n","Minibatch at Epoch 6 batch 51 Train accuracy: [0.00389284] Test accuracy: [3.361702e-05]\n","Minibatch at Epoch 6 batch 61 Train accuracy: [0.00308651] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 6 batch 71 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 6 batch 81 Train accuracy: [0.00023204] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 6 batch 91 Train accuracy: [5.9604645e-08] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 6 batch 101 Train accuracy: [0.00034702] Test accuracy: [0.00024623]\n","Minibatch at Epoch 6 batch 111 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 6 batch 121 Train accuracy: [0.00143403] Test accuracy: [0.0031302]\n","Minibatch at Epoch 6 batch 131 Train accuracy: [0.00122881] Test accuracy: [0.00053424]\n","Minibatch at Epoch 6 batch 141 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 6 batch 151 Train accuracy: [1.1920929e-07] Test accuracy: [0.00143903]\n","-------------------------------------------------------------------------------------------------------\n","After Epoch 6 Test accuracy: [4.172325e-07]\n","-------------------------------------------------------------------------------------------------------\n","Minibatch at Epoch 7 batch 1 Train accuracy: [0.00051928] Test accuracy: [0.00264674]\n","Minibatch at Epoch 7 batch 11 Train accuracy: [1.1920929e-07] Test accuracy: [0.00288272]\n","Minibatch at Epoch 7 batch 21 Train accuracy: [0.00045109] Test accuracy: [0.00365281]\n","Minibatch at Epoch 7 batch 31 Train accuracy: [5.9604645e-08] Test accuracy: [2.9802322e-07]\n","Minibatch at Epoch 7 batch 41 Train accuracy: [0.00440109] Test accuracy: [0.0004192]\n","Minibatch at Epoch 7 batch 51 Train accuracy: [0.00139695] Test accuracy: [2.9802322e-07]\n","Minibatch at Epoch 7 batch 61 Train accuracy: [0.00047368] Test accuracy: [2.6285648e-05]\n","Minibatch at Epoch 7 batch 71 Train accuracy: [5.9604645e-08] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 7 batch 81 Train accuracy: [0.00384098] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 7 batch 91 Train accuracy: [0.00165427] Test accuracy: [0.00046754]\n","Minibatch at Epoch 7 batch 101 Train accuracy: [5.9604645e-08] Test accuracy: [0.00230491]\n","Minibatch at Epoch 7 batch 111 Train accuracy: [0.00251079] Test accuracy: [0.00375193]\n","Minibatch at Epoch 7 batch 121 Train accuracy: [0.00059128] Test accuracy: [0.00078839]\n","Minibatch at Epoch 7 batch 131 Train accuracy: [0.00110734] Test accuracy: [0.0038777]\n","Minibatch at Epoch 7 batch 141 Train accuracy: [0.00027305] Test accuracy: [0.00059408]\n","Minibatch at Epoch 7 batch 151 Train accuracy: [1.1920929e-07] Test accuracy: [3.5762787e-07]\n","-------------------------------------------------------------------------------------------------------\n","After Epoch 7 Test accuracy: [0.00039464]\n","-------------------------------------------------------------------------------------------------------\n","Minibatch at Epoch 8 batch 1 Train accuracy: [5.9604645e-08] Test accuracy: [3.5762787e-07]\n","Minibatch at Epoch 8 batch 11 Train accuracy: [0.00100446] Test accuracy: [4.23193e-06]\n","Minibatch at Epoch 8 batch 21 Train accuracy: [0.00456673] Test accuracy: [0.00519973]\n","Minibatch at Epoch 8 batch 31 Train accuracy: [0.00053781] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 8 batch 41 Train accuracy: [0.01158917] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 8 batch 51 Train accuracy: [2.9802322e-07] Test accuracy: [0.00336164]\n","Minibatch at Epoch 8 batch 61 Train accuracy: [8.881092e-06] Test accuracy: [0.0020873]\n","Minibatch at Epoch 8 batch 71 Train accuracy: [1.1920929e-07] Test accuracy: [0.00149655]\n","Minibatch at Epoch 8 batch 81 Train accuracy: [0.0006125] Test accuracy: [1.0609627e-05]\n","Minibatch at Epoch 8 batch 91 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 8 batch 101 Train accuracy: [3.5762787e-07] Test accuracy: [0.00302052]\n","Minibatch at Epoch 8 batch 111 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 8 batch 121 Train accuracy: [3.5762787e-07] Test accuracy: [0.00017178]\n","Minibatch at Epoch 8 batch 131 Train accuracy: [0.0014416] Test accuracy: [0.00522339]\n","Minibatch at Epoch 8 batch 141 Train accuracy: [0.00189096] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 8 batch 151 Train accuracy: [0.00327206] Test accuracy: [5.9604645e-08]\n","-------------------------------------------------------------------------------------------------------\n","After Epoch 8 Test accuracy: [4.172325e-07]\n","-------------------------------------------------------------------------------------------------------\n","Minibatch at Epoch 9 batch 1 Train accuracy: [1.1920929e-07] Test accuracy: [4.172325e-07]\n","Minibatch at Epoch 9 batch 11 Train accuracy: [0.00125277] Test accuracy: [2.9802322e-07]\n","Minibatch at Epoch 9 batch 21 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 9 batch 31 Train accuracy: [0.00055069] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 9 batch 41 Train accuracy: [0.00026035] Test accuracy: [0.00352722]\n","Minibatch at Epoch 9 batch 51 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 9 batch 61 Train accuracy: [0.00039184] Test accuracy: [9.119511e-06]\n","Minibatch at Epoch 9 batch 71 Train accuracy: [4.172325e-07] Test accuracy: [0.00044179]\n","Minibatch at Epoch 9 batch 81 Train accuracy: [0.00043678] Test accuracy: [9.071827e-05]\n","Minibatch at Epoch 9 batch 91 Train accuracy: [0.01329124] Test accuracy: [0.00638777]\n","Minibatch at Epoch 9 batch 101 Train accuracy: [0.00242102] Test accuracy: [0.00175411]\n","Minibatch at Epoch 9 batch 111 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 9 batch 121 Train accuracy: [5.9604645e-08] Test accuracy: [0.00029916]\n","Minibatch at Epoch 9 batch 131 Train accuracy: [0.0029763] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 9 batch 141 Train accuracy: [4.172325e-07] Test accuracy: [0.00741512]\n","Minibatch at Epoch 9 batch 151 Train accuracy: [4.172325e-07] Test accuracy: [0.00063431]\n","-------------------------------------------------------------------------------------------------------\n","After Epoch 9 Test accuracy: [0.00326335]\n","-------------------------------------------------------------------------------------------------------\n","Minibatch at Epoch 10 batch 1 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 10 batch 11 Train accuracy: [4.172325e-07] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 10 batch 21 Train accuracy: [4.172325e-07] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 10 batch 31 Train accuracy: [0.00018293] Test accuracy: [0.00382662]\n","Minibatch at Epoch 10 batch 41 Train accuracy: [0.00105059] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 10 batch 51 Train accuracy: [0.00113279] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 10 batch 61 Train accuracy: [0.00196755] Test accuracy: [0.00369501]\n","Minibatch at Epoch 10 batch 71 Train accuracy: [5.9604645e-08] Test accuracy: [0.00058144]\n","Minibatch at Epoch 10 batch 81 Train accuracy: [4.529953e-06] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 10 batch 91 Train accuracy: [5.9604645e-08] Test accuracy: [0.00550801]\n","Minibatch at Epoch 10 batch 101 Train accuracy: [0.0050348] Test accuracy: [0.00096232]\n","Minibatch at Epoch 10 batch 111 Train accuracy: [5.9604645e-08] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 10 batch 121 Train accuracy: [0.00125313] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 10 batch 131 Train accuracy: [5.9604645e-08] Test accuracy: [8.6426735e-06]\n","Minibatch at Epoch 10 batch 141 Train accuracy: [0.00436735] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 10 batch 151 Train accuracy: [0.00132859] Test accuracy: [1.1920929e-07]\n","-------------------------------------------------------------------------------------------------------\n","After Epoch 10 Test accuracy: [5.9604645e-08]\n","-------------------------------------------------------------------------------------------------------\n","Minibatch at Epoch 11 batch 1 Train accuracy: [0.01350433] Test accuracy: [3.5762787e-07]\n","Minibatch at Epoch 11 batch 11 Train accuracy: [0.00680006] Test accuracy: [0.00374544]\n","Minibatch at Epoch 11 batch 21 Train accuracy: [0.00154579] Test accuracy: [4.172325e-07]\n","Minibatch at Epoch 11 batch 31 Train accuracy: [0.00126952] Test accuracy: [0.00086576]\n","Minibatch at Epoch 11 batch 41 Train accuracy: [0.00236642] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 11 batch 51 Train accuracy: [0.00611246] Test accuracy: [5.9604645e-08]\n","Minibatch at Epoch 11 batch 61 Train accuracy: [0.00231904] Test accuracy: [0.0002228]\n","Minibatch at Epoch 11 batch 71 Train accuracy: [0.00275654] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 11 batch 81 Train accuracy: [0.01456845] Test accuracy: [4.172325e-07]\n","Minibatch at Epoch 11 batch 91 Train accuracy: [0.00390929] Test accuracy: [0.00327456]\n","Minibatch at Epoch 11 batch 101 Train accuracy: [5.9604645e-08] Test accuracy: [0.00151974]\n","Minibatch at Epoch 11 batch 111 Train accuracy: [5.9604645e-08] Test accuracy: [0.00019288]\n","Minibatch at Epoch 11 batch 121 Train accuracy: [4.172325e-07] Test accuracy: [2.3841858e-07]\n","Minibatch at Epoch 11 batch 131 Train accuracy: [0.003447] Test accuracy: [1.1920929e-07]\n","Minibatch at Epoch 11 batch 141 Train accuracy: [0.00026429] Test accuracy: [0.00193423]\n","Minibatch at Epoch 11 batch 151 Train accuracy: [2.9802322e-07] Test accuracy: [5.9604645e-08]\n","-------------------------------------------------------------------------------------------------------\n","After Epoch 11 Test accuracy: [0.00034374]\n","-------------------------------------------------------------------------------------------------------\n","Minibatch at Epoch 12 batch 1 Train accuracy: [4.172325e-07] Test accuracy: [0.00034398]\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-efe8ffd75c21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-89019792385e>\u001b[0m in \u001b[0;36mtrain_unet\u001b[0;34m(learning_rate, n_epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_batch_no\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpermute_mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_h5py_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch_no\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpermute_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mdice_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print (\"epoch\",epoch+1,\"batch\",iteration+1)#,\"Cost\",sess_results[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-bc2a18c76c97>\u001b[0m in \u001b[0;36mrandom_h5py_batch\u001b[0;34m(current_batch_no, permute_mat)\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpermute_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_batch_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mcurrent_batch_no\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mread_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"Icc3WNqr_ZYR","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}